%%% ------------------------------------------
%%% MEC 2013 and 2014 Proceedings: Full volume

@proceedings{Roland_2016a,
 abstract = {Conference proceedings of the Music Encoding Conferences 2013 and 2014 with Foreword by Perry D. Roland and Johannes Kepper},
 year = {2016},
 title = {{Music Encoding Conference Proceedings 2013 and 2014}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 bibbase_note = {<span style="color: green; font-weight: bold">Full volume.</span>},
 keywords = {mec-proceedings, mec-proceedings-2013, mec-proceedings-2014},
 displayby = {Common part MEC 2013--2014}
}

%%% ---------------------------------------
%%% MEC 2013 and 2014 Proceedings: Foreword

@inproceedings{Roland_2016b,
 abstract = {Foreword of the Music Encoding Conference 2013 and 2014 proceedings.},
 author = {Roland, Perry and Kepper, Johannes},
 title = {{Foreword}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {1},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013, mec-proceedings-2014},
 displayby = {Common part MEC 2013--2014}
}

%%% ------------------------------------------------------
%%% MEC 2013 and 2014 Proceedings: Contributions from 2013

@inproceedings{Bohl_2016,
 abstract = {Tracing back theoretical discussion and writing about the nature of music, leads as far as classical antiquity. Pythagoras (of Samos) laid out the mathematical foundations of musical harmony -- and hence constituted the tradition of more than 2.500 years that we can look upon today. Ever since, knowledge on music and its theory has been accompanied by the knowledge about its history. No matter the century that you pick, the basic pythagorean derivation of musical harmony or some variant of the "legend of the hammer strokes" is omnipresent. This tradition produced a huge corpus of individual treatises that provide rules for composing  music. Different eras and genres called for different rules and not seldom, personal preference and self-display were motors to pen down a certain theory of music. Moreover, notorious treatises got transcribed, reproduced me-chanically or borrowed from and -- as consciousness of authorship and copyright had yet to prosper -- partly incorporated into other treatises, without referencing the original author. Beside the amount of pages to grasp in various languages, the above mentioned circumstances make it es-pecially hard for the uninitiated to know which rule to find where or even to fathom the multiple interrelations between these treatises},
 author = {Bohl, Benjamin W.},
 title = {{Fingerprinting the Rule: Towards Interconnecting Music Treatises by Means of an Encoding Scheme for Compositional Rules}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {4--10},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

@inproceedings{Diet_2016,
 abstract = {The RISM-OPAC (http://opac.rism.info) is a free online catalogue that provides access to the data of the RISM series A II (music manuscripts between 1600 and 1800). It has been developed by the Bavarian State Library in cooperation with RISM and the State Library of Berlin and was launched in June 2010. In March 2011, a new version of the RISM-OPAC has been released that includes a searching possibility in the music incipits of the RISM data. Most of the 850.000 data records (as of September 2013) contain one or several music incipits that describe the beginning of instrumental or vocal parts of the music manuscripts using the Plaine{\&}Easie code. This paper describes how the music incipits are encoded in Plaine{\&}Easie and how the searching for music incipits is done in the RISM-OPAC. Furthermore, the rendering of an incipit encoded in Plaine{\&}Easie in a graphical image will be covered. When a RISM-record is displayed the user will not see the Plaine{\&}Easie code but the corresponding graphical form using the common western music notation. Finally, the current developments for the next version of the RISM-OPAC will be explained that include among others an improved user interface for searching in the music incipits and the conversion of the data records of the RISM series A/II into RDF in order to publish them as linked open data.},
 author = {Diet, J{\"u}rgen and Gerritsen, Magda},
 title = {{Encoding, Searching, and Displaying of Music Incipits in the RISM-OPAC}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {11--14},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

@inproceedings{Freedman_2016,
 abstract = {Our work with 16th-century polyphony uses MEI encodings to deliver dynamic renderings of analytic observations as musical notation in any internet browser. The interface allows users to perform faceted searches among thousands of analytic observations about the repertory, collecting them as part of a larger project that aims to reconstruct missing voice parts according to stylistic rules observed elsewhere in the corpus and in theoretical writings of the sixteenth century. This poster will explain our workflow, documents the technologies deployed in relation to MEI, and shows some of the musical insights we have gleaned.},
 author = {Freedman, Richard and Hankinson, Andrew and Viglianti, Raffaele and Besson, Vincent},
 title = {{Recovering Lost Voices: A Digital Workshop for the Restoration of Renaissance Polyphony}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {15--16},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

@inproceedings{Richts_2016,
 abstract = {The Music Encoding Initiative's (MEI) XML schema recommendation not only supports detailed encodings of music notation; it also accommodates comprehensive metadata in the file header. The attempt to utilize the header for cataloguing projects has proved the need to distinguish different levels of description: Some meta-data relate to the musical work in general, some only to a certain version, or to a specific musical source, for instance. The Functional Requirements for Bibliographic Records (FRBR) model, which was developed by the International Federation of Library Associations and Institutions (IFLA), was explicitly conceived to provide a concept for this distinction within bibliographic records in general. An effort has been made within the MEI community to implement the so-called FRBR Group 1 entities (work, expression, manifestation, and item) and relationships in the MEI header. The paper gives an introduction to the FRBR implementation in MEI and demonstrates how relatively com-plex source situations can be modeled with it. Some limitations and problems are discussed.},
 author = {Richts, Kristina and {Teich Geertinger}, Axel},
 title = {{Implementing the Functional Requirements for Bibliographic Records (FRBR) Model in MEI}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {17--26},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

@inproceedings{Hartwig_2016,
 abstract = {This paper documents the steps of a work process used in the creation of a group of example MEI files, one of the main objectives of the project \textit{Digital Music Notation Data Model and Prototype Delivery System} (jointly funded by the DFG and NEH from 2010 to 2013.) This paper describes the need, the workflow, and future objectives for the MEI sample collection.},
 author = {Hartwig, Maja and Richts, Kristina},
 title = {{The MEI Sample Collection: A Description of Workflows}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {27--32},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

@inproceedings{Ludovico_2016,
 abstract = {IEEE 1599 is an XML-based format conceived for a comprehensive representation of music material within a unique document. In a single le it is possible to represent music symbols, graphical scores, audio and video renderings,  catalogue  metadata,  structural  information,  computer  performances,  and  much  more.  All  data  and metadata are synchronized thanks to the concept of spine. IEEE 1599 became an international standard in 2008. On the other hand, the Music Encoding Initiative (MEI) is a community-driven eort to create a com-monly-accepted, digital, symbolic representation of music notation documents. The purpose of this paper is discussing the integration of MEI and IEEE 1599 approaches, each one presenting its own peculiarities, in order to couple the precise notation of the former with the multimedia versatility of the latter},
 author = {Ludovico, Luco A.},
 title = {{The Music Encoding Initiative and the IEEE 1599 Standard: Towards an Integrated Description of Music Contents}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {33--40},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

@inproceedings{Meredith_2016,
 abstract = {A computational approach to music analysis is presented, based on the compression of point-set representations of musical works. The approach relates closely to the theory of Kolmogorov complexity and to psychological coding theories of perceptual organisation. A sketch of a model of musical learning based on this approach is given and it is shown how the model accounts in principle for differences between individuals in how pieces of music are understood. The approach is implemented in a greedy compression algorithm, called COSIATEC, which partitions a point-set into the covered sets of translational equivalence classes of maximal translatable patterns. The analyses generated by COSIATEC on five fugues by J. S. Bach are presented and discussed. These analyses demonstrate the potential of the approach for automatically discovering musical patterns of thematic and structural importance.},
 author = {Meredith, David},
 title = {{Analysis by Compression: Automatic Generation of Compact Geometric Encodings of Musical Objects}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {41--53},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

@inproceedings{Rizo_2016,
 abstract = {\textit{Plaine and Easie Code} is being used as the format for encoding musical content in the RISM catalogue. In this paper we propose an attributed grammar that formally specifies it. The grammar specification is written using a EBNF notation and is accompanied by syntax diagrams and some examples that show how it parses a valid input. With the formalization of the \textit{Plaine and Easie Code}, it is easier to create translators to other formats, analyze possible extensions, and avoid syntactic misunderstandings in the encoding process. The proposed grammar has been successfully used to decode more than one million incipits from the RISM catalogue in an automatic way. In the near future, we are planning to propose some extensions to the PAEC code and specify translation semantic actions associated to the grammar productions in order to convert from PAEC to the MEI format.},
 author = {Rizo, David and I{\~n}esta, Jos{\'e} M.},
 title = {{A Grammar for \textit{Plaine and Easie Code}}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {54--64},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

@inproceedings{Herold_2016,
 abstract = {Being famous not only for his opere \textit{buffe}, but also for his \textit{opere serie}, Giuseppe Sarti was one of the most eminent composers in late 18th century Europe. In this paper, the first steps of two MEI based \textit{Edirom} editions of Sarti's operas -- of \textit{Giulio Sabino} and \textit{Fra i due litiganti il terzo gode} -- are discussed. The prepared editions do not aim to provide a definite or "authentic" text, but will focus on the adaptations characterizing Italian operas of the period, with the intention to show different types of variants and a wide range of arrangements.},
 author = {Herold, Kristin and Siegert, Christine},
 title = {{The Encoding of Sarti's Operas: Macro and Micro Structures}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {65--70},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

@inproceedings{Thalmann_2016,
 abstract = {This paper presents a generalized version of the BigBang rubette, a module for the music software Rubato Composer. It now allows for visualization, generation, and transformation of arbitrary musical data, as long as the data is defined in the denotator format, which models mathematical spaces based on the category of modules. While in earlier stages of development, BigBang was created to deal with the MIDI-like forms \textit{Score}, \textit{MacroScore}, and \textit{SoundScore}, it will now accept any kind of denotators, which enables composers to work with their own objects such as chords, progressions, FM sounds, metrical patterns, counterpoint, pitch-classes, sound spectra, etc.},
 author = {Thalmann, Florian and Mazzola, Guerino},
 title = {{Visualization and Transformation: In General Musical and Music-Theoretical Spaces}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {71--80},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

@inproceedings{Viglianti_2016a,
 abstract = {The \textit{Freisch{\"u}tz Digital project} uses MEI to encode multiple source in Common Music Notation (CMN). The project avoids choosing one specific source as base text and plans to encode diplomatic details about all sources included in the edition. This paper describes how the model is designed to handle this complex situation without requiring a non-conformant customization of MEI.},
 author = {Viglianti, Raffaele},
 title = {{Modelling Complex Editions in MEI: The \textit{Freisch{\"u}tz Digital} Project}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {81--82},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

@inproceedings{Hild_2016,
 abstract = {This essay describes the development process and encoding scheme of mono:di, the MEI-based, music-notation software program of \textit{Corpus monodicum}. \textit{Corpus monodicum} is a scholarly edition of the Latin-texted, medieval monophonic repertories -- both sacred and secular -- that form the historical foundation of European music, but have thus far been under-represented in musicological scholarship. The editorial project is spon-sored by the Akademie der Wissenschaften und der Literatur, Mainz, as part of the Akademienprogramm der Union der deutschen Akademien der Wissenschaften; it is housed at the Institut f{\"u}r Musikforschung, Universit{\"a}t W{\"u}rzburg.
    Mono:di was developed in conjunction with the music typesetting firm notengrafik berlin in order to facilitate the production of \textit{Corpus monodicum}'s publications, which will include both a series of 25 printed volumes and a digital edition (CM digital). Mono:di offers the project's editors a means of creating digital transcriptions in a direct and efficient way. The software also allows for an unproblematic transfer of editorial material to the typesetters who produce the analogue editions. Moreover, mono:di allows the same encoded material to serve as the basis both for the printed volumes and for the digital edition. This paper examines the editorial practices that shaped mono:di's development and the specific adaptations that were made to the MEI neumes module in mono:di's encoding scheme.},
 author = {Hild, Elaine and Weber, Thomas},
 title = {{Developing Encoding and Software Solutions: For the Digital and Analogue Publication of Medieval Monophonic Music}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {83--90},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

@inproceedings{Lewis_2016,
 abstract = {In this panel, we present a number of approaches to the creation of music corpora, using manual and fully- and partially-automated methods, and we consider the effects these approaches have on the nature, size and data encoding of the respective collections We also explore how the process is affected by the nature of the source materials used. We illustrate the impact of these approaches for later use, such as simple web or paper publication or searching and analyzing the newly-available musical information.},
 author = {Lewis, David and Wiering, Frans},
 title = {{Practicalities of Corpus Building: Creating and Exploring Digital Data}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {91--117},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

@inproceedings{Byrd_2016,
 abstract = {Arguably the most significant work to date on integrating content-based music retrieval with high-quality Western music notation is some 12 years old: it is implemented in my Nightingale program for the Macintosh computer. I describe how MEI-encoded scores can be converted into a form Nightingale can open, and discuss some of Nightingale's music-searching features.},
 author = {Byrd, Donald},
 title = {{High-Quality Notation: To Display and Search Music Encoded in MEI}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {118--121},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

@inproceedings{TeichGeertinger_2016,
 abstract = {The poster is intended to demonstrate that the MEI (Music Encoding Initiative) metadata section allows the description of musical works, including their history and sources, in such detail that it can serve as the basis for entire thematic catalogues or to collect source information for use with scholarly editions of music.The Danish Centre for Music Publication (DCM) is developing a web-based tool to facilitate capturing, editing, storing, and reviewing music metadata, called MerMEId (Metadata Editor and Repository for MEI Data). The main focus of the poster is to present the software including its architecture and user interface. The poster also outlines the results so far.},
 author = {{Teich Geertinger}, Axel and Lundberg, Sigfrid},
 title = {{MerMEId: Creating Thematic Catalogues Using MEI Metadata}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {122--126},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

@inproceedings{Meier_2016,
 abstract = {We present an approach that uses \textit{human computation} and \textit{crowdsourcing} principles for encoding large amounts of monophonic, handwritten sheet music.},
 author = {Meier, Florian and Burghardt, Manuel and Bazo, Alexander and Wolff, Christian},
 title = {{A Crowdsourced Encoding Approach for Handwritten Sheet Music}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {127--130},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

@inproceedings{Besson_2016,
 abstract = {Consortium "Musica" combines several units and research teams around a common theme -- the development and exploitation of digital music -- using common standards and supporting the dissemination of good practices and supports the conversion of information into digital form. The Consortium is accredited by the TGIR (Very High Research Infrastructure) Huma-Num aimed at facilitating digital turning points in humanities and social science research.},
 author = {Besson, Vincent},
 title = {{Musica: A Musical \textit{Consortium} of Digital Humanities}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {131--133},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2013},
 displayby = {Contributions from MEC 2013}
}

%%% ------------------------------------------------------
%%% MEC 2013 and 2014 Proceedings: Contributions from 2014

@inproceedings{Pugin_2016,
 abstract = {The Music Encoding Initiative defines the specifications of encoding music in XML format. While MEI is extremely powerful and promising, very few tools exist for rendering it directly into graphical music notation. Most of the solutions currently used require an intermediate step to convert it into a format that can then be processed by one existing music typesetter. This approach has the disadvantage of being complex, often slow, and needing to rely on other tools for the task, whilst losing some of MEI's features in the conversion process. Verovio is an attempt to solve this issue: it is a portable, small and fast library that is capable of interpreting MEI directly to SVG music output, without intermediate steps. Its development focuses on compatibility with the MEI specification and also on making portable code that is easily employed in different environments, from rendering of small-scale incipit to rendering long multi-page scores. The paper presents some use-case scenarios for the Verovio library.},
 author = {Pugin, Laurent and Zitellini, Rodolfo},
 title = {{Verovio: A Library for Typesetting MEI}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {136--141},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2014},
 displayby = {Contributions from MEC 2014}
}

@inproceedings{Beer_2016,
 abstract = {This paper presents the final status of the MEI Score Editor (MEISE) by the end of the first funding phase of DARIAH-DE in February 2014, by presenting exemplary use cases facilitating MEISE in different research projects. Experiences done by these projects build the basis for future improvements and developments of MEISE during the second funding phase of DARIAH-DE, starting in March 2014. Beside the disposal of current technical boundaries the ongoing development will then focus on understanding MEI encoding principles arising from the field of scholarly edition as encoded non-verbal annotations and its visualization.},
 author = {Beer, Nikolaos and Hartwig, Maja and Herold, Kristin},
 title = {{The MEI Score Editor: Use Cases and Future Perspectives}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {142--146},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2014},
 displayby = {Contributions from MEC 2014}
}

@inproceedings{Bemman_2016,
 abstract = {In recent years, a significant body of research has focused on developing algorithms for computing analyses of musical works automatically from encodings of these works' surfaces [3,4,7,10,11]. The quality of the output of such analysis algorithms is typically evaluated by comparing it with a "ground truth" analysis of the same music produced by a human expert (see, in particular, [5]).

 In this paper, we explore the problem of generating an encoding of the musical surface of a work automatically from a systematic encoding of an analysis. The ability to do this depends on one having an effective (i.e., computable), correct and complete description of some aspect of the structure of the music. Generating the surface structure of a piece from an analysis in this manner serves as a proof of the analysis' correctness, effectiveness and completeness.

 We present a reductive analysis of \textit{Sheer Pluck} (1984), a twelve-tone composition for guitar by Milton Babbitt (1916--2011). This analysis focuses on the all-partition array structure on which the piece is based. Having presented this analysis, we formalize some constraints on the structure of the piece and explore some computational difficulties in automating the generation of the all-partition array structure},
 author = {Bemman, Brian M. and Meredith, David},
 title = {{From Analysis to Surface: Generating the Surface of Milton Babbitt's \textit{Sheer Pluck} from a Parsimonious Encoding of an Analysis of its Pitch Class Structure}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {147--152},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2014},
 displayby = {Contributions from MEC 2014}
}

@inproceedings{Kjellberg_2016,
 abstract = {The \textit{best text method} is commonly applied among music scholars engaged in producing critical editions. In this method, a comment list is compiled, consisting of variant readings and editorial emendations. This list is maintained by inserting the comments into a document as the changes are made. Since the comments are not input sequentially, with regard to position, but in arbitrary order, this list must be sorted by copy/pasting the rows into place -- an error-prone and time-consuming process. Scholars who produce critical editions typically use off -the-shelf music notation software such as Sibelius or Finale. It was hypothesized that it would be possible to develop a Sibelius plug-in, written in Manuscript 6, that would improve the critical editing work fl ow, but it was found that the capabilities of this scripting language were insufficient. Instead, a 3-part system was designed and built, consisting of a Sibelius plug-in, a cross-platform application, called CriticalEd, and a REST-based solution, which handles data storage/retrieval. A prototype has been tested at the Danish Centre for Music Publication, and the results suggest that the system could greatly improve the efficiency of the critical editing work flow.},
 author = {Kjellberg, Caspar M. and {Teich Geertinger}, Axel and Lundberg, Sigfrid and Meredith, David},
 title = {{CriticalEd: A Tool for Assisting with the Creation of Critical Commentaries}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {153--158},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2014},
 displayby = {Contributions from MEC 2014}
}

@inproceedings{Shanahan_2016a,
 abstract = {This study discusses the nature of stylistic change through the examination of more than 27,500 incipits taken from the R{\'e}pertoire International des Sources Musicales (RISM) project. It re-examines the hypotheses set forth by both Morrow [6] that Germanic melodic composition began to become more differentiated in the 1760s and 1770s, as the Italianate style began to be less associated with "serious" music by German critics. Daniele and Patel [2] used the Barlow and Morgenstern dataset [1] to examine this from a computational perspective, and this paper seeks to replicate these findings with the much larger RISM corpus.},
 author = {Shanahan, Daniel and Bell, Eamonn},
 title = {{Re-Examining National Influences and Stylistic Shifts with the RISM Dataset}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {159--161},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2014},
 displayby = {Contributions from MEC 2014}
}

@inproceedings{Kepper_2016,
 abstract = {In music, scholarly editing has a tradition of more than 160 years. The Bach Gesamtausgabe (BGA), published between 1851 and 1904, was the first complete works edition committed to scholarly principles. While other editions followed their example quite soon, the BGA was always one of the most advanced editions, continuously refining both the concepts and the techniques of scholarly editing. With very few exceptions, all printed scholarly editions up to now conform to the general model established by the BGA. In order to understand our current situation on the verge of digital editions, it is helpful to recall the situation in the second half of the 19th century, which in many ways is quite similar to ours.},
 author = {Kepper, Johannes},
 title = {{The Impact of the Digital: How Digital Editions Will Change Editing Itself, and What Can Be Learned From the History of Editing}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {162--167},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2014},
 displayby = {Contributions from MEC 2014}
}

@inproceedings{Shanahan_2016b,
 abstract = {When examining possible geographical effects in music, one must be vigilant of a number of possible confounds presented by the datasets that are currently available. Some provide a great deal of data, but are often limited in geographic scope, and the provenance of the transcriptions is in doubt. Additionally, composition dates are sometimes apocryphal, and can span centuries. Ideally, a dataset would allow researchers to examine folksongs from a large geographic area in a way that would minimize these issues, as well as other issues. This paper presents the completion of the encoding of the collected transcriptions of Frances Densmore's fieldwork on Native American groups in North America. This dataset, known as the Densmore Collection, is now available in the Humdrum, MusicXML, and MEI formats, and will ideally facilitate research in the fields of musical style change, music and language, and the transmission of folk songs, as well as broader anthropological topics.},
 author = {Shanahan, Daniel and Shanahan, Eva},
 title = {{Revisiting the Densmore Collection: Completing a Collection of Native American Transcriptions}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {168--171},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2014},
 displayby = {Contributions from MEC 2014}
}

@inproceedings{Viglianti_2016b,
 abstract = {This paper introduces \textit{MEItoVexFlow}, a JavaScript library that parses and renders Common Music Notation (CMN) in the browser using HTML5 technologies. After a first prototype, the library has been extended over a three month project supported by the Google Summer of Code programme. It is currently being integrated into a number of research projects. After introducing the tool and its features, we discuss the challenges of creating a generic MEI rendering tool and how One Document Does-it-all (ODD), a literate programming format for generating documentation and schemata (see Viglianti [4] and Hankinson \textit{et al.} [1]), can define an application profile.},
 author = {Viglianti, Raffaele and KÅ‘m{\'i}ves, Zolt{\'a}n and Lewis, Richard},
 title = {{Rendering MEI in the Browser: \textit{MEItoVexFlow} and Application Profiling}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {172--175},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2014},
 displayby = {Contributions from MEC 2014}
}

@inproceedings{Viglianti_2016c,
 abstract = {Addressing music notation segments is central to many kinds of musicological discourse; references vary in scope and precision, such as "the measures two and three" or a more generic "the timpani in the opening bars of the Overture". Prompted the growing number of digitized music scores, this paper seeks to answer such questions as (1) how can one virtually 'circle' music notation? and (2) how can a machine interpret this 'circling' to retrieve music notation?},
 author = {Viglianti, Raffaele},
 title = {{Music Notation Addressability}},
 url_URN = {https://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 pages = {176--178},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {Roland, Perry and Kepper, Johannes},
 booktitle = {{Music Encoding Conference Proceedings 2013 and 2014}},
 year = {2016},
 keywords = {mec-proceedings, mec-proceedings-2014},
 displayby = {Contributions from MEC 2014}
}





%%% ------------------------------------------------
%%% MEC 2015, 2016 and 2017 Proceedings: Full volume

@proceedings{DiBacco_2019a,
 abstract = {Conference proceedings of the Music Encoding Conferences 2015, 2016 and 2017 with Introduction by Giuliano Di Bacco},
 year = {2019},
 title = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 url = {https://www.musiconn.de/metaopac/search?id=BV045900855&View=mus},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 doi = {10.15463/music-1},
 bibbase_note = {<span style="color: green; font-weight: bold">Full volume.</span>},
 keywords = {mec-proceedings, mec-proceedings-2015, mec-proceedings-2016, mec-proceedings-2017},
 displayby = {Common part MEC 2015--2017}
}

%%% -------------------------------------------------
%%% MEC 2015, 2016 and 2017 Proceedings: Introduction

@inproceedings{DiBacco_2019b,
 abstract = {Introduction of the Music Encoding Conference 2015, 2016 and 2017 proceedings.},
 author = {{Di Bacco}, Giuliano},
 title = {{Introduction}},
 pages = {1--3},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2015, mec-proceedings-2016, mec-proceedings-2017},
 displayby = {Common part MEC 2015--2017}
}

%%% ---------------------------------------------------------------
%%% MEC 2015, 2016 and 2017 Proceedings: Contributions from MEC 2015

@inproceedings{Dubowy_2019,
 abstract = {The \textit{Digital Mozart Edition} (DME) has as its goal the digital presentation of documents and texts related to Mozart's life and oeuvre. The most challenging project within the DME is the digital edition of Mozart's music which is currently being developed. It will eventually make the complete compositional output of Mozart available to the public in critical, MEI based editions. The DME already hosts the \textit{NMA Online}, the representation in digital images of the \textit{Neue Mozart Ausgabe} (NMA) print edition, originally published between 1954 and 2007. While on the one hand, the DME seeks to transform the authoritative musical text of the NMA into digital format, the DME also intends to broaden the philological concept by the publication of new and alternative editions based on individual sources. At the present state of the project, several challenges have been identified, some connected to the publication history and the availability of sources used by the NMA. Others are related to the representation of the \textit{Kritische Berichte} of the NMA within the DME. The paper reports on the development of the conceptual as well as practical model of the DME music edition.},
 author = {Dubowy, Norbert},
 title = {{Encoding the NMA in the Digital Mozart Edition: A Progress Report}},
 pages = {7--13},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2015},
 displayby = {Contributions from MEC 2015}
}

@inproceedings{Stinson_2019,
 abstract = {This paper illustrates opportunities for revising the current Chant and Mensural modules of the Music Encoding Initiative for encoding music notation from before c.1500. Repurposing data collected over the last three decades in Scribe music encoding software required a bespoke MEI module, which we have called NeoScribe. The Scribe project has benefited from the long-term investigation and implementation of methods for the efficient encoding of late medieval music notation. With Scribe, users are able to represent every meaningful scribal mark on the written page, something that is not currently possible in the current MEI Chant and Mensural modules. In converting Scribe data to a MEI-compliant XML, we recognised the need to retain Scribe's nuance-rich encoding of medieval musical notation. For zero dataloss, new elements and data types were added to MEI for encoding late medieval chant and mensural notation. We demonstrate some of NeoScribe's enhanced features for encoding 14th-century repertoires. We conclude by discussing some of the benefits of revising the MEI Chant and Mensural modules for projects investigating music from before c.1500.},
 author = {Stinson, John A. and Stoessel, Jason},
 title = {{Revising MEI for Research on late Medieval Manuscripts}},
 pages = {15--24},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2015},
 displayby = {Contributions from MEC 2015}
}

@inproceedings{DiBacco_2019c,
 abstract = {This paper stems from the project of redevelopment of the \textit{Thesaurus Musicarum Latinarum} (TML), the online searchable archive of early music treatises in Latin. Over 25 years after the project's inception, work is in progress to enrich the large corpus of plain-text files by encoding them with TEI, to improve the resource's fruition and the discoverability of the text. Over that background, a quite more difficult challenge emerges: to make also discoverable the large quantity of notated examples found interleaved with the verbal text of the treatises. It was not in the original intent to make music notation systematically searchable, but attempts were made to capture some facets of mensura notation through a code specifically designed for the project. The aim of this paper is both to discuss these earlier encoding attempts, with their shortcomings, and to propose our customization of MEI as a possible starting point to expand the current specifications. This is proving useful in the present state of the project: more work will be necessary to take care of other mensural features and flavors, and of course of chant and non-mensural notations, but MEI is proving apt to the job. The TML provides an ideal benchmark for developing a more specialized model of markup that will be useful for many other scholarly purposes. (The transcript below reflects the status of the TML project and of MEI at the time of the conference.)},
 author = {{Di Bacco}, Giuliano and Roland, Perry},
 title = {{MEI for Mensural Notation in the Thesaurus Musicarum Latinarum}},
 pages = {25--35},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2015},
 displayby = {Contributions from MEC 2015}
}

@inproceedings{Saenger_2019,
 abstract = {This paper describes a model for genetic criticism in MEI, which takes slightly different approaches than the corresponding module in TEI.},
 author = {S{\"a}nger, Richard and Kepper, Johannes},
 title = {{Encoding Genetical Processes}},
 pages = {37--44},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2015},
 displayby = {Contributions from MEC 2015}
}

@inproceedings{Horwitz_2019,
 abstract = {This paper presents a web-based XML editor tailored for use with MEI. This editor provides an interface for synchronizing text edits with changes from a graphical editor. While initially developed to facilitate editing the results of optical music recognition, the editor is built to interface with other graphical editors. Various features such as loading multiple files at the same time, saving to the user's computer, and validation are also built in.},
 author = {Horwitz, Andrew and Hankinson, Andrew and Fujinaga, Ichiro},
 title = {{A Browser-Based MEI Editor}},
 pages = {45--46},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2015},
 displayby = {Contributions from MEC 2015}
}

@inproceedings{Viglianti_2019,
 abstract = {Enhancing Music Notation Addressability (EMA) is a one-year project that investigates methods for addressing arbitrary portions of encoded music notation on the web. By "addressing" we mean being able to refer to, or cite, a passage of music in order to make a statement about it. This could be considered a virtual equivalent of "circling" some music notation on a printed score. The technical specification created by the EMA project are described below. The specification aims at defining a scheme for addressing a selection of music notation regardless of its representation. The expression is based on simple units that are commonly represented by music notation systems for common Western music notation, such as measure, staff, and beat. The expression is formulated as a URL, which makes it possible to target resources on the web.},
 author = {Viglianti, Raffaele},
 title = {{A Specification for Addressing Encoded Music on the Web}},
 pages = {47--49},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2015},
 displayby = {Contributions from MEC 2015}
}

%%% ----------------------------------------------------------------
%%% MEC 2015, 2016 and 2017 Proceedings: Contributions from MEC 2016

@inproceedings{Kraemer_2019,
 abstract = {Computational Music Analysis Platforms (or CMAPs for short) in general parse music data and transcode the data to an internal format in order to process the acquired data. We call the internal format an intermediate format, because it acts within a software architecture as an intermediary between input and output of a given CMAP's workflow. The paper examines three different types of intermediate formats, one historical, and two currently in use, as they occur in CMAPs, and posits how these intermediate formats influence the analytical process and thought.},
 author = {Kr{\"a}mer, Reiner},
 title = {{On Intermediate Formats}},
 pages = {53--61},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2016},
 displayby = {Contributions from MEC 2016}
}

@inproceedings{Shaw_2019,
 abstract = {The \textit{Wolfenb{\"u}ttel Lute Tablature} (c. 1460) consists of two fragmented folios with intabulations for five secular songs and is the only extant source of a notation system described theoretically in \textit{Kassel Lautenkragen}. The notation, named the Kassel-Wolfenb{\"u}ttel Tablature System (KWTS) by Marc Lewon, combines a quasi- mensural notation, which closely resembles the upper voice of organ tablature, and an alphabetic notation, parallel to organ tablature. Because of its connections to both tablature and mensural notations, in order to encode KWTS, one must combine the encoding systems for both tablature and mensural notation. In this paper, I examine some of the problems inherent in encoding KWTS; suggest possible solutions; and define a musicological application for the project. As the earliest lute-specific notation, KWTS contains valuable information on the changing lute performance practices of the mid-fifteenth century, despite the sources' brevity. Developing an encoding system for this notation will enable further exploration of fifteenth-century lute repertoire, including that prior to lute-specific notation.},
 author = {Shaw, Rebecca A.},
 title = {{The Kassel-Wolfenb{\"u}ttel Tablature System: A Convergence of Lute Tablature and Mensural Notation}},
 pages = {63--71},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2016},
 displayby = {Contributions from MEC 2016}
}

@inproceedings{Swanson_2019,
 abstract = {Entering metadata for medieval chants in the Cantus Database often poses challenges for the indexer. Although many of the chants follow the standard, expected forms, some items are difficult to classify. For example, certain melodies do not conform to the standard modes and some chants are unique in their usage for a particular day or service within the liturgical year. Although it is easy to create new classification tags, the prudent database manager exercises caution, as the modern need to categorize does not always conform to medieval custom. By focusing on chants from Holy Week including the \textit{Exsultet}, \textit{Improperia} and \textit{Trisagion}, this paper addresses the various criteria used to create two new genre codes, "Varia" (Va) and "Holy Week Varia" (VaHW). Although these classifiers provide less specificity than other possible options, they avoid over-interpretation, are easy-to-use by novice indexers, and usefully differentiate the unique chants of Holy Week from other chant miscellany.},
 author = {Swanson, Barbara and Lacoste, Debra},
 title = {{Chants That Defy Classification: Implications of Categorization in the Cantus Database}},
 pages = {73--78},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2016},
 displayby = {Contributions from MEC 2016}
}

@inproceedings{Seipelt_2019,
 abstract = {The first performance of Weber's \textit{Freisch{\"u}tz} in Vienna took place November 3rd, 1822. A manuscript copy was bought from Weber, which closely followed the composer's autograph. But a close look to the manuscript reveals a great number of performance-related modifications of both the musical and textual content. These transformations have mostly been major ones, like deletions of whole measures or text passages, and insertions of new pages. On the basis of the BMBF-sponsored project "Freisch{\"u}tz Digital" (Digital edition of the \textit{Freisch{\"u}tz}, hereafter "FreiDi"), this paper tries to develop a way to describe the textual and physical modifications of the manuscript not only verbally but in a semantic, i.e. logic, encoding, based on MEI. For this, the paper explores possible modifications of MEI elements, or the creation of new elements and attributes for the special problems. It will explore the usefulness of markup from other projects, most importantly the \textit{Beethoven Werkstatt} project with its genetic encodings. It will also discuss the possibilities, problems and limitations of the different solutions.},
 author = {Seipelt, Agnes},
 title = {{The Freisch{\"u}tz Performance in Vienna: Encoded Representation of Performance-Related Modifications of the Score}},
 pages = {79--90},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2016},
 displayby = {Contributions from MEC 2016}
}

@inproceedings{Berndt_2019,
 abstract = {This paper introduces the Music Performance Markup format for encoding expressive performance parameters. The main focus is the general data organization in global vs. local data and header vs. dated data, illustrated by some musical examples. Moreover future work and use cases are envisioned.},
 author = {Berndt, Axel and Bohl, Benjamin W.},
 title = {{XML Music Performance Description: Reflections on and Future Developments of the Music Performance Markup Format}},
 pages = {91--94},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2016},
 displayby = {Contributions from MEC 2016}
}

@inproceedings{Kepper_2019,
 abstract = {The Freisch{\"u}tz Digital project (FreiDi) was one of the pioneer projects employing MEI in large scale. It did not only try to encode a huge quantity of music material, it also sought to capture as many aspects of the available sources as possible, effectively creating data of almost unrivaled richness. This paper discusses the outcomes of and experiences made in the FreiDi project.},
 author = {Kepper, Johannes},
 title = {{\textit{Wie? Was? Entsetzen!} Lessons Learned from the Freisch{\"u}tz Digital Project}},
 pages = {95--105},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2016},
 displayby = {Contributions from MEC 2016}
}

@inproceedings{DeLaHunt_2019,
 abstract = {Our heritage of music scores need to be delivered in 21st century packaging: the symbolic, digital score, instead of the paper-printed book. This will enable better music-making, but also new tools for using digital scores. The digital score plus the new tools will enable dramatically better music-making. Thus it is important to create a corpus of digital scores for the works in our musical heritage. A gap analysis shows that what is missing is an organization which mobilises participation and produces results, and which provides content in symbolic, digital score form, and freely licensed. Such an organization has recently begun operations: the Keyboard Philharmonic project.},
 author = {DeLaHunt, Jim},
 title = {{All Classical Music, Freely Available As Revisable Digital Scores, Via Crowdsourcing}},
 pages = {107--110},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2016},
 displayby = {Contributions from MEC 2016}
}

%%% ----------------------------------------------------------------
%%% MEC 2015, 2016 and 2017 Proceedings: Contributions from MEC 2017

@inproceedings{Lewis_2019,
 abstract = {As the number of music corpora published online increases, with many of these containing symbolic music encodings, the importance of search activities is also growing. Although it is seldom explicitly recognised as such, the act of querying these corpora is a form of research activity. Despite this, no common standards have emerged for preserving and disseminating these activities, or their results and provenance. In this paper, we discuss two examples of current search tasks -- each with a musicological motivation -- and consider what information might be preserved and communicated, and why. Capturing the method of a search, the timing of the query and the motivation for the investigation may be as important as preserving results. We show a preliminary Linked Data implementation, and consider how it can support visualisation of the results and evaluation of the methods},
 author = {Lewis, David and Page, Kevin and Hankinson, Andrew},
 title = {{Capturing Context and Provenance of Musicology Research}},
 pages = {113--118},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2017},
 displayby = {Contributions from MEC 2017}
}

@inproceedings{Plaksin_2019,
 abstract = {This paper outlines an encoding workflow for a critical edition of Ottoman music manuscripts based on the MEI schema. The encoding workflow is one aspect of a larger digital edition project entitled Corpus Musicae Ottomanicae (CMO). The paper gives a brief introduction to CMO, its scholarly goals and digital infrastructure. It offers some basic information on Ottoman music, focusing on the scholarly transcription into staff notation of manuscript sources written in Hampartsum notation. We discuss the modelling of metadata according to FRBR and MEI, and the challenges involved in adapting the source material to schema that were developed with different musical concepts and practices as their model. We describe the workarounds, tools and procedures we developed to encode Ottoman music in a way that meets both visual and semantic demands, and reflects musical as well as philological aspects of the sources. These solutions are offered as a possible first step towards integrating non-Western musical repertoires and sources into the MEI schema.},
 author = {Plaksin, Anna and Olley, Jacob},
 title = {{Creating an Encoding Workflow for a Critical Edition of Ottoman Music Manuscripts: Challenges and Solutions}},
 pages = {119--130},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2017},
 displayby = {Contributions from MEC 2017}
}

@inproceedings{Schueler_2019,
 abstract = {This paper summarizes the development of computing technology from the 1940s through the 1980s and draws parallels to its influence on the development of music encoding and music-analytical methods. The emphasis on how the developments of computing and computers influenced the development of computer-assisted music analysis (and, thus, various representations) is related to the fact that this knowledge is often absent in contemporary discussions of music encoding and of computer applications in music analysis.},
 author = {Sch{\"u}ler, Nico},
 title = {{The Development of Computing Technology and Its Influence on Music-Analytical Methods and Encoding: 1940s through 1980s}},
 pages = {131--133},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2017},
 displayby = {Contributions from MEC 2017}
}

@inproceedings{Voigt_2019,
 abstract = {This paper discusses the implementation of an infrastructure for LilyPond that allows import and export of different file formats, to connect LilyPond with the rest of the music-engraving world and make it a valuable chain link in a multi format environment.},
 author = {Voigt, Jan-Peter},
 title = {{Creating an Import and Export Infrastructure for LilyPond}},
 pages = {135--141},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2017},
 displayby = {Contributions from MEC 2017}
}

@inproceedings{Harrison_2019,
 abstract = {In this paper we offer a new corpus and a new method for how to consider musical style from a sociological perspective, by looking at the phenomenon of \textit{debussysme} in early 20th-century France. We focused on the solo piano scores of the "Apaches" subset of potential \textit{debussystes}, comparing them to a randomly selected control group of their peers. Due to the challenge of manually correcting these complex scores, we experimented with leaving the errors generated during the OMR process uncorrected in our MEI files, planning to correct them progressively in later stages of hypothesis testing. We then validated the error level and successfully analyzed nearly all of the scores for parallel 5ths and meter changes using customized MEI search programs. Even when taking the estimated error levels into account, a statistically significant difference was discovered between the Apaches and control groups. In addition to presenting these initial findings, our description of the methodological challenges of encoding and analyzing these complex scores might serve as a model for how to deploy a multi-hypothesis corpus study involving difficult scores over several, more manageable steps.},
 author = {Harrison, Jane and Khalid, Farhan},
 title = {{Introducing a Corpus of French Compositions for Exploring Social Interaction and Musical Change}},
 pages = {143--150},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2017},
 displayby = {Contributions from MEC 2017}
}

@inproceedings{Chen_2019,
 abstract = {We wish to introduce a toolbox that transforms handwritten mensural notation as found in 16th-century music manuscripts into modern music notation. To the best of our knowledge, this is the first such toolbox that can deal with the whole pipeline from symbol recognition to transcription. Along with the toolbox, we present our solution to the problem of ligature recognition, transcription, and encoding, which has remained an obstacle in previous mensural Optical Music Recognition (OMR) systems. We propose a visual encoding method as a reference to recognize and describe ligatures, then transform them to modern notation according to the time signature. Given an image as input, our toolbox recognizes the contents, transcribes them into modern musical notation, and encodes the result in a MusicXML file, with MEI support under development. Availability of the encoding enables further processing with third party tools.},
 author = {Chen, Xuanli and Huang, Yu-Hui and Beck, Serafina and Timofte, Radu and Burn, David and {van Gool}, Luc},
 title = {{TAMIR: A Toolbox for Recognition and Transcription of Music Manuscripts in Mensural Notation}},
 pages = {151--152},
 publisher = {{Bavarian State Library (BSB)}},
 editor = {{Di Bacco}, Giuliano and Kepper, Johannes and Roland, Perry},
 booktitle = {{Music Encoding Conference Proceedings 2015, 2016 and 2017}},
 year = {2019},
 doi = {10.15463/music-1},
 keywords = {mec-proceedings, mec-proceedings-2017},
 displayby = {Contributions from MEC 2017}
}

%%% -------------------------------------
%%% MEC 2020 Proceedings: Full volume

@proceedings{DeLuca_2020,
 abstract = {Conference proceedings of the Music Encoding Conference 2020 with Foreword by Richard Freedman and Anna J. Kijas},
 year = {2020},
 title = {{Music Encoding Conference Proceedings 2020}},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 doi = {10.17613/mvxw-x477},
 bibbase_note = {<span style="color: green; font-weight: bold">Full volume.</span>},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Common part MEC 2020}
}

%%% ------------------------------
%%% MEC 2020 Proceedings: Foreword

@inproceedings{Freedman_2020,
 abstract = {Foreword of the Music Encoding Conference 2020 proceedings.},
 author = {Freedman, Richard and Kijas, Anna J.},
 title = {{Foreword}},
 pages = {1},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Common part MEC 2020}
}

%%% -------------------------------
%%% MEC 2020 Proceedings: Keynote I

@inproceedings{Duguid_2020,
 abstract = {Digital methods have begun to make their way into the research practices of music scholars, and most this insurgence can be attributed to the rise of the discipline of music technology. Though music encoding is becoming increasingly prevalent among the research and teaching methodologies of music scholars, evidence gathered from course descriptions and presentations at national meetings of music scholars would indicate that encoding continues to lag other music-based technologies. Drawing from the advancement of music technology and the experiences of digital humanities teaching and scholarship, this paper presents a path for the music encoding community to promote greater integration of encoding and digital methods more broadly into the pedagogical practices of music historians and music theorists.},
 author = {Duguid, Timothy},
 title = {{The Forgotten Classroom? Bringing Music Encoding to a New Generation}},
 pages = {3--14},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/fbqn-s474},
 bibbase_note = {<span style="color: green; font-weight: bold">Keynote I.</span>},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

%%% ------------------------------
%%% MEC 2020 Proceedings: Articles

@inproceedings{Regimbal_2020,
 abstract = {In this paper we introduce a set of improvements to Neon, an online square-notation music editor based on the International Image Interoperability Framework (IIIF) and the Music Encoding Initiative (MEI) file format. The enhancements extend the functionality of Neon to the editing of lyrics and single-session editing of entire manuscripts and lyric editing. We describe a scheme for managing and processing the information necessary for visualizing and editing full manuscripts. A method of concurrently editing the position and content of lyrics is also discussed. We expect these will provide a better user experience when correcting the output of automated optical music recognition workflows},
 author = {Regimbal, Juliette and Vigliensoni, Gabriel and Hutnyk, Caitlin and Fujinaga, Ichiro},
 title = {{IIIF-Based Lyric and Neume Editor for Square-Notation Manuscripts}},
 pages = {15--18},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/d41w-n008},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{Thomae_2020,
 abstract = {In this paper, we apply machine translation techniques to solve one of the central problems in the field of optical music recognition: extracting the semantics of a sequence of music characters. So far, this problem has been approached through heuristics and grammars, which are not generalizable solutions. We borrowed the seq2seq model and the attention mechanism from machine translation to address this issue. Given its example-based learning, the model proposed is meant to apply to different notations provided there is enough training data. The model was tested on the PrIMuS dataset of common Western music notation incipits. Its performance was satisfactory for the vast majority of examples, flawlessly extracting the musical meaning of 85% of the incipits in the test set -- mapping correctly series of accidentals into key signatures, pairs of digits into time signatures, combinations of digits and rests into multi-measure rests, detecting implicit accidentals, etc.},
 author = {Thomae, Martha E. and R{\'i}os-Vila, Antonio and Calvo-Zaragoza, Jorge and Rizo, David and I{\~n}esta, Jos{\'e} M.},
 title = {{Retrieving Music Semantics from Optical Music Recognition by Machine Translation}},
 pages = {19--24},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/605z-nt78},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{Ricciardi_2020,
 abstract = {Despite the interdisciplinary nature of the Italian madrigal -- a genre in which poetry and music often stand on equal footing -- critical editions of this repertoire tend to focus primarily on the \textit{musical} text, devoting limited attention to the often-complex philological tradition of the poems set to music. Likewise, most critical editions are devoted to the works of a single composer -- as opposed to settings of the same poetry by multiple composers -- and thus offer a rather segmented perspective on the repertoire, which is not conducive to the study of musical traditions and to comparative analysis. This paper proposes a new model for critical editions of this repertoire, one in which musical \textit{and} poetic texts are devoted equal attention. To do so, we will provide an overview of a digital project that follows this model, namely the Tasso in Music Project (www.tassomusic.org), showing how it draws on both musical (Humdrum, MEI) and textual (TEI) encoding systems to render the interdisciplinary nature of its repertoire.},
 author = {Ricciardi, Emiliano and Sapp, Craig Stuart},
 title = {{Editing Italian Madrigals in the Digital World: The Tasso in Music Project}},
 pages = {25--40},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/17a5-2b65},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{Pfeffer_2020,
 abstract = {In 1731, Johann Mattheson writes in the preface to the Gro{\ss}e Generalbass-Schule: "The complaint, however, which I made in the first edition of this Organisten-Probe about the badly printed notes, is still in its full strength, and patience is the only remedy." \textit{Probst{\"u}cke Digital} is an open and critical digital edition project of the 24 test pieces of the Ober-Classe ("upper class") by Johann Mattheson and as such an example for the use and application of MEI and TEI in an integrated environment. After almost 300 years it also seeks to finally give remedy to Mattheson's complaint by editing his Probst{\"u}cke and by providing perhaps a little more than merely "prettifying" the original print.},
 author = {Pfeffer, Niels and Rettinghaus, Klaus},
 title = {{Probst{\"u}cke Digital -- A Critical Digital Edition of Johann Mattheson's 24 Probst{\"u}cke of the Ober-Classe}},
 pages = {41--46},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/r8pk-6e15},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{Saccomano_2020,
 abstract = {While the increase in digital editions, online corpora, and browsable databases of encoded music presents an extraordinary resource for contemporary music scholarship, using these databases for computational research remains a complex endeavor. Although norms and standards have begun to emerge, and interoperability among different formats is often possible, researchers must devote considerable time to discover, learn, and maintain the skill sets necessary to make use of these resources. This talk will discuss our work with the Serge Prokofiev Archive and the creation of a prototype to browse, display, and play notated music from Prokofiev's notebooks via a web browser. The project is an example of how using the principles of minimal computing can reduce the burden of technological expertise required to both disseminate and access encoded music.},
 author = {Saccomano, Mark and Ermolaev, Natalia},
 title = {{MEI and Verovio for MIR: A Minimal Computing Approach}},
 pages = {47--50},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/9xav-q378},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{M.Weigl_2020,
 abstract = {MEI-encoded scores are versatile music information resources representing musical meaning within a finely addressable XML structure. The Verovio MEI engraver reflects the hierarchy and identifiers of these encodings into its generated SVG output, supporting presentation of digital scores as richly interactive Web applications. Typical MEI workflows initially involve scholarly or editorial activities to generate an encoding, followed by its subsequent publication and use. Further iterations may derive new encodings from precedents; but the suitability of MEI to interactive applications also offers more dynamic alternatives, in which the encoding provides a framework connecting data that is generated and consumed simultaneously in real-time. Exemplars include compositions which self-modify according to external contextual parameters, such as the current weather at time of performance, or which are assembled by user-imposed external semantics, such as a performer's explicit choices and implicit performative success at playing musical triggers within a composition. When captured, these external semantic signals (interlinked with the MEI structure) themselves encode the evolution of a dynamic score during a particular performance. They have value beyond the immediate performance context; when archived, they allow audiences to revisit and compare different performances.},
 author = {{M. Weigl}, David and Goebl, Werner},
 title = {{Rehearsal Encodings with a Social Life}},
 pages = {51--53},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/5ae5-8387},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{Lehrman_2020,
 abstract = {MIDI, the musical instrument digital interface, is a highly successful protocol for conveying and, through the use of Standard MIDI Files, representing musical performance information. However, it lacks the ability to convey notation information. The newly approved MIDI 2.0 protocol gives us a chance to rectify that by including notation information in the next version of the MIDI File Specification.},
 author = {Lehrman, Paul D.},
 title = {{MIDI 2.0: Promises and Challenges}},
 pages = {55--58},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/652c-4540},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{Herold_2020,
 abstract = {For musicologists, the collation of multiple sources of the same work is a frequent task. By comparing different witnesses, they seek to identify variation, describe dependencies, and ultimately understand the genesis and transmission of (musical) works. Obviously, the need for such comparison is independent from the medium in which a musical work is manifested. In computing, comparing files for difference is a common task, and the well-known Unix utility \textit{diff} is almost 46 years old. However, \textit{diff}, like many other such tools, operates on plain text. While many music encoding formats based on plain text exist, formats used in the field of Digital Humanities are typically based on XML. There are dedicated algorithms for comparing XML as well, but they only focus on the syntax of XML, but not the semantic structures modelled into such standards as MEI. MEI seeks to describe musical structures, and the XML syntax is just a means to express those structures. A diff tool for music should focus on comparing musical structures, but not the specifics of their serialization into a file format. In \textit{Beethovens Werkstatt}, a 16-year project focussed on exploring the concepts and requirements of digital genetic editions of music, based on and arguing with examples from Ludwig van Beethoven, a case-bound diff tool for music was developed. The following paper discusses how that specific tool can be generalized, and which use cases such a tool may support.},
 author = {Herold, Kristin and Kepper, Johannes and Mo, Ran and Seipelt, Agnes},
 title = {{MusicDiff -- A Diff Tool for MEI}},
 pages = {59--66},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/ydbv-e158},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{Obert_2020,
 abstract = {In my master thesis I am working on the analysis of scriptural problems, trying to discuss the chronology of Ludwig van Beethoven's entries in the autograph of his \textit{Flohlied} op. 75, no. 3. This is in order to examine the efficiency of the so-called \textit{VideApp} of the research project \textit{Beethovens Werkstatt} which studies sketches and manuscripts of Beethoven by combining methods of genetic criticism and digital edition.},
 author = {Obert, Salome},
 title = {{\textit{Beethovens Werkstatt} on the Test Bench}},
 pages = {67--70},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/j9rm-fa25},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{Ju_2020,
 abstract = {The computational study of figured bass remains an under-researched topic, likely due to the lack of machine- readable datasets. This paper is intended to address the paucity of digital figured bass data by 1) investigating procedures for systematically annotating symbolic music files with figured bass, and 2) producing and releasing a model annotated dataset as an illustration of how these procedures can be applied in practice. We introduce the Bach Chorales Figured Bass dataset, which includes 103 chorales composed by Johann Sebastian Bach that includes both the original music and figured bass annotations encoded in MusicXML, **kern, and MEI formats.},
 author = {Ju, Yaolong and Margot, Sylvain and McKay, Cory and Fujinaga, Ichiro},
 title = {{Figured Bass Encodings for Bach Chorales in Various Symbolic Formats: A Case Study}},
 pages = {71--73},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/hcbz-5702},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{Valk_2020,
 abstract = {In this progress report, we describe the issues encountered during the design and implementation of TabMEI, a new MEI module for encoding instrumental tablatures. We discuss the main challenges faced and lay out our workflow for implementing the TabMEI module. In addition, we present a number of example encodings, and we describe anticipated applications of the module.},
 author = {de Valk, Reinier and Lewis, David and Crawford, Tim and Ahmed, Ryaan and Pugin, Laurent and Kepper, Johannes},
 title = {{Crafting TabMEI, a Module for Encoding Instrumental Tablatures}},
 pages = {75--81},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/4f2k-fr26},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{NapolesLopez_2020,
 abstract = {High-quality annotations of harmonic analysis are scarce. Furthermore, the existing data usually follows different conventions for spelling scale degrees, inversions, and special chords (e.g., cadential six-four). There have been efforts for standardizing the notation of harmonic analysis annotations, however, these have not been very successful because: 1) there are few software tools able to parse such notations 2) as a consequence, researchers have not adopted the suggested notations and it is more frequent to find a different notation with every new dataset. We attempt to mitigate the limitations of existing notations through the definition of a new language for harmonic analysis, which we call \textit{harmalysis}. This language 1) provides a notation that adjusts as much as possible to the way in which researchers have annotated roman numerals in existing datasets, 2) formalizes the resulting notation into a consistent and extensible context-free grammar, 3) uses the context-free grammar to generate tools that are able to parse and validate annotations in the syntax of the language. We make the formal definition of the language, a context-free grammar described in the Extended Backus-Naur Form (EBNF), available as an open-source repository. Within the same repository, we make available tools for parsing annotations in the harmalysis language. The tools allow the users to extract high-level semantic information from their annotations (e.g., local key, root of the chord, inversion, added intervals, whether the chord is tonicizing another key or not, etc.) and to validate the correctness of a given annotation according to the grammar of the proposed language.},
 author = {{N{\'a}poles L{\'o}pez}, N{\'e}stor and Fujinaga, Ichiro},
 title = {{Harmalysis: A Language for the Annotation of Roman Numerals in Symbolic Music Representations}},
 pages = {83--85},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/380x-dd98},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{Plaksin_2020,
 abstract = {This paper reports on the task of developing concepts for a computational analysis of the transmission of mensural music based on concepts of phylogenetic analysis. Since the analysis of transmission aims for the reconstruction of relations between sources, it focuses on the differences of rather similar items. Therefore, it is necessary to find substitution models which are optimized for distinguishing fine levels of differences and to deal with the structural ambiguities and visual variance of mensural notation.},
 author = {Plaksin, Anna},
 title = {{Do Visual Features Matter? Studies in Phylogenetic Analysis of Mensural Music}},
 pages = {87--94},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/pzy7-ek18},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{Harding_2020,
 abstract = {The discrete Fourier transform is a mathematically robust way of modeling various musical phenomena. I use the music21 Python module to interpret the pitch classes of an encoded musical score through the discrete Fourier transform (DFT). This methodology offers a broad view of the backgrounded scales and pitch-class collections of a piece. I have selected two excerpts in which the composers are very frugal with their pitch class collections---one in a tonal idiom, the other atonal. These constrained vocabularies are well suited for introducing the DFT's methodological strengths as they pertain to score analysis.},
 author = {Harding, Jennifer Diane},
 title = {{Computer-Aided Analysis Across the Tonal Divide: Cross-Stylistic Applications of the Discrete Fourier Transform}},
 pages = {95--104},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/2n0b-1v04},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

%%% -----------------------------
%%% MEC 2020 Proceedings: Posters

@inproceedings{ParadaCabaleiro_2020,
 abstract = {Conversion issues across musical symbolic representations, such as musicXML, MEI, and humdrum, are well known. Often, these depend on methodological choices undertaken during the generation and processing of the data. For a better under-standing of this topic, we present a transcription protocol, result of trial and error transcription attempts performed with Finale engraving software, which aims to prevent conversion errors (Verovio 2.1.0 and VHV were taken into account for conversion) from musicXML (export format from Finale) to MEI and **kern (symbolic representations also evaluated).},
 author = {Parada-Cabaleiro, Emilia and Torrente, {\'A}lvaro},
 title = {{Preventing Conversion Failure across Encoding Formats: A Transcription Protocol and Representation Scheme Considerations [Poster]}},
 pages = {105--108},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/etwb-m434},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{Rettinghaus_2020,
 abstract = {The MEI Garage is a toolbox for various tasks related to MEI, but also other encoding formats. Besides the possibility to customize the MEI framework for specific needs, turning it into a reasonable format for a given purpose, one major aspect of the MEI Garage is that it provides easy-to-use conversions between MEI and a growing number of other music encoding formats, including MusicXML. This is possible through both a guided web interface and a REST API.},
 author = {Rettinghaus, Klaus and R{\"o}wenstrunk, Daniel and Kepper, Johannes},
 title = {{Integrating Score Rendition in the MEI Garage [Poster]}},
 pages = {109},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{Rashleigh_2020,
 abstract = {\textit{Furnace and Fugue} is both a digital edition of and scholarly essays on Michael Maier's \textit{Atalanta fugiens}, a 17th-century alchemical emblem book. Each of the book's 50 mutlilingual emblems includes a fugue for three voices, which represents the race between Atalanta and Hippomenes. The project modernized the polyphonic fugues into animated notation that is playable in a web browser.},
 author = {Rashleigh, Patrick and Brusch, Crystal},
 title = {{Multimedia from the 17th-Century Book to the 21st-Century Web: a Playable Digital Edition of Michael Maier's "Atalanta fugiens" [Poster]}},
 pages = {111--116},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/ggym-sc21},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{Kuo_2020,
 abstract = {The ability to "address" areas of a musical score is useful in music scholarship such as analysis and/or historical research. In this project, we implement software that enables us to "select" regions of MusicXML files, in accordance with the Enhancing Music Addressability (EMA) specification.},
 author = {Kuo, Kevin and Viglianti, Raffaele},
 title = {{Implementing the Enhancing Music Addressability API for MusicXML [Poster]}},
 pages = {117--120},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/n2nk-aa67},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

@inproceedings{Desmond_2020,
 abstract = {This poster presents an NEH-funded project to develop a prototype editor for encoding mensural notation (PI: Karen Desmond, Brandeis University). It builds on the Measuring Polyphony project (measuringpolyphony.org), a website that presents digitisations of polyphonic motets copied in late medieval manuscripts in mensural notation. Coding of the editor prototype began in January 2020, and a workshop directly before the 2020 Music Encoding Conference evaluated the prototype in terms of its interface and design, accessibility, and interoperability, and advised on a plan for the project's full implementation. This poster includes links to videos that outline the main functionality of the prototype and a summary of the project goals, impact, and next stages of edevelopment.},
 author = {Desmond, Karen and Hankinson, Andrew and Pugin, Laurent and Regimbal, Juliette and Sapp, Craig Stuart and Thomae, Martha E.},
 title = {{Next Steps for Measuring Polyphony -- A Prototype Editor for Encoding Mensural Music [Poster]}},
 pages = {121--124},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/5k88-9z02},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}

%%% --------------------------------
%%% MEC 2020 Proceedings: Keynote II

@inproceedings{Joubert_2020,
 abstract = {This paper employs a digital project entitled "Visualizing Operatic Fame" to delve into three major issues in graph theory and network science: searching and pathfinding, influencers and hubs, and clusters and communities.},
 author = {Joubert, Estelle},
 title = {{Traversing Eighteenth-Century Networks of Operatic Fame}},
 pages = {125--137},
 publisher = {{Humanities Commons}},
 editor = {{De Luca}, Elsa and Flanders, Julia},
 booktitle = {{Music Encoding Conference Proceedings 2020}},
 year = {2020},
 doi = {10.17613/6yhy-a027},
 bibbase_note = {<span style="color: green; font-weight: bold">Keynote II.</span>},
 keywords = {mec-proceedings, mec-proceedings-2020},
 displayby = {Contributions from MEC 2020}
}



%%% -------------------------------------
%%% MEC 2021 Proceedings: Full volume

@proceedings{Muennich-Rizo_2022a,
 abstract = {Conference proceedings of the Music Encoding Conference 2021 with Foreword by Stefan M{\"u}nnich and David Rizo.},
 year = {2022},
 title = {{Music Encoding Conference Proceedings 2021}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 doi = {10.17613/fc1c-mx52},
 bibbase_note = {<span style="color: green; font-weight: bold">Full volume.</span>},
 displayby = {Common part MEC 2021}
}

%%% ------------------------------
%%% MEC 2021 Proceedings: Foreword

@inproceedings{Muennich-Rizo_2022b,
 abstract = {Foreword of the Music Encoding Conference 2021 proceedings.},
 author = {M{\"u}nnich, Stefan and Rizo, David},
 title = {{Foreword}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {vii--viii},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/f1b1-zv67},
 displayby = {Common part MEC 2021}
}

%%% -------------------------------
%%% MEC 2021 Proceedings: Keynote I

@inproceedings{Torrente-LLorens_2022,
 abstract = {Musicology is a small discipline within the wide spectrum of human knowledge, yet it is already divided into various branches, each with its own societies, conferences, journals, jargons, degrees, prejudices, $\ldots$, and jobs. Although they share their object of investigation -- ``the art of music as a physical, psychological, aesthetic, and cultural phenomenon'' --, these branches very often ignore one another. Research in musicology is mostly a solitary task, as investigations, papers, and publications are commonly signed by single authors, in contrast with STEM disciplines where teamwork is the rule. This is in part the result of tradition -- the ``Musicological Toolbox'' -- but also the aftermath of the job market and financing programs.

Large funding schemes such as the European Research Council (ERC) grants are becoming a major disruptive factor in many disciplines in the humanities, including musicology. Scholars in all fields now have the opportunity to build research teams, and most of their members receive their salaries to exclusively work on the project. In other words, we are starting to build what could be called a Musicology Lab, learning along the way how teamwork is reshaping and transforming the Musicological Toolbox, the look and feel of our discipline, the way we work as well as the way we publish and disseminate our results.

This paper presents some of the key features of the ERC Didone project, one of its principal tasks being to create a digitally encoded corpus of some 3,000 arias in MusicXML format from about 180 musical settings of a small number of opera librettos by Pietro Metastasio. It focuses on some of the project's research tasks, emphasizing how the skills of a team of eighteen scholars with very different expertise -- historical musicology, music theory and analysis, cultural history, librettology, archival research, music performance, music engraving, MIR, computer science, and statistical modeling -- combine to explore the potential answer(s) to the main research question of the project: How are emotions expressed through music?},
 author = {Torrente, {\'A}lvaro and Llorens, Ana},
 title = {{The Musicology Lab: Teamwork and the Musicological Toolbox}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {9--20},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/kmjq-pb94},
 bibbase_note = {<span style="color: green; font-weight: bold">Keynote I.</span>},
 displayby = {Contributions from MEC 2021}
}

%%% -------------------------------
%%% MEC 2021 Proceedings: Papers

@inproceedings{RosFabregas_2022,
 abstract = {This paper presents the recent implementation of encoded music notation in two open access platforms of the Spanish National Research Council (CSIC) devoted to traditional music and polyphony, respectively: Fondo de M{\'u}sica Tradicional IMF-CSIC (FMT)1 and Books of Hispanic Polyphony IMF-CSIC (BHP)2. Even though, at first, both repertories seem unconnected, they have many textual/literary and musical points in common -- such as the presence/survival of old 15th--17th century texts and/or melodies of polyphonic romances (ballads) in the 20th century oral tradition --; future technological developments will facilitate further connections beyond the ones already found through search by text incipits and numeric melodic incipit connecting both platforms. The presentation will have two parts devoted to FMT (with more than 20.000 images of melodies in open access, it is the largest online archive of folklore in the Hispanic world; it is used also for OMR research) and BHP (a reference online catalogue for polyphonic choir books in Spain and books with Hispanic polyphony elsewhere). After a brief explanation about the origin and scope of the repertories covered in each platform, a few examples of encoded transcriptions of a melody, of an incipit in mensural notation, and of a polyphonic work (in MusicXML, **mens, and **kern; MEI can be used, too) rendered through Verovio will illustrate the potential development of FMT and BHP. Both websites constitute leading educational and musicological resources of the very rich Spanish music heritage, inviting national and international collaboration (crowdsourcing) to expand the contents of both platforms and to develop their digital technology.},
 author = {Ros-F{\'a}bregas, Emilio},
 title = {{Encoded Spanish Music Heritage through Verovio: The Online Platforms \textit{Fondo de M{\'u}sica Tradicional IMF--CSIC} and \textit{Books of Hispanic Polyphony IMF--CSIC}}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {21--29},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/m2ny-6b18},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Goebl_2022,
 abstract = {Though MEI is widely used in music informatics and digital musicology research, the relative lack of authoring software and the specialised nature of its community have limited the availability of high-quality MEI encodings. Translating to MEI from other encoding formats, or generating MEI via optical music recognition processes, is thus a typical component of many MEI-project workflows. However, automated translations rarely achieve results of sufficient quality, a problem well-known in the community and documented in the literature. Final correction and validation by hand is therefore a common requirement. In this paper, we present meifriend, an extension to the Atom text editor, which aims to relieve the degree of manual labour required in this process. The tool facilitates most common MEI editing tasks including the insertion and manipulation of MEI elements, makes the encoded score visible and interactively accessible to the user, and provides quality-of-life conveniences including keyboard shortcuts for editing functions as well as intelligent navigation of the MEI hierarchy. We detail the tool's implementation, describe its functionalities, and evaluate its responsiveness during the editing process, even when editing very large MEI files.},
 author = {Goebl, Werner and {M. Weigl}, David},
 title = {{Alleviating the Last Mile of Encoding: The \textit{mei-friend} Package for the Atom Text Editor}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {31--39},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/45ag-v044},
 bibbase_note = {<span style="color: green; font-weight: bold">Best Paper Award.</span>},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Rettinghaus_2022,
 abstract = {Digital symbolic music scores offer many benefits compared to paper-based scores, such as a flexible dynamic layout that allows adjustments of size and style, intelligent navigation features, automatic page-turning, on-the-fly modifications of the score including transposition into a different key, and rule-based annotations that can save hours of manual work by automatically highlighting relevant aspects in the score. However, most musicians still rely on paper because they don't have access to a digital version of their sheet music, or their digital solution does not provide a satisfying experience. To bring digital scores to millions of musicians, we at Enote are building a mobile application that offers a comprehensive digital library of sheet music. These scores are obtained by a large-scale Optical Music Recognition process, combined with metadata collection and curation. Our material is stored in the MEI format and we rely on Verovio as a central component of our app to present scores and parts dynamically on mobile devices. This combination of the expressiveness of MEI with the beautiful engraving of Verovio allows us to create a flexible, mobile solution that we believe to be a powerful and true alternative to paper scores with practical features like smart annotations or instant transpositions. We also invest heavily into the open-source development of Verovio to make it the gold standard for rendering beautiful digital sheet music.},
 author = {Rettinghaus, Klaus and Pacha, Alexander},
 title = {{Building a Comprehensive Sheet Music Library Application}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {41--48},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/s315-2y29},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Lewis_2022,
 abstract = {Music and the scholarship around it can be challenging to present in the forms associated with books and articles -- primarily linear and with an emphasis on the static and visual over the sonic and interactive. We introduce the Lohengrin TimeMachine, a multiple-path multimedia app, optimised for a touch-screen tablet. The app offers two essays about motifs in the opera -- one in textual form, and one a 30-minute video. These linear narratives are supported by audio examples, along with dynamic links that take the reader into a fully-interactive exploration of the occurrence of motifs across the opera. The reader's journey is supported with recorded music and scores, as well as novel visualisations of the orchestration and the timeline of the opera. The app is designed to operate over standards-based web documents published online, with extension and reuse in mind. In this paper, we describe the app, its underlying technology, and the journeys it supports.},
 author = {Lewis, David and Page, Kevin R. and Dreyfus, Laurence},
 title = {{\textit{Lohengrin TimeMachine}: Musicological Multimedia Made with MELD}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {49--55},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/kggk-pz64},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Berndt_2022,
 abstract = {With Music Performance Markup (MPM) we introduce a new XML format for describing musical performances in a systematic way. The format builds upon a series of mathematical models that capture the characteristics of performance features such as continuous tempo and dynamics transitions, articulations, and metrical accentuations. Bundled with MPM comes an infrastructure of documentations and software tools. This paper aims to provide an overview of and introduction to MPM, its infrastructure and ongoing development activities.},
 author = {Berndt, Axel},
 title = {{Music Performance Markup: Format and Software Tools Report}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {57--63},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/s357-e217},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Martignano_2022,
 abstract = {The ERC funded project European Ars Nova aims to study the corpus of poetry in Latin, Italian and French set to music by the polyphonists of the so-called Ars Nova. Since one of the main research goals of the project is the comparative study of musical and poetic texts, we are currently developing a web application that will allow readers to visualize and interact with the TEI- and MEI-encoded editions of our corpus together. The adoption of MEI as the underlying format for the digital editions of the musical texts presented us with the challenge of designing an editing workflow that allowed us to critically edit the texts in a user-friendly software like Finale. In this article, we illustrate how the critical editions are transposed to MEI documents using an ad hoc tool developed within the project, and how they are visualized in the web application. Finally, we discuss the critical aspects of the workflow and possible next steps for our digital critical edition in relation to the state of the art of music encoding.},
 author = {Martignano, Chiara and Calvia, Antonio and Epifani, Michele},
 title = {{Tools and Perspectives for a Digital Critical Edition of Fourteenth-Century Polyphonic Music}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {65--74},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/mnk2-yd48},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{GonzalezGutierrez_2022,
 abstract = {This paper aims to highlight, as a case study, the encoding of a Spanish traditional music corpus using the MEI standard for the development of an interactive traditional music database focused on preserving and disseminating this type of cultural expression in the field of music education as well as ethnomusicology research. It analyzes the possibilities of the schemas and the guidelines followed to describe cancioneros at the bibliographic level, as an archetypal form of compiling traditional music in Spain, as well as the analytical aspects that highlight paradigmatic elements of this kind of music such as rhythmic patterns, tessituras, modal contexts, phrases, structural forms, etc.},
 author = {{Gonz{\'a}lez Guti{\'e}rrez}, Sara and {Merch{\'a}n S{\'a}nchez-Jara}, Javier and {Navarro C{\'a}ceres}, Mar{\'i}a},
 title = {{Encoding Traditional Spanish Music for Pedagogical Purposes Through MEI: Challenges and Opportunities}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {75--84},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/w639-8t53},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Kepper_2022,
 abstract = {Traditional music philology aims at establishing an edited text, which is supposed to stage a clearly identified and well-reasoned version of a musical work. Such a text will always depend on sources used for its preparation and decisions taken by the editor(s). However, the intention is to deliver a product -- a static text, which resembles a specific combination of the transmitted sources of the work in question. In Genetic Editing, the focus lies elsewhere: Instead of justifying a specific product version, the intention is to trace the creative processes involved in the composition of that work. Obviously, those processes are only accessible through transmitted documents as well, but those documents do not need to contain full texts, nor are they only relevant when the composition has already matured enough to more or less reflect the final work.

The Beethovens Werkstatt project is one of the first endeavors to explore the applicability of Genetic Editing to music. Several years ago, a presentation at MEC 2015 in Florence introduced the first findings of the project and illustrated the then novel approaches of encoding genetic processes in MEI [2]. The discussions of the conceptual model proposed there eventually led to the introduction of several new elements into MEI. Since then, not only MEI has evolved, but also the project. The paper at hand reflects on data model considerations for the project's current module.},
 author = {Kepper, Johannes and Cox, Susanne},
 title = {{Encoding Genetic Processes II}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {85--95},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/q6y4-9139},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Gubsch_2022,
 abstract = {Metadata are a very broad and extremely differentiated subject and ranges from rudimentary catalog data to deeply indexed scientific catalogs (e.g., catalogs of works). In this paper, the concept of metadata in the context of MEI is first examined, before two examples are used to show that metadata are more than just rudimentary descriptions. These examples are also intended to illustrate the extent to which metadata are encoded in the field of music philology and thus represent an attempt to create a little more awareness for the work of the Metadata and Cataloging Interest Group of MEI.

The examples deal on the one hand with the encoding of performance resources and on the other hand with watermarks. In both cases, the possibilities of metadata encoding with MEI version 4 are exhausted and it is discussed which steps are useful and necessary to create an even deeper, machine-readable structure so that these sub-fields of the MEI metadata can also be used for larger scientific purposes such as analyses.},
 author = {Gubsch, Clemens and Ried, Dennis},
 title = {{METAdata and metaDATA}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {97--105},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/50t9-z881},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Richts-Matthaei_2022a,
 abstract = {Library forms of cataloging may differ greatly from the cataloging requirements of musicological research projects: They are often not detailed enough and do not take a close enough look at aspects of content relevant to research, such as handwritten entries in materials, etc. Library catalog entries of individual documents stand on their own for historical reasons, but usually do not reflect relationships to other surviving materials. This observation was the starting point for the Detmold Court Theatre Project, a six-year research project (September 2014 -- January 2021) that looked at the interconnectedness of different surviving materials of a 19th century theatre company that existed from 1825 to 1875. This project dealt with a very detailed form of inventory indexing in order to hand over and make accessible the formerly related materials in their entirety. This form of indexing was called `contextual deep indexing'. This special form of indexing took into account not only the pure performance materials but also the surviving theatre files, such as fee books, revenue and expense documents, stock lists, director's books, role and costume books, etc. All information was recorded based on autopsy (in the case of musical records on the basis of already existing RISM records from the 1980s). It was the first attempt to carry out such a form of indexing on the basis of the MEI and TEI encoding standards for a large repertory. For this purpose, a data model was needed that focuses on the linking of MEI and TEI data and enables the linking of different surviving library holdings, with a focus on a FRBR-based indexing of performance materials and associated performers as well as the structure of the theatre. Using a custom ODD-based schema, separate records were created for all works, expressions, and manifestations (in this case preserving the unity of materials kept under a common signature) and given unique identifiers so that they can now all be referenced individually.

The paper summarizes the results of this pilot project. It addresses the particularities and requirements of an inventory development that does not focus on individual objects, but on the relationship between different objects (and subjects). It presents a document-oriented (not object-oriented) data model that uses library materials to revive an entire network of a long-gone organization.},
 author = {Richts-Matthaei, Kristina and Capelle, Irmlind},
 title = {{United, Linked, Connected -- A Data Model for the Inventory of the Former Detmold Court Theatre (1825--1875), or: How Library Inventory History Can also Be Told}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {107--115},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/bqd1-yf81},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Page_2022,
 abstract = {Performance of music in the home was the means by which most works were received before the advent of audio recordings and broadcasts, yet the notation sources that form our primary record of this culture have not been the subject of comprehensive or methodical study. Choices made by arrangers adapting music for domestic consumption -- of instrumentation, abbreviation, or simplification -- reflect the musical life of the 19th century, and can inform our understanding alongside contemporary accounts such as newspapers, adverts, and diaries.

This position paper gives the background, motivation, and proposed approach of research currently being undertaken within the Beethoven in the House project. This will include a study of Steiner editions of Beethoven's 7th and 8th Symphonies and Wellingtons Sieg, making a detailed comparison between arrangements, systematically identifying a core common to multiple versions, and asking if this reflects the stated values of the publisher. A second survey will look for patterns across a larger sample of lesser-known and poorly catalogued scores, collating emergent indicators of arrangers' motivations within a narrative of the domestic market -- the music industry of its day. Both studies will innovate digital methods which characterise arrangements as music encodings, including `sparse' approaches to notation and annotation.},
 author = {Page, Kevin R. and Kepper, Johannes and Siegert, Christine and Hankinson, Andrew and Lewis, David},
 title = {{Beethoven in the House: Digital Studies of Domestic Music Arrangements}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {117--123},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/389b-xx73},
 displayby = {Contributions from MEC 2021}
}

%%% -------------------------------
%%% MEC 2021 Proceedings: Posters

@inproceedings{Albuquerque_2022,
 abstract = {PROFMUS is a collaborative project that aims to carry out the research and consolidation of information to support further research about the Portuguese musicians active in the period from 1750 to 1986. The information to be collected must include as many relevant attributes as possible, especially about their academic background, professional careers, and personal details. This project considers a large amount of data from a wide time-period, which means there will be various attributes for each object, which will evolve over time or differ from source to source. There is also an issue wit the lack of uniformity of existing sources in multiple institutions, museums, archives, and databases, each with its own data scheme. Since PROFMUS has a long-term perspective, it does not try to create a uniform and prefixed scheme for the data to consolidate but accepts every different scheme and stores all data in a controlled knowledge base. We describe here an application for that purpose, using MediaWiki and Wikibase for storage, and a back-office specific application to manage and publish the data.},
 author = {Albuquerque, Maria Jo{\~a}o and Pinto, H. Sofia and Borbinha, Jos{\'e} Lu{\'i}s},
 title = {{The PROFMUS Application: Development, Status, and Future Progress}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {125--130},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/7wd6-1x56},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Gotham_2022,
 abstract = {The OpenScore Lieder Corpus is a collection of over 1,200 nineteenth century songs encoded by a dedicated team of mostly volunteers over several years. Having reported on the initial phase, motivations, design, and community-oriented aspects of the project before, we present here the first, stable, large-scale release of this corpus specifically designed for MIR researchers, complete with comprehensive, structured, linked metadata. The corpus continues to be available under the open CC0 licence and represents a compelling dataset for a range of MIR tasks, not least given its unusual balance of large-scale with high-quality encoding, and of diversity (songs by over 100 composers, from many countries, and in a range of languages) with unity (centred on the nineteenth-century lieder tradition).},
 author = {Gotham, Mark Robert Haigh and Jonas, Peter},
 title = {{The OpenScore Lieder Corpus}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {131--136},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/1my2-dm23},
 bibbase_note = {<span style="color: green; font-weight: bold">Best Poster Award.</span>},
 displayby = {Contributions from MEC 2021}
}

@inproceedings{Richts-Matthaei_2022b,
 abstract = {NFDI4Culture is the consortium for research data on material and immaterial cultural heritage and offers a user-centered and research-led infrastructure. By focusing on the digital capture as well as data-based research of cultural assets, NFDI4Culture brings together different disciplines in their research interests but also in terms of their infrastructure needs. The consortium has been funded since October 2020 for an initial period of 5 years. Paderborn University is connected to NFDI4Culture via the Center for Music, Edition, Media (Zen-MEM), which bundles activities in the fields of digital musicology, music and film informatics, media science, media technologies, and in several areas of computer science with a special focus on Digital Music Edition and Digital Musicology. With its many projects, ZenMEM contributes a lot to the further development of MEI.

MEI will therefore also have a special place in NFDI4Culture. In addition to general community aspects and enhancements of the format, activities will focus on the development of best practice recommendations and training materials, the further development of MEI-related tools, such as MerMEId and the MEIGarage, and concepts for data quality in MEI, but also on the improvement of standard data for musical works. The poster will show the organizational structure of NFDI4Culture and its representation at Paderborn University, its interaction and networking with national and international infrastructures, combined with several examples where MEI is involved.},
 author = {Richts-Matthaei, Kristina and Albrecht-Hohmaier, Martin and R{\"o}wenstrunk, Daniel and M{\"u}nzmay, Andreas},
 title = {{MEI Meets NFDI4Culture}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {137--141},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/ny4d-bp67},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Hentschel_2022,
 abstract = {Chord-based harmony is an important aspect of many types of Western music, across genres, regions, and historical eras. However, the consistent representation and comparison of harmony across a wide range of styles (e.g., classical music, Jazz, Rock, or Pop) is a challenging task. Moreover, even within a single musical style, multiple theories of harmony exist, each relying on its own (possibly implicit) assumptions and leading to harmonic analyses with a distinct focus (e.g., on the root of a chord vs. its bass note) or representation (e.g., spelled vs. enharmonic pitch classes). Cross-stylistic and cross-theory comparisons are therefore even more difficult, particularly in a large-scale computational setting that requires a common overarching representation. To address these problems, we propose a model which allows for the representation of chords at multiple levels of abstraction: from chord realizations on the score level (if available), to pitch-class collections (including a potential application of different equivalences, such as enharmonic or octave equivalence), to pitch- and chord-level functions and higher-order abstractions. Importantly, our proposed model is also well-defined for theories which do not specify information at each level of abstraction (e.g., some theories make no claims about harmonic function), representing only those harmonic properties that are explicitly included and inducing others where possible (e.g., deriving scale degrees from root and key information). Our model thus represents an important step towards a unified representation of harmony and its various applications.},
 author = {Hentschel, Johannes and Moss, Fabian C. and McLeod, Andrew and Neuwirth, Markus and Rohrmeier, Martin},
 title = {{Towards a Unified Model of Chords in Western Harmony}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {143--149},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/4crx-fr36},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Lind_2022,
 abstract = {Musical scores are frequently annotated with harmonic information, but widely used text-based methods rely on a limited number of visual channels. Though glyph-based methods exploit more channels, existing systems often violate perceptual design principles when employing color and rarely capture the frequency of chordal changes or their harmonic function. In this work, we introduce a new design idiom for augmenting sheet music through chordal glyphs embedded directly within musical staves. Harmonic concepts, weighted by saliency and categorized by data type, are mapped to visual channels ranked by discriminability. Preattentive processing is leveraged to support various user tasks, alongside redundant encodings of foundational harmonic elements to improve overall perceptual effectiveness. Key names and chord roots are displayed using parallel hue-based 12-step categorical colormaps. We then distill several design implications inherent in assigning colors to musical pitches regarding perceptual and linguistic effectiveness. Following this discussion, we outline open research directions.},
 author = {Lind, Justin},
 title = {{Visualizing Harmony Using Chordal Glyphs and Color Mapping}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {151--158},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/taak-jv92},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Matuszewska_2022,
 abstract = {The field of musicology is constantly being enriched with digital, searchable music data. This trend opens new research possibilities; conversely, it requires new abilities to work with numerous data sets efficiently. Digital tools facilitate searching large music corpora and serve music analysis well. Nevertheless, there is still a potential to better harmonize research perspectives from musicology and computer science to make computational analysis outcomes more explicit, comprehensible, and flexible.

The aim of this paper is to present new ways of handling, displaying, and considering musicological data. Music information from fugues BWV 846--851 composed by J.S. Bach, retrieved with Humdrum Tools and the Music Processing Suite (MPS) software, was processed and translated into a relational database. The visual display of the retrieved information was accomplished with dashboards using the data visualization software Tableau Public. The possibility of comparing each fugue's voices makes it easier to comprehend the knowledge hidden behind music data. Additional options enable further visual exploration of the analyses and ensure conditions for abduction under assumptions of diagrammatic reasoning as proposed by Charles Sanders Peirce.},
 author = {Matuszewska, Anna and Seibert, Christoph},
 title = {{Diagrammatic Analysis of J.S. Bach's \textit{The Well-Tempered Clavier} Fugues, BWV 846--851}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {159--166},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/j7vc-cq22},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Bohl_2022,
 abstract = {In the past twenty years, the technical setup of the Music Encoding Initiative (MEI) data framework has been adjusted several times. Each of those transitions was motivated by the wish to improve the ways in which MEI could be integrated with other formats, to simplify the maintenance of MEI, and to encourage more people to actively contribute to the development of MEI. Some of those objectives are contradictory, and accordingly, there is no single right answer for all times about the best possible technical setup for MEI. The main purpose of this poster is to give a historical overview of the technical setups that MEI has gone through in the 20 or so years of its existence, and to illustrate the current workflows. Ideally, this empowers wider parts of the community to contribute to the continued development of both the MEI specification and documentation. Eventually, it will explain the steps necessary to set up a local working environment to participate in these developments.},
 author = {Bohl, Benjamin W. and Kepper, Johannes},
 title = {{ODD Structures and Where to Find Them}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {167--171},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/fjmt-xs81},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Siklafidis_2022,
 abstract = {The possibility of rendering scores of Greek Chant repertoires from the 3rd to the 21st century A.D. with the use of the computer opens new horizons in musicological research. In this poster a synoptic overview concerning the historical development of notational types used for Greek chants is given. This is followed by a record of various fonts and software for Byzantine neumes created since 1989. The goal of the poster is to present a new font for psaltic notations of the first and second Christian millennium, displaying the great variety of signs, neume families and neume combinations which are encountered in musical manuscripts and theoretical treatises of the Psaltic Art. These by far exceed the Byzantine neumes found today in the unicode system.

The future development of suitable software can facilitate interdisciplinary studies with other traditions and contribute to the communication between musicologists and musicians belonging to different areas of expertise.},
 author = {Siklafidis, Nikolaos and Alexandru, Maria},
 title = {{Font Design of Psaltic (Byzantine) Notation for Greek Musical Repertoires}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {173--180},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/cwz0-st26},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Stutter_2022,
 abstract = {The Clausula Archive of the Notre Dame Repertory (CANDR) is an in-progress PhD project with the aim of cataloguing, transcribing and analysing digital facsimiles of the thirteenth-century repertory commonly termed Notre Dame polyphony, and a secondary aim of providing new datasets and analytical tools for studying medieval polyphony. This poster highlights the use in the project of (a) a new methodology for de-skewing facsimile images, and (b) average symbol masks in an OMR--enhanced workflow with an emphasis on creating an OMR workflow that is `good enough' to accelerate the annotation of an image dataset of particularly transitional notation.},
 author = {Stutter, Joshua},
 title = {{Annotation of Medieval Music Facsimiles Using `Good Enough' OMR}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {181--187},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/5ssz-2n19},
 displayby = {Contributions from MEC 2021}
}


@inproceedings{Zwissler_2022,
 abstract = {A perspective on the specific issues of music encoding dealing with Electronic Music is presented. In many cases the works to be discussed exist in a fixed media format and hence no prescriptive score is necessary to facilitate a `valid' performance. While there are a number of descriptive scores for pieces of Electronic Music, these are to be treated differently, as they are purely aimed at analysis and therefore contain a certain information bias. Data that is more comparable to instrumental scores is contained in rare examples of so-called realization scores. It is argued that these realization scores can be identified as the main subject for encoding of Electronic Music works. For this we will discuss an example from one such score by Karlheinz Stockhausen. For his piece KONTAKTE, Stockhausen released a realization score that unfolds a very detailed documentation of all steps made within the studio production of that work, including the complex patching of studio devices and the specific transformation processes achieved by the use of tape machines. The paper presents an approach to formalize and encode all these steps within the framework of a semantic database. Using technology like the semantic web standard, Linked Data and the corresponding RDF/OWL framework, an Electronic Music production setup and its usage can be encoded, stored, and analyzed.},
 author = {Zwi{\ss}ler, Florian and Schwarzbauer, Philip and Oehler, Michael},
 title = {{Encoding Scores for Electronic Music}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {189--196},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/kmca-m064},
 displayby = {Contributions from MEC 2021}
}

%%% -------------------------------
%%% MEC 2021 Proceedings: Panel

@inproceedings{Desmond_2022,
 abstract = {This panel submission for the 2021 Music Encoding Conference brings together five short papers that focus on the making of computer-readable encodings of polyphony in the notational style -- mensural notation -- in which it was originally copied. Mensural notation was used in the medieval West to encode polyphony from the late thirteenth to sixteenth centuries. The Measuring Polyphony (MP) Online Editor, funded by an NEH Digital Humanities Advancement Grant, is a software that enables non-technical users to make Humdrum and MEI encodings of mensural notation, and links these encodings to digital images of the manuscripts in which these compositions were first notated. Topics explored by the authors include: the processes of, and the goals informing, the linking of manuscript images to music encodings; choices and compromises made in the development process of the MP Editor in order to facilitate its rapid deployment; and the implications of capturing dual encodings -- a parts-based encoding that reflects the layout of the original source, and a score-based encoding. Having two encodings of the music data is useful for a variety of activities, including performance and analysis, but also within the editorial process, and for sharing data with other applications. The authors present two case studies that document the possibilities and potential in the interchange of music data between the MP Editor and other applications, specifically, MuRET, an optical music recognition (OMR) tool, and Humdrum analysis tools.},
 author = {Desmond, Karen and Pugin, Laurent and Regimbal, Juliette and Rizo, David and Sapp, Craig and Thomae, Martha E.},
 title = {{Encoding Polyphony from Medieval Manuscripts Notated in Mensural Notation}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {197--219},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/tf2j-x697},
 bibbase_note = {<span style="color: green; font-weight: bold">Panel.</span>},
 displayby = {Contributions from MEC 2021}
}

%%% -------------------------------
%%% MEC 2021 Proceedings: Keynote II

@inproceedings{Willcox_2022,
 abstract = {Drawing on collaborative research at The National Archives, including through the UK Arts and Humanities Research Council's programme Towards a National Collection, this talk explores computational archival science, artificial intelligence, citizen involvement, and post-custodial approaches to challenge doom-laden technological determinism, and how together we might combine `hand-curated' and `at-scale' approaches to our shared cultural heritage to ensure automation works `for the people'.},
 author = {Willcox, Pip},
 title = {{Automatic for the People: Archives and the Future}},
 keywords = {mec-proceedings, mec-proceedings-2021},
 pages = {221},
 publisher = {{Humanities Commons}},
 isbn = {978-84-1302-173-7},
 editor = {M{\"u}nnich, Stefan and Rizo, David},
 booktitle = {{Music Encoding Conference Proceedings 2021}},
 year = {2022},
 doi = {10.17613/3stx-3f16},
 bibbase_note = {<span style="color: green; font-weight: bold">Keynote II.</span>},
 displayby = {Contributions from MEC 2021}
}






%%% -------------------------------
%%% MEC 2024 Proceedings: Abstracts

@inproceedings{Beer_2024,
   abstract = {The hybrid music edition project Reger-Werkausgabe (RWA) -- published as traditionally printed volumes accompanied by a complementary digital publication -- has developed and established new and innovative research and publication methods since its very beginning in 2008. By defining and developing appropriate interfaces to convey between real-world cultural heritage objects, (digital) technology, and modern forms of presentation of musicology research the project and its online research and publication platform RWA Online have constitute a stable and sustainable foundation for deeper and more complex digital edition work, leading to other domains of musicology research that in traditionally printed editions would remain in the domain of research "by-catch".},
   author = {Beer, Nikolaos and Nguyen, Alexander},
   title = {{Works of other authors and composers as templates -- approaches to capture template research in digital music editions. A case study in the context of the Reger-Werkausgabe.}},
   keywords = {mec-proceedings, mec-proceedings-2024},
   publisher = {Knowledge Commons},
   year = {2024},
   url = {https://hcommons.org/deposits/item/hc:69893/},
   doi = {10.17613/6pr3-e950},
   displayby = {Contributions from MEC 2024}	
}

@inproceedings{Bouressa_2024,
	abstract = {This paper delves into the transformative potential of Wikidata as a language-agnostic tool for categorizing musical instruments, catering to a broad spectrum of users, from individuals to large-scale deep learning models, across diverse linguistic landscapes. Traditional taxonomy systems, including Hornbostel-Sachs (HBS), Library of Congress (LOC), and Museum of Musical Instruments Online (MIMO), encounter challenges due to language-specific constraints and a lack of provisions for incorporating local terminology. The ubiquity of multiple formal identifiers for even well-known instruments, such as the double bass (contrabass, bass, etc.), further complicates the issue of instrument encoding and reference.},
	author = {Bouressa, Kyrie Ekaterina and Fujinaga, Ichiro},
	title = {{Musical Instrument Encoding Matters}},
	keywords = {mec-proceedings, mec-proceedings-2024},
	publisher = {Knowledge Commons},
	year = {2024},
	url = {https://hcommons.org/deposits/item/hc:69903/},
	doi = {10.17613/g587-jh48},
 	displayby = {Contributions from MEC 2024}	
}

@inproceedings{Calvo-Zaragoza_2024,
	abstract = {Encoding music scores for computational purposes has attracted the attention of researchers and musicologists in recent years. However, with the growing appearance of new Music Information Retrieval (MIR) tasks and techniques, new encoding format standards need to be set to overcome the challenges that still remain open. This contribution aims to study the encoding of Jazz lead sheets, from its justification and beginning to future-proof features. The main objective is to standardize encoding formats by means of several MIR tasks, such as Optical Music Recognition (OMR).},
	author = {Calvo-Zaragoza, Jorge and Garc{\'i}a-Iasci, Patricia and Sevilla, Juan Carlos Mart{\'i}nez and Rizo, David},
	title = {{Towards a standardization of lead sheet encoding: an experience in OMR}},
	keywords = {mec-proceedings, mec-proceedings-2024},
	publisher = {Knowledge Commons},
	year = {2024},
	url = {https://hcommons.org/deposits/item/hc:69905/},
	doi = {10.17613/fbrj-k426},
 	displayby = {Contributions from MEC 2024}	
}

@inproceedings{Day_2024,
	abstract = {The team asked the question "would it be possible to create an MEI parser that would simplify our files to a skeletal structure that could enable searches based on melodic intervals either with or without rhythm?" Also, could this same parser enable constant indexing as the corpus grows. This paper will report on a tool created to convert MEI files in this manner and the technology used to index and search the parsed files. This parser we developed can run against the entire airs connus corpus efficiently to create and maintain a simplified parallel corpus of compressed melodies for searching.},
	author = {Day, David and Stevenson, Jacob Ivan},
	title = {{Simplifying MEI for Searching Applications}},
	keywords = {mec-proceedings, mec-proceedings-2024},
	publisher = {Knowledge Commons},
	year = {2024},
	url = {https://hcommons.org/deposits/item/hc:69889/},
	doi = {10.17613/2y4w-fj61},
 	displayby = {Contributions from MEC 2024}	
}

@inproceedings{DeLuca_2024,
	abstract = {In this paper, we will present an anonymous project focused on the automatic analysis of plainchant found in some Portuguese manuscripts from the 12th to the 17th centuries. The chants to be analyzed are written in two music scripts: neumatic Aquitanian and square notation. This project aims to create a new experimental tool, a prototype interface able to compare the same chant, or portion of chant, across the whole repertory of music sources from the selected geographical area.},
	author = {{De Luca}, Elsa and S{\'a}nchez, Vicente Urones and Thomae, Martha E.},
	title = {{Encoding and Analysis of Early Music: Aquitanian and Square Music Scripts}},
	keywords = {mec-proceedings, mec-proceedings-2024},
	publisher = {Knowledge Commons},
	year = {2024},
	url = {https://hcommons.org/deposits/item/hc:69883/},
	doi = {10.17613/7rgg-gj76},
 	displayby = {Contributions from MEC 2024}	
}

@inproceedings{Feustle_2024,
	abstract = {This workshop will proceed similarly to that of the previous three years, and is intended to give absolute beginners extended explanations of and practice with XML basics and rudimentary MEI encoding. The content will include, but not be limited to that of the MEI online tutorials, in order to maximize comprehension and retention of information through repetition and the gradual addition of new information in successive exercises. This workshop will allow for participation by those who are interested in MEI, but cannot travel to Denton at this time, and it offers both a smoother transition for users into the content of other conference workshops, as well as a recruiting tool for prospective users who donâ€™t know where to begin. This presentation can be given in an in-person or hybrid format.},
	author = {Feustle, Maristella},
	title = {{MEI Basic Workshop}},
	keywords = {mec-proceedings, mec-proceedings-2024},
	publisher = {Knowledge Commons},
	year = {2024},
	url = {https://hcommons.org/deposits/item/hc:69907/},
	doi = {10.17613/9qy1-cz48},
 	displayby = {Contributions from MEC 2024}	
}

@inproceedings{Hankinson_2024,
	abstract = {In the spring of 2023, the Digital and Cognitive Musicology Lab (DCML) at the Ecole polytechnique f{\'e}d{\'e}rale de Lausanne (EPFL) and the RISM Digital Center in Bern, Switzerland joined forces to implement MEI support in MuseScore, a widely used free and open-source music notation editor. One of the main areas of research within the DCML is corpus studies with large amounts of encoded notation. They maintain a number of encodings entered in MuseScore, but use the MEI format in their analysis and publishing toolchain. The current workflow, which imports MusicXML and then converts it to MEI or MuseScore, has impeded the growth of high-quality corpora, primarily due to ambiguities within the MusicXML format itself. A direct conversion method between MEI and MuseScore was identified as the solution to these issues. MEI support in MuseScore would also benefit the wider MEI community.},
	author = {Hankinson, Andrew and Hentschel, Johannes and Pugin, Laurent and Rammos, Ioannis and Rohrmeier, Martin},
	title = {{MEI-Basic support in MuseScore 4.2}},
	keywords = {mec-proceedings, mec-proceedings-2024},
	publisher = {Knowledge Commons},
	year = {2024},
	url = {https://hcommons.org/deposits/item/hc:69887/},
	doi = {10.17613/ccmr-yv05},
 	displayby = {Contributions from MEC 2024}	
}

@inproceedings{Karlsberg_2024,
	abstract = {This paper explores possibilities for greater interoperability among digital hymnody indices and between hymnody indices and digital libraries of musical sources. These findings stem from a comparative analysis of data models for leading hymnody indices and a higher-level comparison of hymnody indices and related resources and collections of digitized musical sources. I undertook this research in developing a plan to index the contents of the forthcoming Sounding Spirit Digital Library (SSDL), a thematic digital collection of 1,300 vernacular sacred music books from the southeastern United States published between 1850 and 1925. In addition to developing a proposed data model for this future hymnody indexing project, I created a crosswalk detailing metadata fields shared among extant hymnody indices and documented opportunities for bringing data from these indices and related resources together to facilitate discovery and research.},
	author = {Karlsberg, Jesse P.},
	title = {{Indexing Hymnody: Comparative Analysis and Opportunities for Interoperability}},
	keywords = {mec-proceedings, mec-proceedings-2024},
	publisher = {Knowledge Commons},
	year = {2024},
	url = {https://hcommons.org/deposits/item/hc:69885/},
	doi = {10.17613/d9vf-mb96},
 	displayby = {Contributions from MEC 2024}	
}

@inproceedings{Kepper_2024,
	abstract = {Undoubtedly, MEI is one of the most, if not the most versatile data model for encoding music notation, covering an increasing number of notational systems for various epochs and regions, and different scholarly interests and research questions on such music. In chapter 1.3.5 of the MEI Guidelines, it is recommended that "in production, it is best to use a customized version of MEI, restricted to the very needs of a project." However, there is no documentation so far on how to properly enrich the MEI model in those cases where the current standard does not adequately cover a given research interest.},
	author = {Kepper, Johannes and Rosendahl, Lisa and S{\"a}nger, Richard},
	title = {{Beyond the Standard Model}},
	keywords = {mec-proceedings, mec-proceedings-2024},
	publisher = {Knowledge Commons},
	year = {2024},
	url = {https://hcommons.org/deposits/item/hc:69895/},
	doi = {10.17613/6van-4b55},
	displayby = {Contributions from MEC 2024}	
}

@inproceedings{Lepper_2024,
	abstract = {The semantics of notation systems can naturally be meta-modelled as a network of transformations, starting with the syntactic elements of the notation and ending with the parameters of an execution. In this context, a digital encoding format for music notation can be seen as selecting a subset of the data nodes of this network for storage, leaving others to evaluation. For such a selection, semantic properties are defined which have impact on the practical costs of maintenance, migration, extension, etc.},
	author = {Lepper, Markus and Widemann, Baltasar Tranc{\'o}n y},
	title = {{Critical Semantic Properties of Music Notation Datasets}},
	keywords = {mec-proceedings, mec-proceedings-2024},
	publisher = {Knowledge Commons},
	year = {2024},
	url = {https://hcommons.org/deposits/item/hc:69899/},
	doi = {10.17613/hq2n-qa74},
 	displayby = {Contributions from MEC 2024}	
}

@inproceedings{Monnier_2024,
	abstract = {Bach's Goldberg Variations provide a rich inventory of examples of all these challenges. This paper will illustrate those challenges and potential solutions in the context of an early-stage project to build an interactive viewer / player for the Goldberg Variations that allows exploration of the work through different domain lenses. The specific contrapuntal structures of these variations allows for a thorough exploration of representing the logical, gestural, and visual domains. Further abstracting away from the conventions of music notation will allow a more detailed exploration of the analytical domain as well, which does not require traditional sheet music and can be rendered in any form that is easily machine-readable. As well as the web application itself, the paper will also discuss Python code used to convert and map between the different domains. Currently the MEI is rendered using Verovio.},
	author = {Monnier, Sarah J. and Tauber, James K.},
	title = {{Modelling Multi-domain Voicing in the Goldberg Variations}},
	keywords = {mec-proceedings, mec-proceedings-2024},
	publisher = {Knowledge Commons},
	year = {2024},
	url = {https://hcommons.org/deposits/item/hc:69879/},
	doi = {10.17613/s553-h929},
 	displayby = {Contributions from MEC 2024}	
}

@inproceedings{Neumann_2024,
	abstract = {MEI's development to date has understandably focused on the digitization of visually-based musical documents. It thus has provided a parallel to historical musicology's long-standing (since the 19th century) conception of musical scores as musical works. The past quarter-century, in particular, has seen an expansion of musicological research to include performance studies based on the use of audio-visual recordings as primary source documents. Not least in the context of current considerations to expand the coding options of the format to include audiovisual elements, the limits of this current structuring become apparent. The question therefore arises whether the existing MEI structures are sufficient to respond to this performance oriented turn, or if they should be questioned and adapted as necessary in order to better align the data format with current developments and considerations in musicological research and neighbouring disciplines.},
	author = {Neumann, Joshua and Richts-Matthaei, Kristina},
	title = {{Modelling Performance -- Conceptual Realities vs. Practical Limitations in MEI}},
	keywords = {mec-proceedings, mec-proceedings-2024},
	publisher = {Knowledge Commons},
	year = {2024},
	url = {https://hcommons.org/deposits/item/hc:69897/},
	doi = {10.17613/15jt-ed47},
 	displayby = {Contributions from MEC 2024}	
}

@inproceedings{Richter_2024,
	abstract = {The DFG project Digital Liszt Catalogue Raisonn{\'e}, which was launched in 2020, catalogues and systematizes Franz Liszt's oeuvre. To this end, philological and bibliographic information on Liszt-related sources and works will be collected and encoded and stored in a suitable data format as the basis for the index. MEI, an XML-based format that is human- and machine-readable and equally suitable for long-term archiving and data export via API, will be used for this purpose. The catalogue raisonn{\'e} to be developed will provide a selection of possible views of this data in a web interface. When indexing the source holdings, problems arise in the FRBR categorization, which forms the basis of MEI. The paper presents a problematic source in this respect and presents a preliminary coding in MEI for discussion.},
	author = {Richter, Matthias and Voigt, Boris},
	title = {{Issues of FRBR systematics in indexing sources that represent different versions of works. The example of Franz Liszt.}},
	keywords = {mec-proceedings, mec-proceedings-2024},
	publisher = {Knowledge Commons},
	year = {2024},
	url = {https://hcommons.org/deposits/item/hc:69891/},
	doi = {10.17613/cgcp-kv08},
 	displayby = {Contributions from MEC 2024}	
}

@inproceedings{Seki_2024,
	abstract = {This paper examines methods for encoding musical scores used for the hichiriki instrument in gagaku, traditional Japanese court music. Gagaku is Japanese oldest musical tradition, but its scores use ambiguous notation, posing challenges for computational analysis. The proposed encoding method focuses on sh{\=o}ga (sung mnemonic texts), which appear most frequently. The elements of tetsuke (fingering) and hy{\=o}shi (symbol for rhythmic cycles) accompany sh{\=o}ga in the markup. Efficient workflow uses Python code for initial markup and a Stream Deck device for rapid tagging while reviewing images of original scores. Encoded data created for 93 short and medium-length pieces provide a structured foundation for computational study of gagaku. Future work will extend encoding to parts for other wind instruments such as sh{\=o} and ry{\=u}teki.},
	author = {Seki, Shintaro},
	title = {{GagakuXML: Markup for Hichiriki Scores and Enhancing Efficiency in Traditional Japanese Music Encoding}},
	keywords = {mec-proceedings, mec-proceedings-2024},
	publisher = {Knowledge Commons},
	year = {2024},
	url = {https://hcommons.org/deposits/item/hc:69901/},
	doi = {10.17613/q8s8-dw75},
 	displayby = {Contributions from MEC 2024}	
}

@inproceedings{Stutter_2024,
	abstract = {This paper presents and demonstrates the features of the "Clausula Archive of the Notre Dame Repertory" (CANDR), an online and open source database for thirteenth-century polyphony, augmented by an optical music recognition (OMR) and editing tool. Alongside this is a Python analysis programming toolkit specifically designed to study the problem of musical reuse in medieval polyphony within the limits of its ambiguous notation. CANDR provides a single graphical web interface to browse, search, and edit the sources of Notre Dame polyphony (in both facsimile and symbolic notation) by overlaying notational traces from OMR directly onto facsimile images.},
	author = {Stutter, Joshua},
	title = {{The "Clausula Archive of the Notre Dame Repertory": End-to-end OMR, encoding, and analysis of medieval polyphony}},
	keywords = {mec-proceedings, mec-proceedings-2024},
	publisher = {Knowledge Commons},
	year = {2024},
	doi = {10.17613/qft3-hg77},
	url = {https://hcommons.org/deposits/item/hc:69881/},
 	displayby = {Contributions from MEC 2024}	
}




%%% -------------------------------
%%% MEC 2025 Proceedings: Book of Abstracts

@proceedings{Lewis-Plaksin-Stremel_2025,
  title = {{Music Encoding Conference 2025 â€“ Book of Abstracts}},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  publisher = {Knowledge Commons},
  doi = {10.17613/20s0d-gq678},
  urldate = {2025-07-08},
  abstract = {The Music Encoding Conference is the annual meeting of the Music Encoding Initiative (MEI) community and all who are interested in the digital representation of music. Music encoding is a critical component for fields and areas of study including computational or digital musicology, digital editions, symbolic music information retrieval, and digital libraries. This event brings together enthusiasts from various music research communities, including technologists, librarians, music scholars, and students and provides an opportunity for learning and engaging with and from each other.},
  bibbase_note = {<span style="color: green; font-weight: bold">Full Book of Abstracts.</span>},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Common part MEC 2025}
}

%%% ------------------------------
%%% MEC 2025 Proceedings: Foreword

@inproceedings{Lewis-Plaksin-Stremel_2025,
  abstract = {Foreword of the Music Encoding Conference 2025 Book of Abstracts.},
  author = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  title = {{Foreword}},
  booktitle = {{Music Encoding Conference 2025 â€“ Book of Abstracts}},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  publisher = {Knowledge Commons},
  year = {2025},
  pages = {x--xi},
  doi = {10.17613/20s0d-gq678},
  urldate = {2025-07-08},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Common part MEC 2025}
}

%%% -------------------------------
%%% MEC 2025 Proceedings: Keynote I

@inproceedings{Volk_2025,
  title = {Making Sense of Music: De- and Encoding Music Information},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Volk, Anja},
  editor = {Stremel, Sophie and Lewis, David and Plaksin, Anna},
  year = {2025},
  pages = {3--4},
  publisher = {Knowledge Commons},
  doi = {10.17613/0w8js-xa987},
  urldate = {2025-07-08},
  bibbase_note = {<span style="color: green; font-weight: bold">Keynote I.</span>},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

%%% -------------------------------
%%% MEC 2025 Proceedings: Keynote II

@inproceedings{Crawford_2025,
  title = {{A Quarter-Century of Music Encoding}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Crawford, Tim},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {5--8},
  publisher = {Knowledge Commons},
  doi = {10.17613/v7r0t-bb073},
  urldate = {2025-07-08},
  abstract = {One way or another, I have been involved with 'music encoding' for well over 25 years now. It started in 1987 with my first Macintosh computer, on which I played with a program called Hypercard, which you could get to play tunes rather crudely; I was soon exploring how to make it play from lute tablature, for which I needed my own encoding format. Soon after, I met the late Donald Byrd, then working on his music-notation editor, Nightingale, a Macintosh program which never achieved the success it deserved. Don's colleague, John Gibson, helped me to hack together, using bits of code from Nightingale, my own Tablature Processor for Mac, which soon died owing to my failure to keep up with successive OS upgrades. But I was able to use it in earnest in an exacting project, providing modern tablature for a pair of volumes of my own scholarly edition of the lute music of Silvius Leopold Weiss (1687-1750). Don and I worked on several projects together, including Online Music Recognition and Search (OMRAS), which received joint US/UK funding for three years. It was at the suggestion of our US funders, the NSF Digital Libraries Initiative, that we hold an international workshop, which in fact became the first ISMIR conference (Plymouth, Massachusetts, 2000). Already, with Don and John Gibson, I had contributed a chapter to Beyond MIDI (1999) about the Nightingale Notelist, an ASCII-based encoding format for music which captured many of the features of Nightingale itself. But all was swept aside by the rapid domination of formats based on XML, which itself had only existed for a decade or so at that point. At the second ISMIR (Bloomington, Indiana, 2001), I was witness in a pub to what can best be described as a 'lively discussion' between Michael Good, whose MusicXML had just got going, and Perry Roland, about the relative merits of elements and attributes for certain features of music which I don't need to go into here. Since the last time I was honoured to give an MEC keynote (at Charlottesville, Virginia, in 2014), Perry's baby, MEI (amusingly, known to my email client as 'Mei'), has grown up considerably. I shall try to summarise briefly some of the achievements of those here at MEC, and some who can't be present, to bring this about. There will be many omissions, for which I apologise in advance, as I don't pretend to keep up to date in every facet of MEI's development, and there may well be things happening which none of us know about - such is the nature of Open Source. But I hope it will be a non-technical and personal survey showing something of MEI's current range and scope that was just a dream back in 2014, and certainly undreamt of in 1999.},
  bibbase_note = {<span style="color: green; font-weight: bold">Keynote II.</span>},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

%%% -------------------------------
%%% MEC 2025 Proceedings: Papers

@inproceedings{Alemayehu_2025,
  title = {{Community-Driven Open Source Development of Edirom Online 1.0 and Beyond}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Alemayehu, Hizkiel and Bachmann, Tobias and Beer, Nikolaos and Bohl, Benjamin and Friedl, Dennis and R{\"o}wenstrunk, Daniel and Ried, Dennis and Herold, Kristin and Jettka, Daniel and Kepper, Johannes and Reich, Silke and Stadler, Peter},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {167--170},
  publisher = {Knowledge Commons},
  doi = {10.17613/9q5gf-sbn97},
  urldate = {2025-07-08},
  abstract = {Edirom-Online is a software for the presentation and analysis of critical musical editions in a digital format, particularly in the fields of musicology and philology. Edirom-Online supports various data formats commonly used in digital humanities, such as TEI (Text Encoding Initiative) for textual data and MEI (Music Encoding Initiative) for musical data, that is visualized with Verovio. This allows for the integration of different data formats, starting in the early days with texts, images and music and adding audio and even film within a single edition. The Edirom idea was born in 2004 at Musikwissenschaftliches Seminar Detmold/Paderborn and even after several years of Edirom development, the success of Edirom based on the same core concepts as in the beginning continues with numerous projects using and developing Edirom tools and creating digital musical editions with this software. Edirom tools were originally developed by the project Entwicklung von Werkzeugen f{\"u}r digitale Formen wissenschaftlich-kritischer Musikeditionen (2006--2012) funded by the DFG. The development of Edirom is now maintained as a community effort while being strongly supported and accompanied by Virtueller Forschungsverbund Edirom (ViFE), primarily based at Paderborn University. This poster aims to celebrate the release of the first stable version of Edirom and as a demonstration of successful collaboration in open source research software development.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Arjmand_2025,
  title = {{A Step Forward in Lute Tablature Studies with \textit{MEI.Tablature}}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Arjmand, Ailin and Seyedi, Reza},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {132--135},
  publisher = {Knowledge Commons},
  doi = {10.17613/frpq3-ytw66},
  urldate = {2025-07-08},
  abstract = {The Tablatures from the Albani Collection project, a collaboration between the Ricercar Lab at the Centre d'{\'E}tudes Sup{\'e}rieures de la Renaissance (Tours, France) and the Ente Olivieri in Pesaro (Italy), focuses on the rediscovered Albani archives: a collection of 38 music manuscripts containing lute music from the late Renaissance and early Baroque periods. By adopting the MEI.tablature module, the project encodes musical incipits, enriches them with detailed metadata, and integrates the results into the Ricercar database, making these valuable resources openly accessible through a IIIF viewer. The initiative tackles significant challenges related to MEI.tablature, including its limitations for early lute notation and the constraints of existing tools like Verovio, MuseScore, and Luteconv. To address these issues, the project introduces R{\'e}Tab, a web-based application designed to simplify and enhance the encoding of lute tablature. R{\'e}Tab offers a streamlined, customizable workflow, ensures synchronization between visualized tablature and MEI code, and accommodates historical notational practices. This project represents a notable advancement in digital musicology, contributing to the refinement of MEI.tablature and fostering broader adoption of standardized tools for music encoding. By providing open-access resources and innovative solutions, it paves the way for future research and digital dissemination of Renaissance musical heritage.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Bonde_2025,
  title = {Enhancing the Experience of Contemporary Classical Music through Dynamic, Interactive Visualisation},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Bonde, Anders and Meredith, David},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {127--131},
  publisher = {Knowledge Commons},
  doi = {10.17613/5qj0w-jsn47},
  urldate = {2025-07-08},
  abstract = {We explore the problem of designing dynamic, interactive visualisations in order to enhance the experience of contemporary classical music. We aim to address the well-recognized problem that contemporary classical music (CCM) receives minimal media attention and lacks prominent dissemination in mainstream culture. Recent empirical studies (Emerson, 2020) have suggested that adding appropriate extra-musical and audiovisual elements to a CCM performance can attract newcomers to this type of music and enhance audience experience. We identify four dilemmas that emerge when designing an effective visualisation, specifically, that a visualisation should (1) enhance the experience without distracting listeners from the music itself; (2) guide listeners through the music without constraining their interpretation; (3) possibly provide listeners with the option to control their experience, subject to the user interface being self-explanatory and only to the extent that this does not distract attention from the music; and (4) provide listeners with a means to locate themselves within the music, but without disclosing the music's development prematurely.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Cerveto-Serrano_2025,
  title = {{Kernpy: A Humdrum **Kern Oriented Python Package for Optical Music Recognition Tasks}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {{Cerveto-Serrano}, Joan and Rizo, David and {Calvo-Zaragoza}, Jorge},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {178--183},
  publisher = {Knowledge Commons},
  doi = {10.17613/qhvtd-hkv52},
  urldate = {2025-07-09},
  abstract = {We present kernpy, a Python package that provides comprehensive tools for working with symbolic modern and mensural notations in Humdrum format. It serves as an intermediary tool for data extraction and significantly enhances the performance of Optical Music Recognition Python workflows. kernpy addresses the scarcity of symbolic score datasets in **kern/**mens by enabling the creation of large-scale datasets. By integrating formal grammars, kernpy offers a unified software for handling Humdrum files within a single, cohesive and user-friendly interface. kernpy is a fully open-source project open to contributions available at https://github.com/OMR-PRAIG-UA-ES/kernpy.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Cividini_2025,
  title = {{Switching Between Standard and Original Score Order: Encoding, Transforming and Rendering Alternative Score Definitions in Digital Music Editions}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Cividini, Iacopo and {Mair-Gruber}, Roland and {Sapov-Erlinger}, Oleksii},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {61--65},
  publisher = {Knowledge Commons},
  doi = {10.17613/n7h15-jtq15},
  urldate = {2025-07-08},
  abstract = {Printed music editions face a critical dilemma in the definition of the score order. On the one hand, the standard score order established in the 20th century offers several practical advantages: it allows for a more compact score by grouping individual parts on a single staff, and it provides a convention that is broadly accepted and used for editions of works from all historical periods. On the other hand, the standard score order often differs significantly from the original parts arrangement chosen by the composer. As a result, it may overlook important aspects of the compositional process and the composer's intention in structuring the score in a particular way. Furthermore, the standard score order may no longer reflect the historical ensemble configuration originally intended by the composer, which could affect the performance interpretation of the work. For these reasons, some printed music editions have restored the original order of the scores. Using Mozart's Exsultate, jubilate KV 165 as a case study, the paper discusses a solution to the editorial dilemma in a digital edition by offering the option to choose between alternative score configurations. By encoding each part of a score in MEI as a semantically independent layer, each part can be relocated into alternative score configurations using a dedicated transformation tool. As a result, the MEI file, originally encoded in one score order, can potentially be displayed in any other score order. This finally enables switching between the standard and the original score order in a web application.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Desmond_2025,
  title = {{The Encoding of Insular Polyphony in English Mensural and Pre-mensural Notations}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Desmond, Karen},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {112--115},
  publisher = {Knowledge Commons},
  doi = {10.17613/2zcma-hb133},
  urldate = {2025-07-08},
  abstract = {The Music Encoding Initiative currently has two fairly robust modules for the encoding of vocal repertoire notated in important medieval notation systems, namely the MEI Neumes module (for plainchant) and the MEI Mensural Notation module (for polyphony). Franco's systematic rule-based system for mensural notation made a significant intervention in the history of music when he asserted that the notational symbol (the 'figure') ought to represent a fixed duration. But a significant portion of the western European polyphonic repertoire is notated in notations that preceded Franco's rule-based system that associated fixed durations to specific symbols, including, for example, the Aquitanian and Parisian polyphonic repertoires. BROKENSONG, a five-year project funded by an ERC Consolidator Grant, examines polyphonic singing and written culture in late medieval Britain and Ireland, from c. 1150-c. 1350. As part of the project, the entire extant repertoire is being encoded (approximately 600 compositions, many of them fragmentary, notated in approximately 120 fragmentary manuscript sources). While many compositions are notated in Franconian and extended Franconian notations, a large portion of the repertoire is notated in notations that can be broadly categorized as either modal, modal with Insular characteristics, and pre-mensural or mensural with Insular characteristics (Bent, Wibberley, Lefferts, Losseff). These notations are more flexible than standard Franconian notation and frequently informed by local practice. The interpretation may be dependent on notational dialects used in a particular geographic location, or by a particular scribe, or indeed the interpretation may be unclear. In this paper, I introduce two case studies from the BROKENSONG repertoire copied in Insular notation and present some of the most significant issues related to their encoding.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Dvorakova_2025,
  title = {{Visualizing Gregorian Traditions: ChantMapper}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Dvo{\v{r}}{\'a}kov{\'a}, Anna and {Haji{\v{c}} jr.}, Jan},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {143--151},
  publisher = {Knowledge Commons},
  doi = {10.17613/g378z-ppk48},
  urldate = {2025-07-08},
  abstract = {One of the major topics in Gregorian chant scholarship is the study of chant transmission and traditions: systematizing the variability of chant repertoire witnessed in sources across medieval Europe. Given that several hundred chant sources have been digitally catalogued, there is a clear opportunity for computational methods, but in the absence of ground truth against which to measure their accuracy, manual inspection of results by experts remains necessary. This in turn requires appropriate user interfaces for visualizing the results. Given that locations -- or transregionality -- are part of what defines the identity of a chant tradition, we believe this interface should involve a map. Hence, we present ChantMapper: a pilot web application for computational analysis of chant repertoire on a map. The interface can be used both to analyse traditions found by known methods (exemplified by Louvain community detection), as well as to inspect results of proposed methods (e.g. topic models). While the application provides a large dataset of antiphons and responsories extracted via Cantus Index and enriched with geocoding information users can upload their own datasets as well.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Einbond_2025,
  title = {{Encoding Interactive, Immersive, and Generative Electroacoustic Music}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Einbond, Aaron},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {118--124},
  publisher = {Knowledge Commons},
  doi = {10.17613/ee60x-jd298},
  urldate = {2025-07-08},
  abstract = {This short paper is presented as an invitation to explore the challenges of encoding music for instruments and interactive electronics including elements of immersive 3-D sound and generative computer improvisation. The topic of encoding electronic music has been addressed in the context of fixed media (Zwi{\ss}ler et al., 2021) but interactive electronics present specific challenges: it may involve acoustic instruments accompanied by computer, and both of these may vary from performance to performance due to human and computer improvisation. Further, the notation of the electronic part may follow different strategies from that of the acoustic instruments, including timbral and spatial information that can be specified using audio descriptors and higher order Ambisonics (HOA). A work for solo percussion and interactive 3-D electronics is presented as a case study to highlight these challenges.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Fiala_2025,
  title = {{A New XML Conversion Process for Mensural Music Encoding : CMME\_to\_MEI (via Verovio)}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Fiala, David and Pugin, Laurent and {van Berchum}, Marnix and Thomae, Martha and Roger, K{\'e}vin},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {31--35},
  publisher = {Knowledge Commons},
  doi = {10.17613/gwvsx-q0c26},
  urldate = {2025-07-08},
  abstract = {The Ricercar Lab --- the musicological research team at the Center for advanced Studies in the Renaissance at the University of Tours --- has decided to make available in open access, thanks to the support of the French digital infrastructure Biblissima, a large corpus of about 3500 XML files of 15th-c. music. This corpus was produced by the German musicologist Clemens Goldberg who encoded since 2010 onwards the musical content of 34 major 15th-c. music manuscripts and other complementary files, in order to offer on his foundation's website PDF files of complete collections of works by Du Fay, Binchois, Okeghem, Busnoys and most of their major contemporaries, focusing on their secular output. This corpus was encoded in an XML format named CMME (Computerized Mensural Music Editing), specifically conceived for mensural music by Theodor Dumitrescu in the 2000s, together with editorial and publication tools which have not been updated since then. This article focuses on the development of a set of conversion tools for these CMME files to meet more up-to-date standards of music encoding, namely MEI. A workshop was organised in September 2024 at the Campus Condorcet in Paris, gathering experts with a wide range of knowledge on mensural music notation, XML formats and programming. A converter was developped directly in the open-source rendering library Verovio, allowing the conversion from CMME to MEI mensural. A conversion to MEI CMN was implemented afterwards, enabling to load these files in common engraving softwares such as MuseScore with minimal loss of information. With the availability of a direct import of CMME-XML into Verovio, the corpus of existing CMME files gets a new life. Furthermore, since the stand-alone CMME editor still works fine and no alternative is available yet for native MEI, the converter offers a new pipeline for encoding and editing mensural music.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Finkensiep_2025,
  title = {{An Annotation Interface for Protovoice Analysis}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Finkensiep, Christoph and Rohrmeier, Martin},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {107--111},
  publisher = {Knowledge Commons},
  doi = {10.17613/1vkha-t8j47},
  urldate = {2025-07-08},
  abstract = {Expert annotations for corpus studies and computational models need to be processable by both humans and computers, which usually requires specialized tools. This paper presents a web-based annotation interface for creating protovoice analyses, a neo-Schenkerian model of hierarchical voice-leading reduction. The interface ensures the consistency of an analysis and supports data export in a machine-readable JSON format as well as visualizations in the form of TikZ/LaTeX and SVG. A separate viewer component can be used to embed interactive visualizations of an analysis in a website. The internal representations and manipulation operations used by the annotation and viewer components is provided by a shared library module which could be also used by other tools to implement extra functionality.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Friedl_2025,
  title = {{Challenges of Modelling Metadata for Film Music in MEI}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Friedl, Dennis and Reich, Silke},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {116--117},
  publisher = {Knowledge Commons},
  doi = {10.17613/tntzq-0e604},
  urldate = {2025-07-08},
  abstract = {Erich Wolfgang Korngold (1897--1957) contributions to Hollywood's "golden age" of film music between 1934 and 1946, particularly at Warner Bros., are widely recognised. Beginning with Max Reinhardt's adaptation of Mendelssohn's A Midsummer Night's Dream (1934/35), Korngold became a defining voice in the "Hollywood sound," crafting 19 film scores and winning Academy Awards for Anthony Adverse (1936) and The Adventures of Robin Hood (1939). The Erich Wolfgang Korngold Edition Project seeks to integrate his film music alongside his other compositions in a hybrid scholarly edition. This effort presents significant challenges, requiring the inclusion of traditional written sources (e.g., scores, sketches) and film-specific materials (e.g., scripts, cue sheets, audiovisual content). Such integration demands innovative digital and multimedia formats to account for the unique relationship between music and film. Korngold's film music exemplifies a deep interdependence with its visual counterpart. The bond between music and film is therefore exceptionally close, making the task of modelling this relationship particularly challenging. Within the FRBR framework, the film and its music can be treated as two distinct yet interconnected works. This intricate structure can be represented with all its variations, adaptations, and corresponding digital representations, as well as the relationships linking the two works. Representing this complexity necessitates balancing comprehensive metadata with resource limitations. Using The Adventures of Robin Hood as a case study, this paper examines how metadata standards such as MEI can be applied to represent film music and its intricate connections to film. It explores the suitability and limitations of MEI, considers alternative standards, and reflects on meaningful integrations of metadata for hybrid editions. Rather than presenting definitive solutions, the paper invites discussion on strategies to navigate these challenges in digital musicology.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Garcia-Iasci_2025,
  title = {{Evaluating Music Encoding Approaches: An Accuracy Analysis of Tools and Standards}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {{Garc{\'i}a-Iasci}, Patricia and Rizo, David and {Calvo-Zaragoza}, Jorge},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {189--194},
  publisher = {Knowledge Commons},
  doi = {10.17613/eepkj-etq50},
  urldate = {2025-07-09},
  abstract = {This paper considers different approaches for music encoding, evaluating user experience, accessibility, and readability, and accuracy with different software programs which musicologist, researchers, and musicians commonly use. A selection of monophonic pieces from The Dance Music of Ireland have been encoded in PAEC, MEI, MusicXML, and **kern, using manual direct encoding strategies, notation programs, and different OMR procedures. The result allows us to identify the most convenient method according to the needs of each user in each context.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Goebl_2025,
  title = {{Let's Do the ScoreWarp Again! Shifting Notes to Performance Timelines}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Goebl, Werner and Weigl, David M.},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {49--55},
  publisher = {Knowledge Commons},
  doi = {10.17613/gqd3b-w7c28},
  urldate = {2025-07-08},
  abstract = {Traditional approaches to visualize performance-related data captured while executing a musical score, rely usually on juxtaposing physical and score-time axes or connecting them with indicators, which can limit cognitive accessibility and interpretive clarity. This paper introduces ScoreWarp, a novel methodology and tool for aligning musical scores with performance timelines by shifting score elements horizontally to correspond with the temporal position of the performance timeline. This approach provides a seamless visual integration of music semantics with empirical timing data, eliminating the need for supplemental piano-roll visualizations or external alignment indicators. Using MEI-encoded scores engraved with the Verovio toolkit and alignment data from MIDI-to-MIDI matching algorithms, ScoreWarp adjusts the placement of individual notes, chords, and associated score elements such as slurs and dynamics. The tool offers two primary warping functions: one aligning chords to single timestamps and another visualizing fine-grained asynchronies at the note level, enabling the depiction of performance nuances like arpeggios or chord asynchronies. This methodology has been implemented in an open-source prototype, enabling users to generate warped SVG scores with physical time axes for integration into broader performance analysis tools. Potential applications include empirical research in music performance, psychology, and listener response, particularly for visualizing physiological and behavioral data in the context of performed music. Future work involves integrating ScoreWarp into comparative performance analysis tools and conducting user studies to evaluate its effectiveness in enhancing interpretive insights across diverse musical and empirical contexts.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Goya_2025,
  title = {{Exalting Natural Genius: Francesco Geminiani's Pedagogy of Harmonic Creativity}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Goya, Jonathan},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {81--87},
  publisher = {Knowledge Commons},
  doi = {10.17613/sm44z-knr59},
  urldate = {2025-07-08},
  abstract = {Francesco Geminiani published his Guida Armonica in 1752 with the express aim of liberating students of composition from, in his view, the confining and repetitive harmonic progressions of contemporary compositional pedagogy. The Guida consists of 2236 fragments of figured bass in D minor, each beginning and ending with one of 21 common chords. Complete passages of figured bass thus exist within the Guida network as paths through the common chord nodes and fragment edges. This presentation discusses the historical context of Geminiani's critique and presents a digital implementation of the Guida which facilitates the composition process with digital sort, filter, and edit functions. The implementation also includes an interface to find paths through the Guida network for search queries of bass pitch sequence. The search interface not only supplements the compositional process, but also opens the possibility of using the Guida as a tool for the analysis of 18th-century music. A full movement produced from the Guida fragments demonstrates the utility of the digital implementation and the harmonic variety contained within the Guida. Though the Guida is entirely in the key of D minor and typical 18th-century Rule of the Octave harmonizations of each scale degree are well represented, unusual harmonizations are also offered by the Guida --- often with the strong and weak beats offset compared to the paths using typical harmonizations. These unusual harmonizations reveal secondary key areas implicit in the Guida fragments and the interdependence of key, beat hierarchy, and sonority in the harmonic sensibilities of a well-regarded 18th-century composer and pedagogue.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Gronemeyer_2025,
  title = {{Encoding Non-Western Music Notation and Tonal Correspondances: A Case Study for Ottoman Music Sources}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Gronemeyer, Sven and Dimitriou, Marco and Pelen, Semih},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {25--30},
  publisher = {Knowledge Commons},
  doi = {10.17613/8a70g-j1g31},
  urldate = {2025-07-08},
  abstract = {Historically, numerous cultures and music traditions worldwide have developed their own notation systems, before Western staff notation became the de facto standard in notating music. There is evidence as ancient as Sumerian cuneiform to be used (Wulstan, 1971), and often, pitch signs were derived from a culture-specific writing system. The pitches themselves likewise depend on specific theories on harmony that led to the use of different scales. When working with historic, discontinued, or non-European notational systems, the emic concept of pitches and their corresponding signs must be correlated to Western staff notation in a critical edition. There is currently only native support of eurogenetic notations in MEI. The present paper showcases a solution of mapping emic pitch signs, pitch names, and Western staff notation, discussing Hampartsum notation used in the context of Ottoman music sources.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Jacquemard_2025,
  title = {{Automated MEI Transcription of a Dataset of Electronic Drum Kit Performances}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Jacquemard, Florent and {Rodriguez-de la Nava}, Lydia},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {70--74},
  publisher = {Knowledge Commons},
  doi = {10.17613/ts2pj-n8q68},
  urldate = {2025-07-08},
  abstract = {We present a method for the automated transcription of human performances on electronic drum kits, captured in MIDI files, into music scores in the MEI encoding. It works by parsing an input MIDI sequence into a tree-structured intermediate representation, using techniques from formal languages and NLP, post-processing the latter representation, with dedicated term rewriting rules, and exporting it into MEI. In an case study conducted on Magenta's Groove MIDI Dataset, we successfully transcribed, without pre-training or manual adjustments, 333 MIDI files of this dataset, covering various genres, time signatures, tempi and of length up to 260 measures.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Jaklin_2025,
  title = {{Wanted! Approaches for Search in Polyphonic Lute Music}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Jaklin, Julia Maria},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {139--142},
  publisher = {Knowledge Commons},
  doi = {10.17613/a1h7s-c6h54},
  urldate = {2025-07-08},
  abstract = {Search is one of the key issues in music information retrieval. For symbolically encoded, unvoiced polyphonic music---such as music notated in various types of lute tablatures---this is not an easy task. This poster aims to present the requirements of searching within lute tablatures, present examples of existing methods and approaches, and ask for feedback and further ideas for the development of a search within lute tablatures.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Kepper_2025,
  title = {{Let's Get Visual. Dealing with Layout Information in MEI}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Kepper, Johannes and Pugin, Laurent},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {66--69},
  publisher = {Knowledge Commons},
  doi = {10.17613/hf8kc-beg40},
  urldate = {2025-07-08},
  abstract = {This paper addresses the challenges of encoding visual layout information in MEI, which traditionally prioritizes logical structures, such as measures and sections, over visual domains like pages and systems. While this design simplifies logical encoding, it complicates visual representation and limits flexibility for use cases like diplomatic transcriptions. Diplomatic transcriptions require precise encoding of note placement and alignment, which can benefit from separating visual and logical domains into parallel, interlinked encodings. Similarly, Optical Music Recognition (OMR) workflows, which link graphical signs to music symbols, could leverage MEI at multiple stages using facsimile-based solutions, already supported in MEI through and elements. Rendering tools like Verovio could also integrate visual positioning, though challenges remain for complex cases like slurs crossing page breaks. By proposing methods that balance logical and visual perspectives, this paper suggests an adaptable approach for layout-centric use cases, aiming to encourage discussions within the music encoding community to refine MEI's capabilities.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Kijas_2025,
  title = {{Digital Pedagogy \& Public Musicology Round Table}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Kijas, Anna E. and Grimmer, Jessica and Wissner, Reba and Robin, William},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {214--216},
  publisher = {Knowledge Commons},
  doi = {10.17613/jtj6p-atz44},
  urldate = {2025-07-09},
  abstract = {Student-centered digital pedagogy and projects enable simultaneous engagement with music history and literature as content while developing expertise in critical digital literacy skills. Through assignments or projects that employ music encoding standards, data curation, or creation of public facing scholarship students develop transferable skills that can be applied beyond the classroom and academy. Their knowledge is made visible through open-access projects that can become a resource for future students or scholars in the form of encoding, mapping, and other novel forms of disseminating information. Furthermore, such publicly available forms of publication aim to be inclusive, projecting knowledge and resources beyond the academy. In this roundtable, we bring together scholars and practitioners with backgrounds in public musicology, digital humanities, libraries, archives, and music encoding who will share their experiences in leveraging digital humanities methods and tools to engage students in experiential praxis-centered music courses and projects. Drawing on experiences teaching a seminar on music and public scholarship, Will Robin will address how to teach students the concept of the public. One longstanding problem of the phrase "public musicology" has been the assumption that there is a single, unified "public" waiting for scholars to reach it; in this presentation, Robin will discuss the idea of publics: how to conceive work aimed towards imagined and real non-academic audiences, and how to help students execute projects that draw on existing publics or develop new ones. As part of the public musicology program at Columbus State University, students take four courses in which they undertake several digital musicology projects including editing and encoding music in manuscript form using MEI, database entry, and use of online digital content management systems for exhibits and archiving. After giving a brief overview of the program, Reba Wissner will discuss how music encoding and digital musicology are fundamental public musicology skills for every music student, and how these skills can be incorporated into almost any music history course. Working with information students presents a unique approach to digital musicology. With an emphasis on creating space for close reading, for preservation, and for generating material that will be useful to future users and researchers, students in a special topics course on Music Encoding at the University of Maryland School of Information encoded a corpus of works by Carrie Jacobs-Bond, based on archival manuscripts at the Library of Congress. They subsequently collaboratively wrote a best practices paper for others embarking on encoding projects. Jessical Grimmer will discuss how this course equips students with technical and conceptual skills in digital humanities fostering connections between scholarly work and public engagement. She will also highlight strategies for using MEI to create accessible, sustainable, and community-focused digital resources.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Klauk_2025,
  title = {{Visualizing Wagner: A Combined Annotational Approach to Siegfried Act III}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Klauk, Stephanie and Schmolenzky, Pascal and Kleinertz, Rainer and Wei{\ss}, Christof and M{\"u}ller, Meinard},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {184--188},
  publisher = {Knowledge Commons},
  doi = {10.17613/x2vba-xn564},
  urldate = {2025-07-09},
  abstract = {After the controversial large-scale analyses of Richard Wagner's Der Ring des Nibelungen by Alfred Lorenz, Anthony Newcomb was the first to present new perspectives on large-scale Wagner analysis in 1981. One of his examples was the first scene of the third act of Siegfried. Both Lorenz's and Newcomb's analyses will be evaluated and discussed using visualisations of computational analyses of harmony and tempo based on audio files.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Koester_2025,
  title = {{The Computational Study of Musical Form: Challenges for Encoding and Analysis}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {K{\"o}ster, Maik and Hentschel, Johannes and Neuwirth, Markus},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {88--96},
  publisher = {Knowledge Commons},
  doi = {10.17613/sxjqb-p5r44},
  urldate = {2025-07-08},
  abstract = {Form can be viewed as a high-level structural domain of music, which is informed by and interacts with other domains, such as tonal structure, metric structure, repetition structure as well as texture and orchestration. The ways in which the musical parameters influence form and warrant the use of the given analytical terms are, however, rarely made explicit. In our contribution, we assess what is needed to encode analyses of musical form in a way that explicitly models the multi-dimensional interplay between structural domains and emergent formal functions. The needs that this research endeavour poses include support for symbolic as well as audio representations, annotation of timespans as well as events on the note or stave levels, and the ability to bring together different types of analyses, ideally in a user-friendly GUI. A survey of five current annotation tools shows that the desired features are currently dispersed among different apps. We therefore suggest integrating the strengths of different tools using stand-off annotations. The envisioned solution, consisting in combining different annotation apps via the consistent intermediary representation of time, and using a rich uniform ontology, enables the unification of diverse datasets and hence facilitates the study of musical form on a large scale.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Lanz_2025,
  title = {{Making Computational Study of Gregorian Melody Accessible with ChantLab}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Lanz, Vojt{\v{e}}ch and Szabov{\'a}, Krist{\'i}na and {Haji{\v{c}} jr.}, Jan},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {157--163},
  publisher = {Knowledge Commons},
  doi = {10.17613/z50gm-qf714},
  urldate = {2025-07-08},
  abstract = {Computational methods for studying Gregorian chant melodies are being developed, but musicologists face technical barriers to applying them, and computer scientists may not have the depth of musicological knowledge required to use them effectively. Part of the [redacted] project's aims is to bridge this gap. To this end, we present ChantLab: a web application for analysing large sets of Gregorian melodies. Specifically, ChantLab implements multiple sequence alignment and phylogenetic tree building, The application visualises the results through an interactive user interface, exports them in widely used formats, and supports custom dataset. ChantLab is available at https://quest.ms.mff.cuni.cz/chantlab},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Lewis_2025,
  title = {{'Mein Vleis Und Mue': MEI Support for Lute Tablatures}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Lewis, David and Janju{\v{s}}, Olja and {de Valk}, Reinier and Weigl, David M. and Crawford, Tim and Overell, Paul and Sch{\"o}ning, Kateryna},
  editor = {Lewis, David and Stremel, Sophie and Plaksin, Anna},
  year = {2025},
  pages = {75--80},
  publisher = {Knowledge Commons},
  doi = {10.17613/f5xjr-jj674},
  urldate = {2025-07-08},
  abstract = {Tablatures differ from other music notation types in that they do not describe abstract music semantics directly, but rather prescribe actions for the musician(s) performing the music. Though tablature notations exist for many instruments (e.g. keyboards and accordions), it has central importance for plucked-string instruments such as the lute (from the late 15th to the 18th century) and guitar (particularly in popular music of the 20th century). We are pleased to announce the inclusion of plucked string tablatures into MEI 5.1, with a particular focus on historical notation for the lute and related instruments. In our paper, we describe the community process that has given rise to this, the changes to the schema and guidelines, and the tooling that supports working with tablature in MEI.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Mantica_2025,
  title = {{Towards a Digital Critical Edition of the Operas of Vincenzo Bellini}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Mantica, Candida Billie and Meriani, Giovanni and Saccomano, Mark Scott and Maccarini, Francesco},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {201--205},
  publisher = {Knowledge Commons},
  doi = {10.17613/2qn07-r6523},
  urldate = {2025-07-09},
  abstract = {Established in 2003, the Edizione critica delle opere di Vincenzo Bellini (Milan, Ricordi) plans to publish all of Bellini's music in a critical edition, serving a dual purpose: philological, to render musical texts that reflect authorial intention; and practical, to provide users and performers with reliable scores that correct errors perpetuated by traditional editions. Its traditional printed book format presents, however, several practical limitations: a) it does not allow simultaneous visualization of alternative materials; b) users lack access to the sources on which the volumes are based; c) the text of the main score cannot be modified, preventing the use of alternative materials. This poster illustrates the research objectives of the NextGenerationEU-funded project VerDigital (University of Pavia), which intends to overcome these limitations by combining the meticulous editorial approach of the series with tools offered by digital musicology. Specifically, VerDigital will employ the Edirom digital tools and Verovio to develop two interconnected models. 1) A model of digital critical edition using Bellini's "Adelson e Salvini" as a case study. The model does not simply provide encodings (MEI) of the individual sources, which do not allow for the reconstruction of a complete edited text that can be used by performers. Instead, it also presents an encoding of the edited text, offering data to retrace the editorial process. Relying on a tailored combination of Edirom, MEI and Verovio, the model develops an interactive system of fruition, allowing performers to choose among alternative readings/versions to customize their score/parts. 2) The second model focuses on Bellini's so-called 'studi giornalieri', attesting the first phases of his creative process. The model aims at connecting two different encodings: a 'diplomatic-interpretive' one, based on the actual spatial organization of the annotations in the pages, and another 'linearized' transcription, centered on the textual features of every fragment.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Nachtwey_2025,
  title = {{Beyond Bars: Distribution of Differences in Music Prints}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Nachtwey, Adrian and Moss, Fabian C.},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {136--138},
  publisher = {Knowledge Commons},
  doi = {10.17613/8cw62-5mt26},
  urldate = {2025-07-08},
  abstract = {Our goal is to analyse differences between prints of Beethoven's Piano Sonatas. Since there is a huge number of prints, we will only compare sample encodings instead of full encodings. The aim of the presented work is to evaluate three different algorithms to draw these samples and find the one which draws the samples that best represent the prints. To that end we used six editions of Beethoven's Bagatelles Op. 33 as a test group and drew 1000 samples from each Bagatelle for each algorithm. Then, encodings of these samples were compared, resulting in 45.000 comparisons for each Bagatelle. To visualize the results, they are being plotted, so that the number of differences can be seen on the x-axis and the frequency, with which this number of differences occurs, on the y-axis. As a result we obtain a normal distribution for each of the algorithms but with different scale parameters. We interpret this finding to demonstrate that thinking of music in terms of bars is not sufficient to find a sample that represents the basic population. Instead, it is necessary to take into account the density of the musical events in the scores.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Neumann_2025,
  title = {{Building an Interpretations-Edition}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Neumann, Joshua},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {56--60},
  publisher = {Knowledge Commons},
  doi = {10.17613/s1t13-r3z56},
  urldate = {2025-07-08},
  abstract = {Digital editions of music represent the fusion of musicology's longstanding focus on philological questions with the affordances of technological flexibility for data modelling, encoding, and presentation, along with possibilities for rapid and broad dissemination. Parallel to analogue musicological work, the focus remains on the concept of works and the identification and compilation of authoritative or definitive editions. Notably absent in both spheres are the contributions of performers and the acknowledgment that music is foremost a sounded entity rather than only a written one. Of course, exponentially more challenges exist for documenting the process of performance than the fixity of a written score. A first step in the direction of addressing some of these challenges still lies within the area of philology, albeit with a different purpose than has been conventional: an Interpretations Edition. Here, the goal is to account for diverse interpretive instructions appearing in a variety of score editions. In the case of project design, of course, a primary challenge is how to balance the usual plethora of editions against a corpus of recordings for interpretations-analysis. Curating the edition to the specific needs of a project thus becomes of paramount importance. More than exhibiting the conceptual variations in the use of MEI for this kind of work, this paper reinforces the importance of balancing technological development with the best ethical practices of edition making as historiographical praxis.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Obert_2025,
  title = {{Sketching Genetic Editions: Challenges and Opportunities}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Obert, Salome and Seipelt, Agnes and Paciotti, Alessandra and Raunisi, Cecilia and Rosendahl, Lisa},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {208--213},
  publisher = {Knowledge Commons},
  doi = {10.17613/ryvf1-y3w06},
  urldate = {2025-07-09},
  abstract = {The digital humanities have been changing scholarly methodologies in musicology for quite a while now. With this panel we would like to explore the possibilities of musicological genetic editions also in the digital realm. Bringing together four doctoral students with different backgrounds, experts on various 19th century composers, the discussion aims to address critical questions about the nature, scope, and practical implementation of genetic criticism into digital editions. Our focus extends beyond the territory of the well known project Beethovens Werkstatt, examining how new approaches can accommodate a wide array of musical repertoires, sources, and creative processes. Each panelist will pitch their research, highlighting the unique selling points of their projects, the challenges posed by their sources, and the innovative models, tools and concepts used to address these challenges. The panel is organized around four case studies: the sketches and autograph manuscript for Beethoven's Bagatelle Op. 126, Franz Liszt's autograph manuscript for the Sonata in B minor, the preparatory materials for Carl Maria von Weber's opera Die drei Pintos, and the surviving compositional sketches of Johannes Brahms. Collectively, these studies offer a multifaceted view of how digital genetic editions can address diverse repertoires and reveal the creative dynamics embedded in musical documents. Digital genetic editions represent an attempt to document and analyze the creative process of composition through a dynamic representation of its textual and musical sources. These editions seek to move beyond the final stage of the work by shedding light on the intermediary stages of creation. Beethovens Werkstatt -- a joint research project by the Beethoven-Haus Bonn (Germany) and the Department of Musicology Detmold/Paderborn (Germany), funded by the Academy of Sciences and Literature Mainz (Germany) -- plays a pioneering role in the field of genetic text criticism in music and digital editions. It is a fundamental research project that, for the first time, presents a series of concepts and models, as well as a glossary, for the investigation of writing and compositional processes in music and their digital representation and communication. Each panelist will introduce a case study, illustrating how their project expands the boundaries of genetic editions and illustrates the extent to which the research subject could reuse the concepts and (data) models from Beethovens Werkstatt and where there is a need to modify or extend them. The case studies expand the focus beyond a single composer's workshop, addressing different genres/repertoires and creative contexts. They invite comparisons and contrasts, offering insights into how the lessons of Beethovens Werkstatt can be adapted to different challenges, from Liszt's fluid revisions to the openness of the Weber manuscript. The presented sources reveal distinct challenges and possibilities for genetic editions, also in digital form. By focusing on these themes, the panel aims to inspire a broader conversation about the future of digital genetic editions in musicology. Ultimately, this panel envisions a future where digital genetic editions become a central tool for understanding and engaging with the creative processes of composers.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Page_2025,
  title = {{Annotating Music Scores: Representing and Interacting with Annotations with MEI and Verovio}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Page, Kevin R. and Pugin, Laurent and Weigl, David M.},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {222--225},
  publisher = {Knowledge Commons},
  doi = {10.17613/8q6rc-es750},
  urldate = {2025-07-09},
  abstract = {This half-day workshop will address annotations of musical scores, considering their role and structure, and strategies for representing, encoding and visualising them. The workshop will combine presentations, discussion and hands-on activities with new versions of Verovio and mei-friend. Annotation is an activity common across many walks of life and, for music, it unites scholars, musicians, teachers and composers. The practice is extremely varied, both in the forms it takes and the purposes it serves, and it is used for both physical and digital material. Digital annotations refer to highlights, circles, references, links or other selections made on digital documents or media. User-generated annotations are increasingly seen as a key mechanism for the use and reuse of digital materials across a wide range of applications, while also enhancing the findability and accessibility of that media through its annotations. While the importance of annotations in music notation is generally acknowledged, there is less of a consensus on how best to integrate them into interoperable software applications. Annotations for music can encompass the association of textual observations with regions of a work; cross-reference between musical passages or from a musical passage to some other, non-musical, material; or they might include categorical or structured music-analytical annotations, such as metrical or harmonic labels; most commonly, perhaps, they are used by musicians and teachers for sharing or remembering aspects of musical interpretation. Approaches taken in the digital domain include graphical, drawn overlays on top of an engraved score (which is popular in software for musicians and teachers), the use of URLs to specify score regions to be extracted and drawn by a web service (EMA, used by the CRIM project), Web Annotations (a Linked Data standard used by the MELD framework) and the MEI element itself. Given this diversity, it is essential to align implementation to specific needs and use cases rather than assuming a universal solution. This workshop consolidates a review of existing digital score annotation implementations, presenting new recommendations for enhanced annotation practice in MEI, and with hands-on experiments for implementing these recommendations in Verovio and mei-friend.},
  bibbase_note = {<span style="color: green; font-weight: bold">Workshop.</span>},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Peter_2025,
  title = {{How to Infer Repeat Structures in MIDI Performances}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Peter, Silvan David and Hu, Patricia and Widmer, Gerhard},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {173--177},
  publisher = {Knowledge Commons},
  doi = {10.17613/vbe6s-rds89},
  urldate = {2025-07-09},
  abstract = {MIDI performances are generally expedient in performance research and music information retrieval, and even more so if they can be connected to a score (Cancino-Chac{\'o}n et al., 2018, Peter et al., 2023). This connection is usually established by means of alignment, linking either notes or time points between the score and the performance. The first obstacle when trying to establish such an alignment is that a performance realizes one (out of many) structural versions of the score that can plausibly result from instructions such as repeats, variations, and navigation markers like 'dal segno/da capo al coda'. A score needs to be unfolded, that is, its repeats and navigation markers need to be explicitly written out to create a single timeline without jumps matching the performance, before alignment algorithms can be applied. In the curation of large performance corpora this process is carried out manually, as no tools are available to infer the repeat structure of the performance (Bukey et al., 2024). To ease this process, we develop a method to automatically infer the repeat structure of a MIDI performance, given a symbolically encoded score including repeat and navigation markers. The intuition guiding our design is: 1) local alignment of every contiguous section of the score with a section of a performance containing the same material should receive low alignment cost, whereas local alignment with any other performance section should accrue a high cost. And 2) stitching local alignments together according to a valid structural version of the score should result in an approximate full alignment and correspondingly low global backtracking cost if the structural version corresponds to the performance, and high cost for all other, ill-fitting structural versions.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Phan_2025,
  title = {{Plainchant Analyser for MEI Neumes: A Tool for Understanding Chant Transmission}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Phan, Antoine and Thomae, Martha E. and {{De Luca}}, Elsa and Orio, Francesco},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {36--48},
  publisher = {Knowledge Commons},
  doi = {10.17613/jm6rw-btm49},
  urldate = {2025-07-08},
  abstract = {With the widespread use of the web browser, we present the Plainchant Analyser for MEI Neumes (PAM), a web application that gives musicologists the ability to search and analyse historical chants encoded in the Music Encoding Initiative (MEI) Neume format. PAM provides a wide range of features, including search by chant characteristics, metadata, text, and melodic patterns using pitches and/or contour. Its analysis toolkit allows users to examine note frequency, finalis (final pitch), ambitus (melodic range), and placements of ornamental notes. A modern visualisation of the chants is also available through the Verovio engraver tool. PAM empowers early music scholars to make sophisticated melodic comparisons and analysis, fostering a more nuanced understanding of centuries-old historical chants.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Pineo_2025,
  title = {{Using MEI to Create Accessible Music Scores: Findings from a Pilot Study}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Pineo, Elisabeth Anne},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {99--103},
  publisher = {Knowledge Commons},
  doi = {10.17613/b8j2q-wn251},
  urldate = {2025-07-08},
  abstract = {In online archives, music scores are typically available as PDF or JPEG files, and most newly created music scores are PDFs; if they are archived, it is usually as a PDF or PDF/A (Akau, McKinney, \& McNellis, 2023). Unfortunately, these formats are frequently inaccessible to Disabled users because they are incompatible with many assistive technologies. MusicXML and MEI files can be converted to accessible file types, but archives do not use them as frequently as PDFs or JPEGs. As a result, most archives' digital music scores are inaccessible to many Disabled users. Encoding scores using MEI makes them compatible with MuseScore, which can be used to create accessible score file formats. Therefore, this paper will present the findings of an exploratory study that examines the feasibility of regularly creating these file types for use and dissemination in an online archive setting.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Polyakov_2025,
  title = {{Encoding the New Frontier: Adapting MEI and Verovio for Post-Tonal and Spectral Notations}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Polyakov, Egor},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {152--156},
  publisher = {Knowledge Commons},
  doi = {10.17613/exk9y-s3x74},
  urldate = {2025-07-08},
  abstract = {This paper examines the challenges and strategies involved in encoding post-tonal and spectral musical notations within the Music Encoding Initiative (MEI) format for rendering with the Verovio library. While Verovio has become a streamlined and efficient tool for displaying standard music notation, its application to contemporary scores featuring microtonality and non-traditional symbolic elements presents significant hurdles. This proposal introduces AudioSpylt, a Python-based toolset leveraging Verovio to visualize pitch structures derived from audio analysis. AudioSpylt employs MEI in unconventional ways to represent data exceeding the limitations of standard notation, approximating complex elements found in environments like OpenMusic. By critically assessing these "hacks" for encoding microtonal pitch data and graphic notations within a Python/Jupyter environment, this paper highlights both the practical benefits of such approaches for specialized research and the inherent limitations of current standards. The increasing prevalence of publicly available microtonal and spectral scores necessitates a broader discussion about expanding MEI's capabilities. This paper advocates for a more inclusive and robust encoding environment within MEI and Verovio to facilitate the accurate representation and analysis of the full spectrum of contemporary musical practices.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Rettinghaus_2025,
  title = {{Pushing the Standard to Its Limits: MuseScore as a Feature-Complete MusicXML Editor}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Rettinghaus, Klaus},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {195--197},
  publisher = {Knowledge Commons},
  doi = {10.17613/60310-z4n65},
  urldate = {2025-07-09},
  abstract = {The de facto standard format for the exchange of symbolic music notation today is MusicXML and will remain so for the foreseeable future, as its successor MNX is still far from being stable or complete. Twenty years have passed since the first version was published at the beginning of 2004, and the format has developed considerably since then and the encoding possibilities have been greatly expanded. Since MuseScore is open source and has made great progress in development since the release of version 4.0 at the most, it was decided to address missing or incorrectly implemented MusicXML support features. The ultimate goal would be to have a feature-complete MusicXML editor with MuseScore that is capable to preserve almost all engraving details in the exported MusicXML files.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Richts-Matthaei_2025,
  title = {{Is It a Work -- and If Yes, How Many? Considerations for the Further Development of a Metadata Editor for MEI Data}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {{Richts-Matthaei}, Kristina and Schmitz, Annabella},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {198--200},
  publisher = {Knowledge Commons},
  doi = {10.17613/9cbcm-p4942},
  urldate = {2025-07-09},
  abstract = {Work on catalogs of works and source lists is currently undergoing major changes. Many of them started out analogue and have to endure the transfer to digital, others are designed directly digitally and are confronted with data modelling issues that need to be considered right from the start. For this latter case, there is still no solution according to the current state of research, as much of this is currently still under development and many things still need to be standardized and defined. Software development must also respond to these considerations when developing a metadata editor that can be used as generically as possible to record metadata for digital musicology. This presentation aims to show the requirements and needs for this infrastructural design process, and also illuminates underway work that is attuned to multicultural and multinational research contexts and their expectations.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Stickler_2025,
  title = {{A Minimal Publishing Model for Text and Music Notation}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Stickler, Felicitas and Roeder, Torsten and Moss, Fabian C.},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {104--106},
  publisher = {Knowledge Commons},
  doi = {10.17613/fv740-yvf93},
  urldate = {2025-07-08},
  abstract = {This paper introduces a minimal publishing model tailored for digital editions that incorporate both text and music notation. While established encoding standards like TEI and MEI are well-suited for text or music individually, their integration poses significant challenges for interdisciplinary projects such as music theory treatises, composers' correspondence, and sheet music editions with peritexts. To address these issues, we propose a sustainable approach using Verovio and CeTEIcean for dynamic rendering, emphasizing direct data generation without intermediate formats. The proposed model simplifies data organization, synchronizes rendering processes, and ensures low-cost deployment through platforms like GitHub Pages and Zenodo. This method not only supports resource-constrained projects but also serves as a blueprint for the TEI Music SIG to harmonize text and music encoding. The approach will be implemented in the Digitizing the Dualism Debate project, aiming to enrich the presentation of dense text-music relationships and lay the groundwork for future digital editions of hybrid materials.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Stutter_2025,
  title = {{Towards New Representations and Methodologies for Detecting Concordances in Symbolic Music Corpora Pre-1600}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Stutter, Joshua},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {164--166},
  publisher = {Knowledge Commons},
  doi = {10.17613/hxt3k-kcx31},
  urldate = {2025-07-08},
  abstract = {This poster investigates new methodologies for feature extraction and representation learning in detecting concordances within pre-1600 symbolic music corpora. Unlike the fixed and discrete works of the common practice period, Medieval and Renaissance music often survives in multiple, divergent versions, giving rise to complex intertextual relationships. While traditional catalogues raisonn{\'e}s and rules-based computational tools have made significant contributions to concordance detection, they are limited by their reliance on hand-crafted features that struggle to capture the more fluid, formulaic aspects of early music. Responding to recent critiques that the small size of early music datasets limits the applicability of post-2020 AI methods, this study argues instead that the challenge lies in how early notation is represented for computational analysis. Using the CANDR dataset of 13th-century polyphony, three feature extraction methodologies are evaluated: hand-crafted melodic features (via jSymbolic and music21), learned monophonic embeddings using Word2Vec, and polyphonic graph-based embeddings using a relational graph convolutional network (R-GCN). Each resulting vector space is assessed using silhouette score, Calinski--Harabasz index, and logistic regression classification. The analysis demonstrates that while all approaches offer insights, R-GCN-based representation learning outperforms hand-crafted feature extraction across all metrics by capturing richer polyphonic context and hierarchical structure. These findings suggest that, contrary to claims of data paucity, early music contains substantial untapped data potential when approached with appropriate representation learning methods. The poster argues for developing new methodologies grounded in learned representations to advance the detection and understanding of concordances in early music.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Thomae_2025,
  title = {{Navigating and Processing MEI Data with XPath and XSLT}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Thomae, Martha E. and Roland, Perry and Kepper, Johannes},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {219--221},
  publisher = {Knowledge Commons},
  doi = {10.17613/8mjs0-b0h87},
  urldate = {2025-07-09},
  abstract = {This workshop is intended for individuals with some knowledge of MEI who want to learn how to work with XML markup for research and analysis. It provides a hands-on introduction to XPath, a powerful query language for XML documents, and XSLT, a language for transforming XML data. By engaging with XSLT's functional programming approach, participants will explore ways to articulate and investigate research questions rooted in an XML-based document model. The emphasis of our workshop is both processing data (or metadata) for MEI to MEI or MEI to HTML conversion, and extracting data (or metadata) from MEI documents for analysis. Markup in documents supplies structures and contexts that are especially useful for processing data beyond what we can do with "plain text." Most of the workshop will focus on learning basic XPath navigation and some calculation functions. After this, we will show how XPath is applied in XSLT templates to address specific elements that hold data of interest for visualization (e.g., notes) and exemplify some fundamental transformations. We will produce simple structured documents for storing, sharing, and visualising data during the workshop: HTML lists and TSV files. We look forward to processing some participant-supplied MEI before, during, and after the workshop. We will carefully document the XSLT we supply during the workshop to help participants revise and adapt the code to their projects.},
  bibbase_note = {<span style="color: green; font-weight: bold">Workshop.</span>},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Wissmann_2025,
  title = {{Stravinskys Way of Sketching -- A Digital Preparation of the Sketches for "Le Sacre Du Printemps"}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Wi{\ss}mann, Jelena},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {171--172},
  publisher = {Knowledge Commons},
  doi = {10.17613/f4wk6-g4f42},
  urldate = {2025-07-08},
  abstract = {The premiere of "Le Sacre du Printemps" has been the subject of much discussion within the field of musicology due to the perceived scandal surrounding the piece. Nevertheless, the work is widely regarded as one of the most significant compositions of the 20th century. Despite this recognition, the genesis of the piece remains underexplored, as no musical edition of the work or its sketches currently exists. This project seeks to address this gap by creating an initial approach of a digital edition that not only provides access to Stravinsky's original sketches and their edited versions but also offers insights into his compositional process. The focus is on the section "Les Augures printaniers", allowing a detailed reconstruction of its compositional development. The sketches were edited according to standard practices, annotated, and encoded using the Music Encoding Initiative (MEI) standards to ensure machine readability. The Verovio software was used for visualization, enabling direct comparisons between sketches and the final score, presented on the created website. The chronological organization of the sketches reveals Stravinsky's method of mechanically assembling motifs into larger structures rather than developing them organically. This approach highlights Stravinsky's special compositional strategies and offers new perspectives on his creative process. By combining edited sketches, textual analysis, graphical representations, and digital tools, the project proposes a model for the digital edition of Le Sacre du Printemps, demonstrating the value of such editions for musicological research.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}

@inproceedings{Yang_2025,
  title = {{Music with Numbers: Jianpu Number-Based Notation in Cultural Heritage and Digital Humanities}},
  booktitle = {{Music Encoding Conference 2025 -- Book of Abstracts}},
  author = {Yang, Rui and Giraud, Mathieu and Lev{\'e}, Florence},
  editor = {Lewis, David and Plaksin, Anna and Stremel, Sophie},
  year = {2025},
  pages = {12--24},
  publisher = {Knowledge Commons},
  doi = {10.17613/cjjtg-yar17},
  urldate = {2025-07-08},
  abstract = {Number-based music notation (NMN) offers an intuitive way to represent music, using numbers to denote pitches. Widely used in Chinese music education, it serves both as an accessible entry point for learners and as a comprehensive system for expressing and conceptualising music. NMN's versatility and adaptability both stem from and are influenced by musical education systems across various cultures, helping students engage with music straightforwardly and effectively. We examine NMN's historical and modern usage in both Eastern and Western contexts, highlighting the extensive adoption of Jianpu in 20th and 21st-century China. We also explore its integration into computer music software, databases, and encodings. We discuss how NMN can represent both simple and complex musical structures, emphasizing its potential for broader incorporation into digital humanities initiatives, including encoding systems such as MEI.},
  keywords = {mec-proceedings, mec-proceedings-2025},
  displayby = {Contributions from MEC 2025}	
}
