% This file was created with Citavi 6.1.0.0
% created 2018-05-05
% modified 2018-06-06

@inproceedings{Bell_2016,
 abstract = {Conductor copies of musical scores are typically rich in handwritten annotations. Ongoing archival efforts to digitize orchestral conductors' scores have made scanned copies of hundreds of these annotated scores available in digital formats.

The extraction of handwritten annotations from digitized printed documents is a difficult task for computer vision, with most approaches focusing on the extraction of handwritten text. However, conductors' annotation practices provide us with at least two affordances, which make the task more tractable in the musical domain.

First, many conductors opt to mark their scores using colored pencils, which contrast with the black and white print of sheet music. Consequently, we show promising results when using color separation techniques alone to recover handwritten annotations from conductors' scores.

We also compare annotated scores to unannotated copies and use a printed sheet music comparison tool to recover handwritten annotations as additions to the clean copy. We then investigate the use of both of these techniques in a combined method, which improves the results of the color separation technique.

These techniques are demonstrated using a sample of orchestral scores annotated by professional conductors of the New York Philharmonic. Handwritten annotation extraction in musical scores has applications to the systematic investigation of score annotation practices by performers, annotator attribution, and to the interactive presentation of annotated scores, which we briefly discuss.},
 author = {Bell, Eamonn and Pugin, Laurent},
 title = {Approaches to Handwritten Conductor Annotation Extraction in Musical Scores},
 pages = {33–36},
 publisher = {{Association for Computing Machinery}},
 isbn = {978-1-4503-4751-8},
 series = {ACM International Conference Proceedings Series},
 editor = {Fields, Ben and Page, Kevin},
 booktitle = {DLfM 2016. Proceedings of the 3rd International Workshop on Digital Libraries for Musicology},
 year = {2016},
 address = {New York, NY},
 doi = {10.1145/2970044.2970053}
}


@inproceedings{Burlet_2012,
 abstract = {This paper introduces Neon.js, a browser-based music notation editor written in JavaScript. The editor can be used to manipulate digitally encoded musical scores in square-note notation. This type of notation presents certain challenges to a music notation editor, since many neumes (groups of pitches) are ligatures–continuous graphical symbols that represent multiple notes. Neon.js will serve as a component within an online optical music recognition framework. The primary purpose of the editor is to provide a readily accessible interface to easily correct errors made in the process of optical music recognition. In this context, we envision an environment that promotes crowdsourcing to further the creation of editable and searchable online symbolic music collections and for generating and editing ground-truth data to train optical music recognition algorithms.},
 author = {Burlet, Gregory and Porter, Alastair and Hankinson, Andrew and Fujinaga, Ichiro},
 title = {Neon.js. Neume Editor Online},
 url = {http://www.ismir2012.ismir.net/event/papers/121_ISMIR_2012.pdf},
 publisher = {{FEUP Edi{\c{c}}{\~o}es}},
 editor = {Gouyon, Fabien and Herrera, Perfecto and Martins, Luis Gustavo and M{\"u}ller, Meinard},
 booktitle = {Proceedings of the 13th International Society for Music Information Retrieval Conference, ISMIR 2012, Mosteiro S.Bento Da Vit{\'o}ria, Porto, Portugal, October 8-12, 2012},
 year = {2012},
 pages = {121–126}
}


@inproceedings{Burlet_2013,
 abstract = {This paper presents Robotaba, a web-based guitar tablature transcription framework. The framework facilitates the creation of web applications in which polyphonic transcription and guitar tablature arrangement algorithms can be embedded. Such a web application is implemented, and consists of an existing polyphonic transcription algorithm and a new guitar tablature arrangement algorithm. The result is a unified system that is capable of transcribing guitar tablature from a digital audio recording and displaying the resulting tablature in the web browser. Additionally, two ground-truth datasets for polyphonic transcription and guitar tablature arrangement are compiled from manual transcriptions gathered from the tablature website ultimate-guitar.com. The implemented transcription web application is evaluated on the compiled ground-truth datasets using several metrics},
 author = {Burlet, Gregory and Fujinaga, Ichiro},
 title = {Robotaba Guitar Tablature Transcription Framework},
 url = {http://ismir2013.ismir.net/wp-content/uploads/2013/09/217_Paper.pdf},
 pages = {517–522},
 editor = {{Souza Britto Jr., Alceu de} and Gouyon, Fabien and Dixon, Simon},
 booktitle = {Proceedings of the 14th International Society for Music Information Retrieval Conference, ISMIR 2013, Curitiba, Brazil, November 4-8, 2013},
 year = {2013}
}


@article{Buschmeier_2011,
 abstract = {},
 author = {Buschmeier, Gabriele and Betzwieser, Thomas},
 year = {2011},
 title = {Digitale Editionen in Akademienprogramm. Die Projektpraxis am Beispiel OPERA},
 pages = {263–269},
 volume = {5},
 number = {3},
 journal = {Die Tonkunst: Magazin f{\"u}r Klassische Musik und Musikwissenschaft}
}


@article{Byrd_2003,
 abstract = {This specification was originally intended for use in developing Variations2. It reflects Indiana University School of Music's orientation toward Western art music ("classical" music), though it also has a strong jazz program and offers courses in popular music. We believe, however, that our requirements are similar to those of almost any academic music department with a similar emphasis on classical music. Specifically, we believe that most music departments that emphasize classical music will have similar requirements regardless of how they approach teaching music theory and analysis and–at least within the limits of music for performance by instrumentalists and singers–regardless of what styles of composition they emphasize. Beyond that, these requirements directly reflect what information is important in notating music, and they should therefore be of considerable interest to designers of music-editing programs.},
 author = {Byrd, Donald A. and Isaacson, Eric},
 year = {2003},
 title = {A Music Representation Requirement Specification for Academia},
 url_JSTOR = {http://www.jstor.org/stable/3681900},
 pages = {43–57},
 volume = {27},
 number = {4},
 journal = {Computer Music Journal}
}


@misc{Byrd_2016,
 abstract = {},
 author = {Byrd, Donald A. and Isaacson, Eric},
 year = {2016},
 title = {A Music Representation Requirement Specification for Academia},
 url = {http://homes.soic.indiana.edu/donbyrd/Papers/MusicRepReqForAcad.doc},
 originalyear = {2003},
 note = {Revised version of the 2003 paper in Computer Music Journal}
}


@article{Crawford_2016,
 abstract = {It will not have escaped the notice of many readers of this Journal that a number of ambitious projects in historical musicology with a major IT component have received generous grant funding in recent years. Underpinning each of these projects is the music-encoding standard known as the Music Encoding Initiative (MEI). […] Clearly MEI is here to stay. In this report we aim to give a sketch of its main features, which potentially enable new modes ofmusic research, and a hint of its impact on the discipline ofmusicology.},
 author = {Crawford, Tim and Lewis, Richard},
 year = {2016},
 title = {Review: Music Encoding Initiative},
 url = {https://jams.ucpress.edu/content/69/1/273.full.pdf},
 pages = {273–285},
 volume = {69},
 number = {1},
 journal = {Journal of the American Musicological Society},
 doi = {10.1525/jams.2016.69.1.273}
}


@mastersthesis{Destandau_2016,
 abstract = {A l’heure du numérique, les pratiques musicales se transforment et les objets qui les véhiculent aussi. Dans ce contexte, ce mémoire étudie la façon dont la Music Encoding Initiative, un format d’encodage pour la musique notée, interagit avec les usages. Il montre que la définition du modèle de description suppose une bonne connaissance du domaine qu’il représente, et un positionnement clair ; que les évolutions du modèle pour s’adapter à de nouvelles pratiques questionnent sa cohérence ; mais que cette flexibilité est pourtant indispensable car c’est elle qui rend le modèle vivant et permet de fédérer autour de lui une communauté, qui invente à son tour de nouvelles applications},
 author = {Destandau, Marie},
 year = {2016},
 title = {La MEI dans tous ses {\'e}tats. La Music Encoding Initiative, de l'encodage aux usages},
 url = {http://www.pas-sages.org/_preview/master/memoireMEI-2016-09-15-5.pdf},
 address = {Lille, France},
 school = {{Universit{\'e} de Lille 3}},
 type = {Master's thesis}
}


@inproceedings{Devaney_2016,
 abstract = {This paper argues for the need to develop a representation for music performance data that is linked with corresponding score information at the note, beat, and measure levels. Building on the results of a survey of music scholars about their music performance data encoding needs, we propose best-practices for encoding perceptually relevant descriptors of the timing, pitch, loudness, and timbral aspects of performance. We are specifically interested in using descriptors that are sufficiently generalized that multiple performances of the same piece can be directly compared with one another. This paper also proposes a specific representation for encoding performance data and presents prototypes of this representation in both Humdrum and Music Encoding Initiative (MEI) formats.},
 author = {Devaney, Johanna and {L{\'e}veill{\'e} Gauvin}, Hubert},
 title = {Representing and Linking Music Performance Data with Score Information},
 pages = {1–8},
 publisher = {{Association for Computing Machinery}},
 isbn = {978-1-4503-4751-8},
 series = {ACM International Conference Proceedings Series},
 editor = {Fields, Ben and Page, Kevin},
 booktitle = {DLfM 2016. Proceedings of the 3rd International Workshop on Digital Libraries for Musicology},
 year = {2016},
 address = {New York, NY},
 doi = {10.1145/2970044.2970052}
}


@article{Doi_2011,
 abstract = {},
 author = {Doi, Carolyn and Martin, Cathy},
 year = {2011},
 title = {Conference Highlights and New Initiatives of MLA 2011},
 url = {https://caml.journals.yorku.ca/index.php/caml/article/viewFile/32103/29349.pdf},
 pages = {28–33},
 volume = {39},
 number = {1},
 journal = {CAML Review/Revue de l'ACBM}
}


@techreport{Duguid_2016,
 abstract = {},
 author = {Duguid, Timothy},
 date = {31.08.2016},
 year = {2016},
 title = {MuSO. Aggregation and Peer Review in Music. NEH White Paper},
 url = {http://oaktrust.library.tamu.edu/bitstream/handle/1969.1/157548/NEH-White-Paper.pdf},
 address = {College Station, TX},
 institution = {{Texas A{\&}M University}}
}


@inproceedings{Duval_2015,
 abstract = {The Europeana repository hosts large collections of digitized music manuscripts and prints. This paper investigates how tools and services for this repository can enable Early Music musicologists to carry out their research in a more effective or efficient way, or to carry out research that is impossible to do without such tools or services. We report on the methodology, user-centered development of a suite of tools that we have integrated loosely, in order to experiment with this specific target audience and an evaluation of the impact that such tools may have on how these musicologists carry out their research. Positive feedback relates to the automation of data sharing between the loosely coupled tools and support for an integrated workflow. Participants in this study wanted to have the ability to work not only with individual items, but also with collections of such items. The use of search facets to filter, and visualization around time and place were positively evaluated, as was the use of Optical Music Recognition and computer-supported analysis of music scores. The musicologists were not convinced of the value of activity streams. They also wanted a less strictly linear organization of their workflow and the ability to not only consume items from the repository, but to also push their research results back into the Europeana repository.},
 author = {Duval, Erik and {van Berchum}, Marnix and Jentzsch, Anja and {Parra Chicho}, Gonzalo Alberto and Drakos, Andreas},
 title = {Musicology of Early Music with Europeana Tools and Services},
 url = {http://ismir2015.uma.es/articles/232_Paper.pdf},
 pages = {632–638},
 isbn = {978-84-606-8853-2},
 editor = {M{\"u}ller, Meinard and Wiering, Frans},
 booktitle = {Proceedings of the 16th International Society for Music Information Retrieval Conference, ISMIR 2015, M{\'a}laga, Spain, October 26-30, 2015},
 year = {2015}
}


@article{Freedman_2011,
 abstract = {},
 author = {Freedman, Richard and Vendrix, Philippe},
 year = {2011},
 title = {The Chansonniers of Nicolas du Chemin. A Digital Forum for Renaissance Music Books},
 pages = {284–288},
 volume = {5},
 number = {3},
 journal = {Die Tonkunst: Magazin f{\"u}r Klassische Musik und Musikwissenschaft}
}


@inproceedings{Hankinson_2010,
 abstract = {Page appearance and layout for music notation is a critical component of the overall musical information contained in a document. To capture and transfer this information, we outline an interchange format for OMR applications, the OMR Interchange Package (OIP) format, which is designed to allow layout information and page images to be preserved and transferred along with semantic musical content. We identify a number of uses for this format that can enhance digital representations of music, and introduce a novel idea for distributed optical music recognition system based on this format.},
 author = {Hankinson, Andrew and Pugin, Laurent and Fujinaga, Ichiro},
 title = {An Interchange Format for Optical Music Recognition Applications},
 url = {http://ismir2010.ismir.net/proceedings/ismir2010-11.pdf},
 pages = {51–56},
 publisher = {{International Society for Music Information Retrieval}},
 isbn = {978-90-393-53813},
 editor = {Downie, J. Stephen and Veltkamp, Remco C.},
 booktitle = {Proceedings of the 11th International Society for Music Information Retrieval Conference, ISMIR 2010, Utrecht, Netherlands, August 9-13, 2010},
 year = {2010}
}


@inproceedings{Hankinson_2011,
 abstract = {Recent changes in the Music Encoding Initiative (MEI) have transformed it into an extensible platform from which new notation encoding schemes can be produced. This paper introduces MEI as a document-encoding framework, and illustrates how it can be extended to encode new types of notation, eliminating the need for creating specialized and potentially incompatible notation encoding standards.},
 author = {Hankinson, Andrew and Roland, Perry and Fujinaga, Ichiro},
 title = {The Music Encoding Initiative as a Document-Encoding Framework},
 url = {http://ismir2011.ismir.net/papers/OS3-1.pdf},
 pages = {293–298},
 publisher = {{University of Miami}},
 isbn = {978-0-615-54865-4},
 editor = {Klapuri, Anssi and Leider, Colby},
 booktitle = {Proceedings of the 12th International Society for Music Information Retrieval Conference, ISMIR 2011, Miami, Florida, USA, October 24-28, 2011},
 year = {2011}
}


@inproceedings{Hankinson_2012,
 abstract = {In this paper we present our work towards developing a largescale web application for digitizing, recognizing (via optical music recognition), correcting, displaying, and searching printed music texts. We present the results of a recently completed prototype implementation of our workflow process, from document capture to presentation on the web. We discuss a number of lessons learned from this prototype. Finally, we present some open-source Web 2.0 tools developed to provide essential infrastructure components for making searchable printed music collections available online. Our hope is that these experiences and tools will help in creating next-generation globally accessible digital music libraries.},
 author = {Hankinson, Andrew and Burgoyne, John Ashley and Vigliensoni, Gabriel and Fujinaga, Ichiro},
 title = {Creating a Large-Scale Searchable Digital Collection from Printed Music Materials},
 pages = {903–908},
 publisher = {{Association for Computing Machinery}},
 booktitle = {WWW'12. Proceedings of the 21st International Conference Companion on World Wide Web},
 year = {2012},
 address = {New York, NY},
 doi = {10.1145/2187980.2188221}
}


@inproceedings{Hankinson_2012b,
 abstract = {Optical music recognition (OMR) and optical character recognition (OCR) have traditionally been used for document transcription–that is, extracting text or symbolic music from page images for use in an editor while discarding all spatial relationships between the transcribed notation and the original image. In this paper we discuss how OCR has shifted fundamentally from a transcription tool to an indexing tool for document image collections resulting from large digitization efforts. OMR tools and procedures, in contrast, are still focused on small-scale modes of operation. We argue that a shift in OMR development towards document image indexing would present new opportunities for searching, browsing, and analyzing large musical document collections. We present a prototype system we built to evaluate the tools and to develop practices needed to process print and manuscript sources.},
 author = {Hankinson, Andrew and Burgoyne, John Ashley and Vigliensoni, Gabriel and Porter, Alastair and Thompson, Jessica and Liu, Wendy and Chiu, Remi and Fujinaga, Ichiro},
 title = {Digital Document Image Retrieval Using Optical Music Recognition},
 url = {http://ismir2012.ismir.net/event/papers/577_ISMIR_2012.pdf},
 pages = {577–582},
 publisher = {{FEUP Edi{\c{c}}{\~o}es}},
 isbn = {978-972-752-144-9},
 editor = {Gouyon, Fabien and Herrera, Perfecto and Martins, Luis Gustavo and M{\"u}ller, Meinard},
 booktitle = {Proceedings of the 13th International Society for Music Information Retrieval Conference, ISMIR 2012, Mosteiro S.Bento Da Vit{\'o}ria, Porto, Portugal, October 8-12, 2012},
 year = {2012}
}


@phdthesis{Hankinson_2014,
 abstract = {},
 author = {Hankinson, Andrew},
 year = {2014},
 title = {Optical Music Recognition Infrastructure for Large-Scale Music Document Analysis},
 url = {https://www.dropbox.com/s/ghupovhktchdfc8/hankinson_dissertation_submission.pdf?dl=0},
 address = {Montreal},
 school = {{Schulich School of Music, McGill University}},
 type = {PhD thesis}
}


@article{Hartwig_2012,
 abstract = {Der Aufsatz stellt die Music Encoding Initiative (MEI), ihr Datenformat, M{\"o}glichkeiten f{\"u}r den Einsatz in Bibliotheken sowie das in Detmold ans{\"a}ssige Projekt zur Weiterentwicklung von MEI vor.},
 author = {Hartwig, Maja and Kepper, Johannes and Richts, Kristina},
 year = {2012},
 title = {Neue Wege der Musikerschlie{\ss}ung. {\"U}ber den m{\"o}glichen Einsatz von MEI in deutschen Bibliotheken},
 url_Link = {https://oa.slub-dresden.de/ejournals/fmb/article/view/96},
 pages = {16–23},
 volume = {33},
 journal = {Forum Musikbibliothek: Beitrage und Informationen aus der Musikbibliothekarischen Praxis}
}


@misc{Kepper_2006,
 abstract = {},
 author = {Kepper, Johannes},
 year = {2006},
 month = {November},
 title = {{Codierungsformen von Musik}},
 url = {http://www.adwmainz.de/fileadmin/adwmainz/MuKo_Veranstaltungen/S2-Digitale_Medien/kepper.pdf},
 note = {{"Digitale Medien und Musikedition". Kolloquium des Ausschusses f{\"u}r musikwissenschaftliche Editionen der Union der deutschen Akademien der Wissenschaften. Mainz, Akademie der Wissenschaften}}
}


@article{Kepper_2009,
 abstract = {The article starts with a brief introduction to the history of music notation encoding. MusicXML and MEI as two of the most recent XML-based file formats are based on completely different concepts of music notation. Whereas MusicXML is the unchallenged market-leader for data interchange, MEI deliberately concentrates on music editorial needs. During this article I will try to point out some of these needs and give a short impression of the specific problems of digital scholarly editions.},
 author = {Kepper, Johannes},
 year = {2009},
 title = {XML-Based Encoding of Musicological Data – About the Requirements of a Digital Music Philology},
 url_Link = {https://www.degruyter.com/view/j/itit.2009.51.issue-4/itit.2009.0544/itit.2009.0544.xml},
 pages = {216–221},
 volume = {51},
 number = {4},
 journal = {it – Information Technology Methoden und innovative Anwendungen der Informatik und Informationstechnik},
 doi = {10.1524/itit.2009.0544}
}


@book{Kepper_2011,
 abstract = {Die Keimzelle der Musikwissenschaft als geisteswissenschaftlicher Disziplin liegt in den Bem{\"u}hungen des 19. Jahrhunderts, die Werke herausragender Komponisten zu konservieren und einer breiteren {\"O}ffentlichkeit zu erschlie{\ss}en. In diesem Umfeld erschien im Jahr 1851 der erste Band der Bach-Gesamtausgabe, herausgegeben von der Leipziger Bachgesellschaft. Alle nachfolgenden Musiker-Ausgaben entwickelten sich auf dieser Basis und reizten die M{\"o}glichkeiten des Buchmediums in zunehmenden Ma{\ss}e aus. Seit etwa zehn Jahren wird versucht, das Potential digitaler Medien f{\"u}r die Musikphilologie zu erschlie{\ss}en. Ausgehend von der Geschichte musikwissenschaftlicher Ausgaben und einer kritischen Reflektion des bisher Geleisteten, weist dieser Band m{\"o}gliche neue Perspektiven f{\"u}r zuk{\"u}nftige, dem neuen Medium angemessene Editionsformen auf.},
 author = {Kepper, Johannes},
 title = {Musikedition im Zeichen neuer Medien. Historische Entwicklung und gegenw{\"a}rtige Perspektiven musikalischer Gesamtausgaben},
 publisher = {BoD},
 address = {Norderstedt},
 year = {2011},
 series = {Schriften des Instituts f{\"u}r Dokumentologie und Editorik},
 number = {5},
 url_URN = {http://nbn-resolving.de/urn:nbn:de:hbz:38-66395},
 isbn = {9783844800760}

}


@inproceedings{Krabbe_2012,
 abstract = {The Danish Centre for Music Publication (DCM) was founded in the spring of 2009, building on the philological expertise of \textit{The Carl Nielsen Edition, }which had published its 33rd and final volume in March 2009. The purpose of the DCM was, by nature, broader than that of \textit{The Carl Nielsen Edition, }standing so to speak on two legs: one is the edition of unknown music kept in the library to be used by scholars and musicians and based on a philological approach, the other is the development of ways to disseminate the results of the Centre's work via the internet. The latter aim has resulted in developing a system for storing and presenting data, especially related to thematic catalogs, based on MEI (Music Encoding Initiative) XML. At present, the software developed at the DCM, called MerMEId (Metadata Editor and Repository for MEI Data), is used for catalogs-in-progress for the works of Carl Nielsen, Johan Svendsen, J. P. E. Hartmann, Niels W. Gade, and J. A. Scheibe. In a further perspective, MEI enables the integration of detailed metadata with the full music text, including variants and emendations within the same file in a format that is interchangeable with other software such as a graphical note editor. In our presentation, we will outline the ideas and principles behind the MerMEId software and briefly demonstrate its use, from the point of view of both the editor and the user.},
 author = {Krabbe, Niels and {Teich Geertinger}, Axel},
 title = {MEI (Music Encoding Initiative) as a Basis for Thematic Catalogues. Thoughts, Experiences, and Preliminary Results},
 url = {http://www.rism.info/fileadmin/content/community-content/events/RISM_Conference_2012/TeichGeertinger_Final.pdf},
 booktitle = {RISM Conference 2012. Music Documentation in Libraries, Scholarship, and Practice},
 year = {2012}
}


@inproceedings{Laplante_2016,
 abstract = {Musical scores and manuscripts are essential resources for music theory research. Although many libraries are such documents from their collections, these online resources are dispersed and the functionalities for exploiting their content remain limited. In this paper, we present a qualitative study based on interviews with librarians on the challenges libraries of all types face when they wish to digitize musical scores. In the light of a literature review on the role libraries can play in supporting digital humanities research, we conclude by briefly discussing the opportunities new technologies for optical music recognition and computer-aided music analysis could create for libraries.},
 author = {Laplante, Audrey and Fujinaga, Ichiro},
 title = {Digitizing Musical Scores: Challenges and Opportunities for Libraries},
 pages = {45–48},
 publisher = {{Association for Computing Machinery}},
 isbn = {978-1-4503-4751-8},
 series = {ACM International Conference Proceedings Series},
 editor = {Fields, Ben and Page, Kevin},
 booktitle = {DLfM 2016. Proceedings of the 3rd International Workshop on Digital Libraries for Musicology},
 year = {2016},
 address = {New York, NY},
 doi = {10.1145/2970044.2970055}
}


@incollection{LeblondMartin_2016b,
 abstract = {},
 author = {{Leblond Martin}, Sylvaine},
 title = {Musiques orales, leur notation musicale et l'encodage num{\'e}rique MEI – Music Encoding Initiative – de cette notation},
 pages = {220–243},
 publisher = {{Les {\'E}ditions de l'Immat{\'e}riel}},
 isbn = {979-1091636049},
 editor = {{Leblond Martin}, Sylvaine},
 booktitle = {Musiques orales, notations musicales et encodages num{\'e}riques},
 year = {2016},
 address = {Paris}
}


@article{Lewis_2015,
 abstract = {Transforming Musicology is a three-year project undertaking musicological research exploring state-of-the-art computational methods in the areas of early modern vocal and instrumental music (mostly for lute), Wagner’s use of leitmotifs, and music as represented in the social media. An essential component of the work involves devising a semantic infrastructure which allows research data, results and methods to be published in a form that enables others to incorporate the research into their own discourse. This includes ways of capturing the processes of musicology in the form of ‘workflows’; in principle, these allow the processes to be repeated systematically using improved data, or on newly discovered sources as they emerge. A large part of the effort of Transforming Musicology (as with any digital research) is concerned with data preparation, which in the early music case described here means dealing with the outputs of optical music recognition software, which inevitably contain errors. This report describes in outline the process of correction and some of the web-based software which has been designed to make this as easy as possible for the musicologist.},
 author = {Lewis, Richard J. and Crawford, Tim and Lewis, David},
 year = {2015},
 title = {Exploring Information Retrieval, Semantic Technologies and Workflows for Music Scholarship. The Transforming Musicology Project},
 url = {http://em.oxfordjournals.org/content/43/4/635.full.pdf+html},
 pages = {635–647},
 volume = {43},
 number = {4},
 journal = {Early Music},
 doi = {10.1093/em/cav073}
}


@article{MartindeGuise_2013,
 abstract = {La MEI – Music Encoding Initiative – a {\'e}t{\'e} d{\'e}velopp{\'e}e selon le m{\^e}me principe que la TEI – Text Encoding Initiative – c'est-{\`a}-dire en poursuivant la volont{\'e} d'offrir un standard qui permette de rendre et d'{\'e}mettre des textes, ici musicaux, qui soient lisibles sur toutes les machines (ordinateurs) et qui puissent comporter une vari{\'e}t{\'e} d'information particuli{\`e}rement exhaustive.

Par exemple, la MEI autorise d{\'e}sormais, non seulement de r{\'e}aliser en langage {\`a} balises le texte des partitions musicales, mais aussi de commenter ces partitions, de fond en comble, d'en pr{\'e}senter des analyses fines et vari{\'e}es qui soient incluses dans le document MEI lui-m{\^e}me et de proposer en m{\^e}me temps les cl{\'e}s de ces analyses.

Si la MEI s'est d'abord appuy{\'e}e sur les caract{\'e}ristiques de la musique occidentale, typiquement "{\'e}crites", pour distinguer des cat{\'e}gories musicales, elle a d{\'e}velopp{\'e} par la suite autant de moyens pour {\'e}tudier les musiques "orales" et aborder leurs caract{\'e}ristiques fondamentales, par exemple les micro-intervalles.

C'est {\`a} ce titre que la MEI montre une capacit{\'e} et une souplesse remarquable {\`a} s'adapter aux musiques de toute origine et de tout mode d'expression, dans le cas pr{\'e}sent les musiques amazighes et arabes d'Alg{\'e}rie. Ce standard devient, par cons{\'e}quent, un outil incontournable au XXIe si{\`e}cle pour faciliter la compr{\'e}hension et la comparaison des musiques du monde.},
 author = {{Martin de Guise}, Sylvaine},
 year = {2013},
 title = {La MEI (Music Encoding Initiative). Un Standard Au Service De La Musique Kabyle},
 url_Link = {http://revue.ummto.dz/index.php/idi/article/view/292/0},
 pages = {245–277},
 volume = {5},
 journal = {Iles d'Imesli}
}


@article{McAulay_2016,
 abstract = {\textit{Purpose} The present paper describes an Arts and Humanities Research Council (AHRC) research project into Scottish fiddle music and the important considerations of music digitization, access and discovery in designing the website that will be one of the project's enduring outcomes.

\textit{Design/methodology/approach} The paper is a general review of existing online indices to music repertoires and some of the general problems associated with selecting metadata and indexing such material and is a survey of the various recent and contemporary projects into the digital encoding of musical notation for online use.

\textit{Findings} The questions addressed during the design of the Bass Culture project database serve to highlight the importance of cooperation between musicologists, information specialists and computer scientists, and the benefits of having researchers with strengths in more than one of these disciplines. The Music Encoding Initiative proves an effective means of providing digital access to the Scottish fiddle tune repertoire.

\textit{Originality/value} The digital encoding of music notation is still comparatively cutting-edge; the Bass Culture project is thus a useful exemplar for interdisciplinary collaboration between musicologists, information specialists and computer scientists, and it addresses issues which are likely to be applicable to future projects of this nature.},
 author = {McAulay, Karen},
 year = {2016},
 title = {Show Me a Strathspey. Taking Steps to Digitize Tune Collections},
 pages = {1–6},
 volume = {30},
 number = {7},
 issn = {0950-4125},
 journal = {Reference Reviews},
 doi = {10.1108/RR-03-2015-0073}
}


@inproceedings{McKay_2016,
 abstract = {This demo presents the jSymbolic2 software for extracting features from symbolic music representations. jSymbolic2 is a tool for assisting musicologists and music theorists in large-scale empirical research projects, and for directly performing the kinds of machine learning based classification and similarity research well-known to the MIR community.},
 author = {McKay, Cory and Tenaglia, Tristano and Fujinaga, Ichiro},
 title = {JSymbolic2. Extracting Features from Symbolic Music Representations},
 url = {https://wp.nyu.edu/ismir2016/wp-content/uploads/sites/2294/2016/08/mckay-jsymbolic2.pdf},
 volume = {Late-Breaking Session},
 isbn = {978-0-692-75506-8},
 editor = {Mandel, Michael I. and Devaney, Johanna and Turnbull, Douglas and Tzanetakis, George},
 booktitle = {Proceedings of the 17th International Society for Music Information Retrieval Conference, ISMIR 2016, New York City, United States, August 7-11, 2016},
 year = {2016}
}


@misc{Morent_2006,
 abstract = {},
 author = {Morent, Stefan and Schr{\"a}der, Gregor},
 year = {2006},
 month = {November},
 title = {T{\"u}Bingen. Digital Critical Edition of Medieval Music. The Music of Hildegard von Bingen [1198-1179]},
 url = {http://www.adwmainz.de/fileadmin/adwmainz/MuKo_Veranstaltungen/S2-Digitale_Medien/TueBingen.pdf},
 note = {{"Digitale Medien und Musikedition". Kolloquium des Ausschusses f{\"u}r musikwissenschaftliche Editionen der Union der deutschen Akademien der Wissenschaften. Mainz, Akademie der Wissenschaften}}
}


@inproceedings{Pugin_2012,
 abstract = {Common Western music notation is traditionally organized on staves that can be grouped into systems. When multiple systems appear on a page, they are arranged from the top to the bottom of the page, similar to lines of words in a text document. Encoding music notation documents for printing requires this arrangement to be captured. However, in the music notation model proposed by the Music Encoding Initiative (MEI), the hierarchy of the XML sub-tree representing the music emphasizes the content rather than the layout. Since systems and pages do not coincide with the musical content, they are encoded in a secondary hierarchy that contains very limited information. In this paper, we present a complementary solution for augmenting the level of detail of the layout of musical documents; that is, the layout information can be encoded in a separate sub-tree with cross-references to other elements holding the musical content. The major advantage of the proposed solution is that it enables multiple layout descriptions, each describing a different visual instantiation of the same musical content.},
 author = {Pugin, Laurent and Kepper, Johannes and Roland, Perry and Hartwig, Maja and Hankinson, Andrew},
 title = {Separating Presentation and Content in MEI},
 url = {http://ismir2012.ismir.net/event/papers/505_ISMIR_2012.pdf},
 pages = {505–510},
 publisher = {{FEUP Edi{\c{c}}{\~o}es}},
 isbn = {978-972-752-144-9},
 editor = {Gouyon, Fabien and Herrera, Perfecto and Martins, Luis Gustavo and M{\"u}ller, Meinard},
 booktitle = {Proceedings of the 13th International Society for Music Information Retrieval Conference, ISMIR 2012, Mosteiro S.Bento Da Vit{\'o}ria, Porto, Portugal, October 8-12, 2012},
 year = {2012}
}


@inproceedings{Pugin_2014,
 abstract = {Rendering symbolic music notation is a common component of many MIR applications, and many tools are available for this task. There is, however, a need for a tool that can natively render the Music Encoding Initiative (MEI) notation encodings that are increasingly used in music research projects. In this paper, we present Verovio, a library and toolkit for rendering MEI. A significant advantage of Verovio is that it implements MEI's structure internally, making it the best suited solution for rendering features that make MEI unique. Verovio is designed as a fast, portable, lightweight tool written in pure standard C++ with no dependencies on third-party frameworks or libraries. It can be used as a command-line rendering tool, as a library, or it can be compiled to JavaScript using the Emscripten LLVM-to-JavaScript compiler. This last option is particularly interesting because it provides a complete in-browser music MEI typesetter. The SVG output from Verovio is organized in such a way that the MEI structure is preserved as much as possible. Since every graphic in SVG is an XML element that is easily addressable, Verovio is particularly well-suited for interactive applications, especially in web browsers. Verovio is available under the GPL open-source license.},
 author = {Pugin, Laurent and Zitellini, Rodolfo and Roland, Perry},
 title = {Verovio. A Library for Engraving MEI Music Notation into SVG},
 url = {http://www.terasoft.com.tw/conf/ismir2014/proceedings/T020_221_Paper.pdf},
 pages = {107–112},
 publisher = {{International Society for Music Information Retrieval}},
 editor = {Wang, Hsin-Min and Yang, Yi-Hsuan and Lee, Jin Ha},
 booktitle = {Proceedings of the 15th International Society for Music Information Retrieval Conference, ISMIR 2014, Taipei, Taiwan, October 27-31, 2014},
 year = {2014}
}


@article{Pugin_2015,
 abstract = {},
 author = {Pugin, Laurent},
 year = {2015},
 title = {The Challenge of Data in Digital Musicology},
 url = {https://www.frontiersin.org/articles/10.3389/fdigh.2015.00004/full},
 volume = {2},
 number = {4},
 journal = {Frontiers in Digital Humanities},
 doi = {10.3389/fdigh.2015.00004}
}


@incollection{Pugin_2016,
 abstract = {},
 author = {Pugin, Laurent},
 title = {Encodage de documents musicaux avec la MEI},
 pages = {162–175},
 publisher = {{Les {\'E}ditions de l'Immat{\'e}riel}},
 isbn = {979-1091636049},
 editor = {{Leblond Martin}, Sylvaine},
 booktitle = {Musiques orales, notations musicales et encodages num{\'e}riques},
 year = {2016},
 address = {Paris}
}


@mastersthesis{Richts_2013,
 abstract = {Following the digital turn and the increasing availability and usefulness of virtual research environments, a stronger collaboration between libraries and research institutions will become an essential prerequisite for future projects. The increasing internationalization in the field of data curation and management leads to higher requirements for libraries and research institutions. This study deals with the implementation of the model of the Functional Requirements for Bibliographic Records(FRBR)in the data framework of the Music Encoding Initiative (MEI), which received much recognition as a standard for encoding music notation in recent years. MEI offers manifold possibilities to store detailed metadata and aims at providing maximum compatibility between the data generated by musicological research projects and best-practice cataloging principles in libraries. Given the upcoming transition to RDA, this combination seems timely and highly promising.},
 author = {Richts, Kristina},
 year = {2013},
 title = {Die FRBR Customization im Datenformat der Music Encoding Initiative (MEI)},
 url_URN = {http://nbn-resolving.de/urn:nbn:de:hbz:79pbc-2013103042},
 address = {K{\"o}ln, Germany},
 school = {{Cologne University of Applied Sciences}},
 type = {Master's thesis}
}


@incollection{Richts_2013b,
 abstract = {The Music Encoding Initiative (MEI) is an XML-based framework for the encoding of music notation and accordingly sheet music. Along the findings of the Text Encoding Initiative (TEI) it was developed for the field of music. One of the distinguishing features of the format is that it not only supports detailed encodings of music notation, but also accommodates comprehensive and detailed metadata for bibliographical recordings of musical sources. Due to its versatility and its robust characteristics MEI is particularly suitable for long-term archiving of data and is thus predestined for use in both fields of musicology and library services. Within the project ``Digital Music Notation Data Model and Prototype Delivery System'' jointly funded by the German Research Foundation (DFG) and the National Endowment of the Humanities (NEH), in summer 2012 training materials have been developed for indexing musical texts and for capturing relevant metadata with MEI. They aim at demonstrating the efficiency of MEI and intend to introduce it to humanities scholars, librarians, editors and computer scientists.},
 author = {Richts, Kristina},
 title = {Entwicklung von Schulungsmaterialien f{\"u}r Einsatzm{\"o}glichkeiten von MEI im bibliothekarischen Bereich},
 url_URN = {http://nbn-resolving.de/urn:nbn:de:hbz:79pbc-opus-3763},
 pages = {137–155},
 publisher = {{Dinges {\&} Frick}},
 isbn = {978-3-934997-51-6},
 series = {b.i.t. online – Innovativ},
 editor = {O{\ss}wald, Achim and Tapenbeck, Inka and Meinhardt, Haike and R{\"o}sch, Hermann},
 booktitle = {MALIS Praxisprojekte 2013. Projektberichte aus dem berufsbegleitenden Masterstudiengang Bibliotheks- und Informationswissenschaft der Fachhochschule K{\"o}ln},
 year = {2013},
 address = {Wiesbaden}
}


@inproceedings{Rizo_2016,
 abstract = {In the realm of digital musicology, standardizations efforts to date have mostly concentrated on the representation of music. Analyses of music are increasingly being generated or communicated by digital means. We demonstrate that the same arguments for the desirability of standardization in the representation of music apply also to the representation of analyses of music: proper preservation, sharing of data, and facilitation of digital processing. We concentrate here on analyses which can be described as hierarchical and show that this covers a broad range of existing analytical formats. We propose an extension of MEI (Music Encoding Initiative) to allow the encoding of analyses unambiguously associated with and aligned to a representation of the music analysed, making use of existing mechanisms within MEI's parent TEI (Text Encoding Initiative) for the representation of trees and graphs.},
 author = {Rizo, David and Marsden, Alan},
 title = {A Standard Format Proposal for Hierarchical Analyses and Representations},
 pages = {25–32},
 publisher = {{Association for Computing Machinery}},
 isbn = {978-1-4503-4751-8},
 series = {ACM International Conference Proceedings Series},
 editor = {Fields, Ben and Page, Kevin},
 booktitle = {DLfM 2016. Proceedings of the 3rd International Workshop on Digital Libraries for Musicology},
 year = {2016},
 address = {New York, NY},
 doi = {10.1145/2970044.2970046}
}


@article{Roewenstrunk_2010,
 abstract = {},
 author = {R{\"o}wenstrunk, Daniel},
 year = {2010},
 title = {Digital Music Notation Data Model and Prototype Delivery System. Ein deutsch-amerikanisches Projekt zur F{\"o}rderung eines wissenschaftlichen Codierungsformats f{\"u}r Musiknotation},
 pages = {134–138},
 volume = {31},
 number = {2},
 journal = {Forum Musikbibliothek: Beitrage und Informationen aus der Musikbibliothekarischen Praxis}
}


@inproceedings{Roland_2000,
 abstract = {This paper evaluates the role of standards in information exchange and suggests the adoption of XML standards for music representation and meta-data to serve as the basis for music information retrieval.},
 author = {Roland, Perry},
 title = {XML4MIR. Extensible Markup Language for Music Information Retrieval},
 url = {http://ismir2000.ismir.net/papers/roland_paper.pdf},
 booktitle = {ISMIR 2000, 1st International Symposium on Music Information Retrieval, Plymouth, Massachusetts, USA, October 23-25, 2000, Proceedings},
 year = {2000}
}


@inproceedings{Roland_2002,
 abstract = {This paper draws parallels between the Text Encoding Initiative (TEI) and the proposed Music Encoding Initiative (MEI), reviews existing design principles for music representations, and describes an eXtensible Markup Language (XML) document type definition (DTD) for modeling music notation which attempts to incorporate those principles.},
 author = {Roland, Perry},
 title = {The Music Encoding Initiative (MEI)},
 url = {http://xml.coverpages.org/MAX2002-PRoland.pdf},
 pages = {55–59},
 booktitle = {MAX2002. Proceedings of the First International Conference on Musical Application using XML},
 year = {2002}
}


@inproceedings{Roland_2003a,
 abstract = {Design patterns attempt to formalize the discussion of recurring problems and their solutions. This paper introduces several XML design patterns and demonstrates their usefulness in the development of XML music representations. The patterns have been grouped into several categories of desirable outcome of the design process – modularity, separation of data and meta-data, reduction of learning requirements, assistance to tool development, and increase in legibility and understandability. The Music Encoding Initiative (MEI) DTD, from which the examples are drawn, the examples, and other materials related to MEI are available at http://www.people.virginia.edu/ {\~{}}pdr4h/.},
 author = {Roland, Perry},
 title = {Design Patterns in XML Music Representation},
 url = {https://jscholarship.library.jhu.edu/bitstream/handle/1774.2/50/paper.pdf},
 booktitle = {ISMIR 2003, 4th International Conference on Music Information Retrieval, Baltimore, Maryland, USA, October 27-30, 2003, Proceedings},
 year = {2003}
}


@misc{Roland_2003b,
 abstract = {This paper provides a technical introduction to the Music Encoding Initiative (MEI) DTD currently under development by the author. It is consciously modeled on the highly successful Text Encoding Initiative (TEI) DTD. The primary purpose of the MEI DTD is the creation of a comprehensive yet extensible standard for the encoding and transmission of music documents in electronic form.},
 author = {Roland, Perry},
 title = {Music Encoding Initiative (MEI) DTD},
 url = {http://xml.coverpages.org/PerryMusicnetwork2003.pdf},
 year = {2003},
 note = {MusicNetwork Notation Workshop: XML-Based Music Notation Solutions. Leeds, England}
}


@misc{Roland_2003c,
 abstract = {},
 author = {Roland, Perry},
 year = {2003},
 title = {Modular Design of the Music Encoding Initiative (MEI) DTD},
 url_Slides = {https://www.powershow.com/view1/20f360-ZDc1Z/Modular_Design_of_the_Music_Encoding_Initiative_MEI_DTD_powerpoint_ppt_presentation},
 note = {MusicNetwork Notation Workshop: XML-Based Music Notation Solutions, Leeds, England. Powerpoint}
}


@inproceedings{Roland_2007,
 abstract = {},
 author = {Roland, Perry and Downie, J. Stephen},
 title = {Recent Developments in the Music Encoding Initiative Project. Enhancing Digital Musicology and Scholarship},
 url_Abstract = {http://www.digitalhumanities.org/dh2007/dh2007.abstracts.pdf},
 url_Poster = {http://music-encoding.org/downloads/RolandDownie2007poster.pdf},
 pages = {186–189},
 booktitle = {19th Joint Conference on the Digital Humanities, Conference Abstracts},
 publisher = {{University of Illinois}},
 year = {2007}
}


@misc{Roland_2009,
 abstract = {},
 author = {Roland, Perry},
 year = {2009},
 title = {The Music Encoding Initiative (MEI) DTD and the OCVE},
 url_Slides = {http://slideplayer.com/slide/2544413/},
 note = {Charlottesville, VA. Powerpoint}
}


@techreport{Roland_2009b,
 abstract = {The purpose of the Music Encoding Initiative (MEI) DTD is two-fold: to provide a standardized, universal XML encoding format for music content (and its accompanying meta-data) and to facilitate interchange of the encoded data. MEI is not designed to be an input code per se, like the Plaine and Easie code; however, it is intended to be human-readable and easily understood and applied. Because of its emphasis on comprehensiveness and software independence, MEI may also function as an archival data format. This white paper describes the features of MEI and the advantages of its use as the encoding standard for the Online Chopin Variorum Edition.},
 author = {Roland, Perry},
 year = {2009},
 title = {The Music Encoding Initiative (MEI) DTD and the Online Chopin Variorum Edition},
 url = {https://pdfs.semanticscholar.org/f216/823c759b89ad8f623cdbd0e3c6e77bc4fe7e.pdf}
}


@article{Roland_2011,
 abstract = {},
 author = {Roland, Perry and Siegert, Christine},
 year = {2011},
 title = {Process-Oriented Notation in MEI},
 pages = {305–309},
 volume = {5},
 number = {3},
 journal = {Die Tonkunst: Magazin f{\"u}r Klassische Musik und Musikwissenschaft}
}


@article{Roland_2014,
 abstract = {The Music Encoding Initiative (MEI) is a collaborative, open-source project focused on building a comprehensive framework for the creation of electronic formats that support encoding of symbolic music notation and other associated data and metadata. The MEI community strives to create scholarly standards for digital musical analysis, criticism and editorial work similar to those available for textual material. The community includes practitioners from a diverse range of related disciplines including musicology, music theory, music librarianship and music technology, each contributing to ongoing discussions and tools for building digital critical music editions. This article provides an introduction to music encoding and MEI in the context of early music.},
 author = {Roland, Perry and Hankinson, Andrew and Pugin, Laurent},
 year = {2014},
 title = {Early Music and the Music Encoding Initiative},
 pages = {605–611},
 volume = {42},
 number = {4},
 journal = {Early Music},
 url_Link = {http://em.oxfordjournals.org/content/42/4/605.full.pdf+html},
 doi = {10.1093/em/cau098}
}


@proceedings{Roland_2015,
 abstract = {},
 year = {2015},
 title = {Music Encoding Conference Proceedings, 2013 and 2014},
 url_URN = {http://nbn-resolving.de/urn:nbn:de:bvb:12-babs2-0000007812},
 publisher = {{Music Enconding Initiative}},
 editor = {Roland, Perry and Kepper, Johannes},
 key = {Roland, Perry and Kepper, Johannes}
}


@inproceedings{Sapp_2015,
 abstract = {This paper discusses the SCORE data format, a graphically oriented music representation developed in the early 1970's, and how such a representation can be converted into sequential descriptions of music notation. The graphical representation system for the SCORE editor is presented along with case studies for parsing and converting the data into other symbolic music formats such as Dox, Humdrum, MusicXML, MuseData, MEI, and MIDI using scorelib, an open-source code library for parsing SCORE data. Knowledge and understanding of the SCORE format is also useful for OMR (Optical Music Recognition) projects, as it can be used as an intermediate layer between raw image scans and higher-level digital music representation systems.},
 author = {Sapp, Craig},
 title = {Graphic to Symbolic Representations of Musical Notation},
 url = {http://tenor2015.tenor-conference.org/papers/20-Sapp-GraphicToSymbolic.pdf},
 pages = {124–132},
 publisher = {{Institut de Recherche en Musicologie}},
 isbn = {978-2-9552905-0-7},
 editor = {Battier, Marc and Bresson, Jean and Couprie, Pierre and Davy-Rigaux, C{\'e}cile and Fober, Dominique and Geslin, Yann and Genevois, Hugues and Picard, Fran{\c{c}}ois and Tacaille, Alice},
 booktitle = {Proceedings of the First International Conference on Technologies for Music Notation and Representation, TENOR 2015, Paris, France, May 28-30, 2015},
 year = {2015},
 address = {Paris},
 doi = {10.5281/zenodo.923829}
}


@misc{Schraeder_2007,
 abstract = {Nach einer kurzen Einf{\"u}hrung zu den Themen der Musikedition und Kodierung mittelalterlicher Neumen habe ich die Vorteile von XML als Speicherformat vorgestellt. Hierbei ist deutlich geworden, dass XML momentan die erste Wahl f{\"u}r die Speicherung von Daten darstellt. Es existieren bereits Speicherformate auf der Basis von XML, die sich mit der Kodierung von Musik besch{\"a}ftigen. MusicXML, MEI und NeumesXML wurden als Beispiele hierf{\"u}r vorgestellt. Diese Formate unterst{\"u}tzen die speziellen Anforderungen dieser Arbeit aber nur teilweise. MusicXML ist als Austauschformat zwischen unterschiedlichen Anwendungen gedacht und unterst{\"u}tzt keine kritischen Editionen oder {\"a}ltere Musiknotation. MEI unterst{\"u}tzt zwar den kritischen Bericht sehr gut, aber nicht die Neumendarstellung. NeumesXML ist f{\"u}r die Neumendarstellung optimiert, allerdings sind Varianten nicht vorgesehen. Eine Eigenentwicklung war dennoch nicht notwendig. Perry Roland, der Entwickler von MEI, zeigte die Bereitschaft, eine Neumenkodierung in MEI zu integrieren. Diese Erweiterung wurde in Kapitel 6 vorgestellt.},
 author = {Schr{\"a}der, Gregor},
 year = {2007},
 month = {August},
 title = {{Ein XML-Datenformat zur Repr{\"a}sentation kritischer Musikedition unter besonderer Ber{\"u}cksichtigung von Neumennotation}},
 url = {http://www.dimused.uni-tuebingen.de/downloads/studienarbeit.pdf},
 note = {{Seminar Paper. T{\"u}bingen, Eberhard Karls Universit{\"a}t}},

}


@article{SelfridgeField_2015,
 abstract = {The publication term “hybrid digital edition” came into existence at the end of 2013, with the publication of Salieri’s theatrical divertimento Prima la musica, e poi la parola. It is a hybrid in that its theatritical apparatus is a digital constellation of auxiliary materials consulted in the course of constructing a new edition, while the score is a conventional one. A user can in principle consult the two bilaterally, but the confinement of the critical report to a physical device unsuited to network use has crippled it in some libraries. Since Prima la musica is both the first of a series of other operas presented in the same way, and of a more opened-ended effort to edit works in other genres similarly, it is important to understand how this combination came to be and what its potential advantages are. Since the new model was perceived by many librarians in the U.S. as excessively expensive, a table of prices of recently published opera editions is provided. These editions prove not to be moderately priced, but the costs of opera scores produced in Europe is, on average, much higher than those produced in the U.S.},
 author = {Selfridge-Field, Eleanor},
 year = {2015},
 title = {Hybrid Critical Editions of Opera. Motives, Milestones, and Quandaries},
 url = {https://muse.jhu.edu/journals/notes/v072/72.1.selfridge-field.pdf},
 pages = {9–22},
 volume = {72},
 number = {1},
 journal = {Notes},
 doi = {10.1353/not.2015.0100}
}


@misc{Stewart_2003,
 abstract = {},
 author = {Stewart, Darin},
 year = {2013},
 month = {December},
 title = {XML for Music},
 url_Link = {http://www.emusician.com/gear/1332/xml-for-music/33473},
 note = {Electronic Musician (01.12.2013)}
}


@article{Stinson_2014,
 abstract = {Encoding massive amounts of medieval music notation provides the raw data needed for gaining a systematic understanding of differences and similarities in musical writing, and for researching notation's role in compositional process and musical transmission in medieval societies. The ability to represent all forms of medieval music notation electronically is also of utmost importance for current and future projects which are developing Optical Music Recognition systems for medieval notation and creating searchable datasets of nowplentiful online images of digitized medieval music manuscripts.1 In this report the authors outline their efforts to date in encoding medieval music notation using the pioneering \textit{Scribe }software and their current collaboration on transforming \textit{Scribe }data into a valuable pool of open access research data for distribution on the internet, for both musicologists and generalists interested in the study and performance of medieval music from original notation.},
 author = {Stinson, John and Stoessel, Jason},
 year = {2014},
 title = {Encoding Medieval Music Notation for Research},
 url_Link = {http://em.oxfordjournals.org/content/42/4/613.full.pdf+html},
 pages = {613–617},
 volume = {42},
 number = {4},
 journal = {Early Music},
 doi = {10.1093/em/cau093}
}


@article{TeichGeertinger_2011,
 abstract = {},
 author = {{Teich Geertinger}, Axel and Pugin, Laurent},
 year = {2011},
 title = {MEI for Bridging the Gap Between Music Cataloguing and Digital Critical Editions},
 pages = {289–294},
 volume = {5},
 number = {3},
 journal = {Die Tonkunst: Magazin f{\"u}r Klassische Musik und Musikwissenschaft}
}


@article{TeichGeertinger_2014,
 abstract = {Traditionally, digital collections of musical metadata, i.e., information about musical works – such as library catalogues or thematic catalogues are based on relational databases. Digital archives of musical scores, on the other hand, usually consist of collections of files, each containing one work in some presentation format (primarily PDF). Both types of collections are technically easy to build, but they have a number of limitations in terms of long-term preservation, data exchange and data re-use, and flexibility. A text-based data structure sophisticated enough to contain both detailed metadata and fully-featured scores may be a way of overcoming some of these limitations and at the same time include catalogue data in the score and vice versa. The Music Encoding Initiative (MEI) offers a framework for such an approach based on XML files. The article discusses pros and cons and illustrates some of the possible use cases.},
 author = {{Teich Geertinger}, Axel},
 year = {2014},
 title = {Turning Music Catalogues into Archives of Musical Scores–or Vice Versa. Music Archives and Catalogues Based on MEI XML},
 url_JSTOR = {http://www.jstor.org/stable/24330408},
 pages = {61–66},
 volume = {61},
 number = {1},
 journal = {Fontes Artis Musicae}
}


@article{Veit_2012,
 abstract = {For the past 150 years scholarly music editions have made use of similar techniques, but the accessibility of sources has continually become easier. Digital editions make thorough use of facsimiles and, hence, bridge the gap between researcher and user. But the capabilities of digital media will only be realized when, in the future, images can be encoded and made available in standardized formats. The results of scholarly work presented in the formats of XML or MEI can be combined with bibliographic metadata and need to be made openly accessible over the long-term as base data for ongoing research. As a consequence, however, the boundaries between the tasks of research and library conservation become blurred. This article illustrates and discusses the problems and consequences of these transformations, which may ultimately lead to a re-definition of what is meant by the term "music edition".},
 author = {Veit, Joachim},
 year = {2012},
 title = {W{\"a}chst zusammen, was zusammen geh{\"o}rt? Wissenschaftliche Musikergesamtausgaben und Bibliotheken},
 url = {http://zs.thulb.uni-jena.de/servlets/MCRFileNodeServlet/jportal_derivate_00226208/j12-h3-4-auf-6.pdf},
 url_Link = {http://zs.thulb.uni-jena.de/receive/jportal_jparticle_00266455},
 pages = {166–174},
 volume = {59},
 number = {3–4},
 journal = {Zeitschrift f{\"u}r Bibliothekswesen und Bibliographie},
 doi = {10.3196/1864295012593472}
}


@inproceedings{Viglianti_2010,
 abstract = {This poster presents the results of the [author's] dissertation's case study: a digital edition of Claude Debussy's Syrinx (La Fl{\^u}te de Pan) for flute solo. The XML-based model represents notation, variant readings and editorial intervention; additionally, several different views are extracted and rendered for presentation with vector images.},
 author = {Viglianti, Raffaele},
 title = {Critical Editing of Music in the Digital Medium. An Experiment in MEI},
 url = {http://dh2010.cch.kcl.ac.uk/academic-programme/abstracts/papers/pdf/ab-819.pdf},
 pages = {380–382},
 booktitle = {Digital Humanities 2010 (DH2010). Conference Abstracts},
 year = {2010}
}


@article{Viglianti_2011,
 abstract = {},
 author = {Viglianti, Raffaele and Veit, Joachim},
 year = {2011},
 title = {Mind the Gap. A Preliminary Evaluation of Issues in Combining Text and Music Encoding},
 pages = {318–325},
 volume = {5},
 number = {3},
 journal = {Die Tonkunst: Magazin f{\"u}r Klassische Musik und Musikwissenschaft}
}


@inproceedings{Viglianti_2016,
 abstract = {This paper describes an Application Programming Interface (API) for addressing music notation on the web regardless of the format in which it is stored. This API was created as a method for addressing and extracting specific portions of music notation published in machine-readable formats on the web. Music notation, like text, can be ``addressed'' in new ways in a digital environment, allowing scholars to identify and name structures of various kinds, thus raising such questions as how can one virtually ``circle'' some music notation? How can a machine interpret this ``circling'' to select and retrieve the relevant music notation?

The API was evaluated by: 1) creating an implementation of the API for documents in the Music Encoding Initiative (MEI) format; and by 2) remodelling a dataset ofmusic analysis statements from the Du Chemin: Lost Voices project (Haverford College) by using the API to connect the analytical statements with the portion of notaiton they refer to. Building this corpus has demonstrated that the Music Addressability API is capable of modelling complex analytical statements containing references to music notation.},
 author = {Viglianti, Raffaele},
 title = {The Music Addressability API},
 pages = {57–60},
 publisher = {{Association for Computing Machinery}},
 isbn = {978-1-4503-4751-8},
 series = {ACM International Conference Proceedings Series},
 editor = {Fields, Ben and Page, Kevin},
 booktitle = {DLfM 2016. Proceedings of the 3rd International Workshop on Digital Libraries for Musicology},
 year = {2016},
 address = {New York, NY},
 doi = {10.1145/2970044.2970056}
}


@inproceedings{Vigliensoni_2011,
 abstract = {In this paper we present our research in the development of a pitch-finding system to extract the pitches of neumes–some of the oldest representations of pitch in Western music– from the Liber Usualis, a well-known compendium of plainchant as used in the Roman Catholic church. Considerations regarding the staff position, staff removal, space- and linezones, as well as how we treat specific neume classes and modifiers are covered. This type of notation presents a challenge for traditional optical music recognition (OMR) systems because individual note pitches are indivisible from the larger ligature group that forms the neume. We have created a dataset of correctly-notated transcribed chant for comparing the performance of different variants of our pitch-finding system. The best result showed a recognition rate of 97{\%} tested with more than 2000 neumes.},
 author = {Vigliensoni, Gabriel and Burgoyne, John Ashley and Hankinson, Andrew and Fujinaga, Ichiro},
 title = {Automatic Pitch Recognition in Printed Square-Note Notation},
 url = {http://www.ismir2011.ismir.net/papers/PS3-12.pdf},
 pages = {423–428},
 publisher = {{University of Miami}},
 isbn = {978-0-615-54865-4},
 editor = {Klapuri, Anssi and Leider, Colby},
 booktitle = {Proceedings of the 12th International Society for Music Information Retrieval Conference, ISMIR 2011, Miami, Florida, USA, October 24-28, 2011},
 year = {2011}
}


@inproceedings{Vigliensoni_2013,
 abstract = {This paper presents work on the automatic recognition of measures in common Western music notation scores using optical music recognition techniques. It is important to extract the bounding boxes of measures within a music score to facilitate some methods of multimodal navigation of music catalogues. We present an image processing algorithm that extracts the position of barlines on an input music score in order to deduce the number and position of measures on the page. An open-source implementation of this algorithm is made publicly available. In addition, we have created a ground-truth dataset of 100 images of music scores with manually annotated measures. We conducted several experiments using different combinations of values for two critical parameters to evaluate our measure recognition algorithm. Our algorithm obtained an f-score of 91 percent with the optimal set of parameters. Although our implementation obtained results similar to previous approaches, the scope and size of the evaluation dataset is significantly larger.},
 author = {Vigliensoni, Gabriel and Gregory, Burlet and Fujinaga, Ichiro},
 title = {Optical Measure Recognition in Common Music Notation},
 url = {http://ismir2013.ismir.net/wp-content/uploads/2013/09/207_Paper.pdf},
 pages = {125–130},
 editor = {{Souza Britto Jr., Alceu de} and Gouyon, Fabien and Dixon, Simon},
 booktitle = {Proceedings of the 14th International Society for Music Information Retrieval Conference, ISMIR 2013, Curitiba, Brazil, November 4-8, 2013},
 year = {2013}
}


@inproceedings{Weigl_2016,
 abstract = {The Music Encoding Initiative (MEI) [1] provides a framework for expressing musical notation that enables the identification (via XML identifiers), and thus addressing, of score elements at various levels of granularity (e.g. individual systems, measures, or notes) [2]. Verovio [3], an open-source MEI renderer that produces beautiful SVG renditions of the score, retains the MEI identifiers and element hierarchy in the produced output, enabling dynamic interactivity with score elements through a web browser. We present a demonstrator that combines these capabilities with semantic technologies including RDF, JSON-LD, SPARQL, and the Open Annotation data model, anchoring into the musical notation by using the MEI XML IDs as fragment identifiers to enable the fine-grained incorporation of musical notation within a web of Linked Data. This fusing of music and semantics affords the creation of rich Digital Music Objects supporting contemporary music consumption and performance.},
 author = {Weigl, David M. and Page, Kevin},
 title = {Dynamic Semantic Notation. Jamming Together Music Encoding and Linked Data},
 url = {https://wp.nyu.edu/ismir2016/wp-content/uploads/sites/2294/2016/08/weigl-dynamic.pdf},
 isbn = {978-0-692-75506-8},
 editor = {Mandel, Michael I. and Devaney, Johanna and Turnbull, Douglas and Tzanetakis, George},
 booktitle = {Proceedings of the 17th International Society for Music Information Retrieval Conference, ISMIR 2016, New York City, United States, August 7-11, 2016},
 year = {2016},
 note = {Late-Breaking Session}
}


@inproceedings{Zitellini_2016,
 abstract = {From the 17th century to the first decades of the 18th century music notation slowly loses all its mensural influences, becoming virtually identical to what we would consider common modern notation. During these five decades of transformation composers did not just suddenly abandon older notation styles, but they used them alongside ones that would eventually become the standard. Void notation, black notation and uncommon tempi were all mixed together. The scholar preparing modern editions of this music is normally forced to normalise all these atypical notations as many software applications do not support them natively. This paper demonstrates the flexibility of the coding scheme proposed by the Music Encoding Initiative (MEI), and of Verovio, a visualisation library designed for it. The modular approach of these tools means that particular notation systems can be added easily while maintaining compatibility with other encoded notations.},
 author = {Zitellini, Rodolfo and Pugin, Laurent},
 title = {Representing Atypical Music Notation Practices. An Example with Late 17th Century Music},
 url = {http://tenor2016.tenor-conference.org/papers/10_Zitellini_tenor2016.pdf},
 pages = {71–76},
 publisher = {{Anglia Ruskin University}},
 isbn = {978-0-9931461-1-4},
 editor = {Hoadley, Richard and Fober, Dominique and Nash, Chris},
 booktitle = {Proceedings of the Second International Conference on Technologies for Music Notation and Representation, TENOR 2016, Cambridge, UK, May 27–29, 2016},
 year = {2016},
 address = {Cambridge, UK}
}
